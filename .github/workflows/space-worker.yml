name: Space Worker

on:
  workflow_dispatch:
    inputs:
      space_url:
        description: X Twitter Space URL https://x.com/i/spaces/...
        required: true
        type: string
      title:
        description: Post title (fallback if no post id)
        required: false
        type: string
        default: ""
      post_id:
        description: Existing WP post id to patch (optional)
        required: false
        type: string
        default: ""
      gcs_prefix:
        description: GCS prefix folder, e.g. "spaces/2025/02" (empty → spaces/YYYY/MM)
        required: false
        type: string
        default: ""
      make_public:
        description: Set GCS objects to public
        required: false
        type: choice
        options: ["true", "false"]
        default: "true"
      do_transcript:
        description: Generate transcript/VTT (Deepgram) when crawler captions unavailable
        required: false
        type: choice
        options: ["true", "false"]
        default: "true"
      wp_marker:
        description: Opaque marker from WP (optional)
        required: false
        type: string
        default: ""
      space_id:
        description: Space ID (e.g. 1kvJpyzZOOkxE). Auto-parsed from URL if blank
        required: false
        type: string
        default: ""
      mode:
        description: Optional targeted mode
        required: false
        type: choice
        options: ["", "transcript_only", "attendees_only"]
        default: ""
      existing_mp3_url:
        description: For transcript_only: URL of already-encoded MP3
        required: false
        type: string
        default: ""

permissions:
  contents: read
  packages: read

concurrency:
  group: ${{ format('space-worker-{0}-{1}', github.ref, inputs.post_id != '' && inputs.post_id || github.run_id) }}
  cancel-in-progress: false

env:
  GCP_SA_KEY:       ${{ secrets.GCP_SA_KEY       || vars.GCP_SA_KEY }}
  GCS_BUCKET:       ${{ secrets.GCS_BUCKET       || vars.GCS_BUCKET }}
  WP_BASE_URL:      ${{ secrets.WP_BASE_URL      || secrets.WP_URL || vars.WP_BASE_URL || vars.WP_URL }}
  WP_USER:          ${{ secrets.WP_USER          || vars.WP_USER }}
  WP_APP_PASSWORD:  ${{ secrets.WP_APP_PASSWORD  || vars.WP_APP_PASSWORD }}
  DEEPGRAM_API_KEY: ${{ secrets.DEEPGRAM_API_KEY || vars.DEEPGRAM_API_KEY }}

  # X / Twitter creds
  TWITTER_AUTHORIZATION: ${{ secrets.TWITTER_AUTHORIZATION || secrets.X_BEARER || vars.TWITTER_AUTHORIZATION || vars.X_BEARER }}
  TWITTER_AUTH_TOKEN:    ${{ secrets.TWITTER_AUTH_TOKEN    || secrets.X_AUTH_TOKEN || vars.TWITTER_AUTH_TOKEN || vars.X_AUTH_TOKEN }}
  TWITTER_CSRF_TOKEN:    ${{ secrets.TWITTER_CSRF_TOKEN    || secrets.X_CSRF       || vars.TWITTER_CSRF_TOKEN || vars.X_CSRF }}

  WORKDIR: ${{ github.workspace }}/work
  ARTDIR:  ${{ github.workspace }}/out

jobs:
  run:
    name: Process Space
    runs-on: ubuntu-latest
    timeout-minutes: 180

    steps:
      - name: Ping WP (queued)
        if: ${{ env.WP_BASE_URL != '' && env.WP_USER != '' && env.WP_APP_PASSWORD != '' && inputs.post_id != '' }}
        shell: bash
        run: |
          set -euo pipefail
          curl -sS -u "${WP_USER}:${WP_APP_PASSWORD}" \
            -H "Content-Type: application/json" \
            -X POST "${WP_BASE_URL%/}/wp-json/ss3k/v1/worker-status" \
            -d "$(jq -n --arg pid "${{ inputs.post_id }}" --arg status "queued" \
                       --arg msg "Workflow received and queued" \
                       --arg run "${{ github.run_id }}" --argjson progress 1 \
                       '{post_id: ($pid|tonumber), status:$status, message:$msg, run_id:$run, progress:$progress}')"

      - name: Install deps (ffmpeg, jq, yt-dlp, gcloud) + docker login
        shell: bash
        run: |
          set -euxo pipefail
          sudo apt-get update
          sudo apt-get install -y --no-install-recommends ffmpeg jq python3 python3-pip ca-certificates gnupg
          python3 -m pip install --upgrade pip
          python3 -m pip install --no-cache-dir yt-dlp
          echo "deb [signed-by=/usr/share/keyrings/cloud.google.gpg] http://packages.cloud.google.com/apt cloud-sdk main" | sudo tee /etc/apt/sources.list.d/google-cloud-sdk.list
          curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo gpg --dearmor -o /usr/share/keyrings/cloud.google.gpg
          sudo apt-get update && sudo apt-get install -y google-cloud-sdk
          echo "${{ github.token }}" | docker login ghcr.io -u "${{ github.actor }}" --password-stdin

      - name: Validate env + compute prefixes
        id: cfg
        shell: bash
        run: |
          set -euxo pipefail
          test -n "${GCP_SA_KEY}" || { echo "GCP_SA_KEY missing"; exit 1; }
          test -n "${GCS_BUCKET}" || { echo "GCS_BUCKET missing"; exit 1; }
          mkdir -p "$WORKDIR" "$ARTDIR" "$ARTDIR/logs"
          PFX="$(echo "${{ inputs.gcs_prefix }}" | sed -E 's#^/*##; s#/*$##')"
          if [ -z "$PFX" ]; then
            PFX="spaces/$(date +%Y)/$(date +%m)"
          fi
          echo "prefix=${PFX}" >> "$GITHUB_OUTPUT"
          echo "PREFIX=${PFX}" >> "$GITHUB_ENV"
          echo "BUCKET_PREFIX=${PFX#spaces/}" >> "$GITHUB_ENV"

      - name: Derive space id + base
        id: ids
        shell: bash
        env:
          INP_SPACE_ID: ${{ inputs.space_id }}
          URL:          ${{ inputs.space_url }}
        run: |
          set -euxo pipefail
          SID="${INP_SPACE_ID}"
          if [ -z "$SID" ]; then
            SID="$(echo "$URL" | sed -nE 's#^.*/i/spaces/([^/?#]+).*#\1#p')"
          fi
          test -n "$SID" || { echo "Could not parse Space ID"; exit 1; }
          BASE="space-$(date +%m-%d-%Y)-${SID}"
          echo "space_id=${SID}" >> "$GITHUB_OUTPUT"
          echo "BASE=${BASE}"     >> "$GITHUB_OUTPUT"
          echo "SPACE_ID=${SID}"  >> "$GITHUB_ENV"
          echo "BASE=${BASE}"     >> "$GITHUB_ENV"

      - name: GCP auth (service account)
        shell: bash
        run: |
          set -euxo pipefail
          printf '%s\n' "${GCP_SA_KEY}" > "${HOME}/gcp-key.json"
          gcloud auth activate-service-account --key-file="${HOME}/gcp-key.json" >/dev/null

      # -------- Relaxed preflight (does not block on /participants 200) --------
      - name: X preflight auth sanity check
        id: x_preflight
        shell: bash
        run: |
          set -euxo pipefail
          AUTH="${TWITTER_AUTHORIZATION:-}"
          AT="${TWITTER_AUTH_TOKEN:-}"
          CT="${TWITTER_CSRF_TOKEN:-}"

          # Keep AUTH only if it starts with "Bearer "
          if [ -n "$AUTH" ] && ! printf '%s' "$AUTH" | grep -q '^Bearer '; then
            AUTH=""
          fi

          # Mask provided secrets
          [ -n "${TWITTER_AUTHORIZATION:-}" ] && echo "::add-mask::${TWITTER_AUTHORIZATION}"
          [ -n "$AT" ] && echo "::add-mask::${AT}"
          [ -n "$CT" ] && echo "::add-mask::${CT}"

          OK=0
          REASON="no_creds"

          HAS_COOKIE=0
          HAS_BEARER=0
          [ -n "$AT" ] && [ -n "$CT" ] && HAS_COOKIE=1 || true
          [ -n "$AUTH" ] && HAS_BEARER=1 || true

          # If we have any creds at all, allow the crawler (diagnostics still run)
          if [ "$HAS_COOKIE" -eq 1 ] || [ "$HAS_BEARER" -eq 1 ]; then
            OK=1
            REASON="creds_present"
          fi

          mkdir -p "${ARTDIR}"
          BASEH=(-H "User-Agent: Mozilla/5.0" -H "Accept: application/json, text/plain, */*" -H "Referer: https://x.com/i/spaces/${SPACE_ID:-home}")

          # Diagnostics only (not gating)
          if [ "$HAS_COOKIE" -eq 1 ] && [ "$HAS_BEARER" -eq 1 ]; then
            CVAL="auth_token=${AT}; ct0=${CT}"
            HTTP=$(curl -sS -o "${ARTDIR}/x_participants_cookie.json" -w "%{http_code}" \
              "https://x.com/i/api/spaces/${SPACE_ID}/participants" \
              "${BASEH[@]}" -H "Authorization: ${AUTH}" -H "x-csrf-token: ${CT}" \
              -H "Cookie: ${CVAL}" -H "x-twitter-active-user: yes" -H "x-twitter-client-language: en" \
              -H "x-twitter-auth-type: OAuth2Session" || echo 000)
            echo "diag_participants_cookie_http=${HTTP}" >> "$GITHUB_OUTPUT"
          fi

          if [ "$HAS_BEARER" -eq 1 ]; then
            GHTTP=$(curl -sS -o "${ARTDIR}/x_guest.json" -w "%{http_code}" \
              -X POST "https://api.twitter.com/1.1/guest/activate.json" \
              -H "Authorization: ${AUTH}" -H "Content-Type: application/json" -d '{}' || echo 000)
            echo "diag_guest_activate_http=${GHTTP}" >> "$GITHUB_OUTPUT"
            if [ "$OK" -ne 1 ] && [ "$GHTTP" = "200" ]; then
              OK=1; REASON="guest_ok"
            fi
            if [ "$GHTTP" = "200" ]; then
              GUEST=$(jq -r '.guest_token // empty' "${ARTDIR}/x_guest.json" 2>/dev/null || true)
              if [ -n "$GUEST" ]; then
                PHTTP=$(curl -sS -o "${ARTDIR}/x_participants_guest.json" -w "%{http_code}" \
                  "https://x.com/i/api/spaces/${SPACE_ID}/participants" \
                  "${BASEH[@]}" -H "Authorization: ${AUTH}" -H "x-guest-token: ${GUEST}" \
                  -H "x-twitter-active-user: yes" -H "x-twitter-client-language: en" || echo 000)
                echo "diag_participants_guest_http=${PHTTP}" >> "$GITHUB_OUTPUT"
              fi
            fi
          fi

          if [ "$OK" -ne 1 ]; then
            for PEEK in "https://x.com/i/spaces/${SPACE_ID}/peek" "https://twitter.com/i/spaces/${SPACE_ID}/peek"; do
              PHTTP=$(curl -sS -o "${ARTDIR}/x_peek.json" -w "%{http_code}" "$PEEK" -H "User-Agent: Mozilla/5.0" -H "Accept: application/json" || echo 000)
              echo "diag_peek_http=${PHTTP}" >> "$GITHUB_OUTPUT"
              [ "$PHTTP" = "200" ] && OK=1 && REASON="public_ok" && break || true
            done
          fi

          echo "ok=${OK}"         >> "$GITHUB_OUTPUT"
          echo "reason=${REASON}" >> "$GITHUB_OUTPUT"
          [ -n "$AUTH" ] && echo "TWITTER_AUTHORIZATION=$AUTH" >> "$GITHUB_ENV"

      # -------------------- CRAWLER (always for "" or attendees_only) --------------------
      - name: Notify WP: crawler starting
        if: ${{ (inputs.mode != 'transcript_only') && env.WP_BASE_URL != '' && env.WP_USER != '' && env.WP_APP_PASSWORD != '' && inputs.post_id != '' }}
        shell: bash
        run: |
          set -euo pipefail
          curl -sS -u "${WP_USER}:${WP_APP_PASSWORD}" -H "Content-Type: application/json" \
            -X POST "${WP_BASE_URL%/}/wp-json/ss3k/v1/worker-status" \
            -d "$(jq -n --arg pid "${{ inputs.post_id }}" --arg status "processing" \
                       --arg msg "twspace crawler fetching metadata/audio" \
                       --arg run "${{ github.run_id }}" --argjson progress 8 \
                       '{post_id: ($pid|tonumber), status:$status, message:$msg, run_id:$run, progress:$progress}')"

      - name: twspace-crawler (run)
        id: crawl
        if: ${{ inputs.mode != 'transcript_only' && steps.x_preflight.outputs.ok == '1' }}
        shell: bash
        env:
          SID: ${{ steps.ids.outputs.space_id }}
        run: |
          set -euxo pipefail
          mkdir -p "${ARTDIR}" "${ARTDIR}/logs"
          docker pull ghcr.io/hitomarukonpaku/twspace-crawler:latest || true

          LOG_STD="${ARTDIR}/logs/crawler_${SID}.out.log"
          LOG_ERR="${ARTDIR}/logs/crawler_${SID}.err.log"

          set +e
          if [ "${{ inputs.mode }}" = "attendees_only" ]; then
            # short run just to capture metadata lines
            timeout 90s docker run --rm \
              -e TWITTER_AUTHORIZATION \
              -e TWITTER_AUTH_TOKEN \
              -e TWITTER_CSRF_TOKEN \
              -v "${ARTDIR}:/app/download" \
              -v "${ARTDIR}/logs:/app/logs" \
              ghcr.io/hitomarukonpaku/twspace-crawler:latest \
              --id "${SID}" --force \
              > >(tee -a "$LOG_STD") 2> >(tee -a "$LOG_ERR" >&2)
          else
            timeout 10m docker run --rm \
              -e TWITTER_AUTHORIZATION \
              -e TWITTER_AUTH_TOKEN \
              -e TWITTER_CSRF_TOKEN \
              -v "${ARTDIR}:/app/download" \
              -v "${ARTDIR}/logs:/app/logs" \
              ghcr.io/hitomarukonpaku/twspace-crawler:latest \
              --id "${SID}" --force \
              > >(tee -a "$LOG_STD") 2> >(tee -a "$LOG_ERR" >&2)
          fi
          RC=$?
          set -e
          echo "crawler_exit=$RC"

          # Try to locate an audio file (only for full mode)
          if [ "${{ inputs.mode }}" != "attendees_only" ]; then
            AUDIO_FILE="$(find "${ARTDIR}" -type f \( -iname '*.m4a' -o -iname '*.mp3' -o -iname '*.mp4' -o -iname '*.aac' -o -iname '*.webm' -o -iname '*.ogg' -o -iname '*.wav' -o -iname '*.ts' \) -printf '%T@ %p\n' | sort -nr | head -n1 | cut -d' ' -f2- || true)"
            if [ -n "$AUDIO_FILE" ]; then
              echo "INPUT_FILE=${AUDIO_FILE}" >> "$GITHUB_ENV"
              echo "audio_file=${AUDIO_FILE}"  >> "$GITHUB_OUTPUT"
            fi
          fi

          # Captions (if any)
          CC_FILE="$(find "${ARTDIR}" -type f \( -iname '*cc.jsonl' -o -iname '*caption*.jsonl' \) | head -n1 || true)"
          if [ -n "$CC_FILE" ]; then
            set +e
            docker run --rm -v "${ARTDIR}:/app/download" \
              ghcr.io/hitomarukonpaku/twspace-crawler:latest \
              cc e "/app/download/$(basename "$CC_FILE")" > "${ARTDIR}/_crawler_cc.txt"
            docker run --rm -v "${ARTDIR}:/app/download" \
              ghcr.io/hitomarukonpaku/twspace-crawler:latest \
              cc v "/app/download/$(basename "$CC_FILE")" > "${ARTDIR}/${BASE}.vtt"
            set -e
            [ -s "${ARTDIR}/_crawler_cc.txt" ] && cp "${ARTDIR}/_crawler_cc.txt" "${ARTDIR}/${BASE}.txt" && echo "TX_PATH=${ARTDIR}/${BASE}.txt" >> "$GITHUB_ENV"
            [ -s "${ARTDIR}/${BASE}.vtt" ] && echo "VTT_PATH=${ARTDIR}/${BASE}.vtt" >> "$GITHUB_ENV"
          fi

      # -------------------- EXTRACT ATTENDEES FROM CRAWLER OUTPUT --------------------
      - name: Extract attendees (GraphQL from crawler logs)
        id: attendees
        if: ${{ steps.crawl.outcome == 'success' }}
        shell: bash
        env:
          SID: ${{ steps.ids.outputs.space_id }}
          LOG_STD: ${{ env.ARTDIR }}/logs/crawler_${{ steps.ids.outputs.space_id }}.out.log
          LOG_ERR: ${{ env.ARTDIR }}/logs/crawler_${{ steps.ids.outputs.space_id }}.err.log
          ATTN_JSON:  ${{ env.ARTDIR }}/attendees.json
          ATTN_HTML:  ${{ env.ARTDIR }}/attendees.html
        run: |
          set -euxo pipefail
          python3 - <<'PY'
import json, os, sys, re

artdir = os.environ.get("ARTDIR", "")
sid = os.environ.get("SID", "")
log_std = os.environ.get("LOG_STD", "")
log_err = os.environ.get("LOG_ERR", "")
attn_json = os.environ.get("ATTN_JSON", "")
attn_html = os.environ.get("ATTN_HTML", "")

def read(p):
    try:
        with open(p, 'r', errors='ignore') as f:
            return f.read()
    except Exception:
        return ""

blob = (read(log_std) + "\n" + read(log_err))

# Try to carve out the JSON object that contains "audioSpace"
# Strategy: find the nearest '{' before the first "audioSpace" and brace-match to extract a valid JSON object
m = re.search(r'\{[^{}]*"audioSpace"\s*:', blob)
if not m:
    # Fallback: try a more permissive search
    m = re.search(r'(\{.*"participants"\s*:.*\})', blob, re.DOTALL)
    start = m.start(1) if m else -1
else:
    start = blob.rfind('{', 0, m.start()+1)

obj = None
if start >= 0:
    depth = 0
    end = -1
    for i,ch in enumerate(blob[start:], start):
        if ch == '{':
            depth += 1
        elif ch == '}':
            depth -= 1
            if depth == 0:
                end = i+1
                break
    if end > start:
        chunk = blob[start:end]
        # Remove trailing log ornaments if any
        # Try a few parses
        for candidate in [chunk, chunk.replace('\n',' ')]:
            try:
                obj = json.loads(candidate)
                break
            except Exception:
                pass

# If we couldn't parse, bail quietly
if not obj:
    # Write nothing; shell will handle empty
    sys.exit(0)

space = obj.get("audioSpace") or obj
participants = space.get("participants") or {}

def extract_people(arr):
    people = []
    if not isinstance(arr, list):
        return people
    for a in arr:
        handle = a.get("twitter_screen_name")
        name = a.get("display_name")
        # try nested
        if not handle:
            ur = (a.get("user_results") or {}).get("result") or {}
            leg = ur.get("legacy") or {}
            handle = ur.get("screen_name") or leg.get("screen_name")
            name = name or ur.get("name") or leg.get("name")
        if handle:
            url = f"https://x.com/{handle}"
            people.append({"name": name or handle, "handle": handle, "url": url})
    # de-dup by handle, keep first
    seen = set()
    uniq = []
    for p in people:
        if p["handle"].lower() in seen: continue
        seen.add(p["handle"].lower())
        uniq.append(p)
    return uniq

admins   = extract_people(participants.get("admins") or [])
speakers = extract_people(participants.get("speakers") or [])
listeners= extract_people(participants.get("listeners") or [])

# Host/co-hosts heuristic: first admin = host, rest = co-hosts
host = admins[:1]
cohosts = admins[1:]

data = {
    "host": host,
    "cohosts": cohosts,
    "speakers": speakers,
    "listeners_sample": listeners[:50]  # avoid giant dumps
}

# Write JSON
with open(attn_json, "w") as f:
    json.dump(data, f, ensure_ascii=False, indent=2)

# Build HTML only if we have at least one person
def li(p): return f'<li><a href="{p["url"]}" target="_blank">{p["name"]} (@{p["handle"]})</a></li>'

sections = []
if host:
    sections.append("<li><strong>Host</strong><ul>" + "".join(li(p) for p in host) + "</ul></li>")
if cohosts:
    sections.append("<li><strong>Co-hosts</strong><ul>" + "".join(li(p) for p in cohosts) + "</ul></li>")
if speakers:
    sections.append("<li><strong>Speakers</strong><ul>" + "".join(li(p) for p in speakers) + "</ul></li>")

html = ""
if sections:
    html = "<ul>" + "".join(sections) + "</ul>"

if html:
    with open(attn_html, "w") as f:
        f.write(html)
PY
          # Announce outputs
          if [ -s "$ATTN_HTML" ]; then
            echo "attendees_html=$ATTN_HTML" >> "$GITHUB_OUTPUT"
            echo "ATTN_HTML=$ATTN_HTML" >> "$GITHUB_ENV"
          else
            echo "attendees_html=" >> "$GITHUB_OUTPUT"
            echo "ATTN_HTML=" >> "$GITHUB_ENV"
          fi

      - name: Upload attendees HTML (if present)
        id: upload_attendees
        shell: bash
        run: |
          set -euxo pipefail
          test -n "${ATTN_HTML:-}" && test -s "${ATTN_HTML:-}" || { echo "No attendees HTML to upload"; exit 0; }
          DEST="gs://${GCS_BUCKET}/${BUCKET_PREFIX}/${BASE}-attendees.html"
          RAW="https://storage.googleapis.com/${GCS_BUCKET}/${BUCKET_PREFIX}/${BASE}-attendees.html"
          PROXY="https://media.chbmp.org/${PREFIX}/${BASE}-attendees.html"
          gsutil cp "${ATTN_HTML}" "$DEST"
          if [ "${{ inputs.make_public }}" = "true" ]; then
            gsutil acl ch -u AllUsers:R "$DEST" || gsutil iam ch allUsers:objectViewer "gs://${GCS_BUCKET}" || true
          fi
          echo "raw_attendees_url=${RAW}"     >> "$GITHUB_OUTPUT"
          echo "proxy_attendees_url=${PROXY}" >> "$GITHUB_OUTPUT"

      - name: Patch WP with attendees (inline HTML and/or URL)
        if: ${{ env.WP_BASE_URL != '' && env.WP_USER != '' && env.WP_APP_PASSWORD != '' && inputs.post_id != '' }}
        shell: bash
        env:
          AHTML: ${{ steps.attendees.outputs.attendees_html }}
          AURL:  ${{ steps.upload_attendees.outputs.proxy_attendees_url }}
        run: |
          set -euo pipefail
          BODY="$(jq -n --arg pid "${{ inputs.post_id }}" --arg attendees_html "$AHTML" --arg attendees_url "$AURL" '
            { post_id: ($pid|tonumber), status:"processing", progress:85 }
            + (if ($attendees_html|length)>0 then { attendees_html:$attendees_html } else {} end)
            + (if ($attendees_url|length)>0  then { artifacts: { attendees_html_url:$attendees_url } } else {} end)
          ')"
          curl -sS -u "${WP_USER}:${WP_APP_PASSWORD}" -H "Content-Type: application/json" \
            -X POST "${WP_BASE_URL%/}/wp-json/ss3k/v1/patch-assets" -d "${BODY}"

      # -------------------- AUDIO / TRANSCRIPT PIPELINE (full mode only) --------------------
      - name: Fallback download (yt-dlp) if crawler produced no audio
        if: ${{ inputs.mode == '' && (steps.crawl.outputs.audio_file == '' || steps.crawl.outcome != 'success') }}
        shell: bash
        working-directory: ${{ env.WORKDIR }}
        env: { URL: ${{ inputs.space_url }} }
        run: |
          set -euxo pipefail
          yt-dlp -o "%(title)s.%(ext)s" -f "bestaudio/best" "$URL"
          IN="$(ls -S | head -n1 || true)"
          test -f "$IN" || { echo "No file downloaded"; exit 1; }
          echo "INPUT_FILE=$PWD/$IN" >> "$GITHUB_ENV"

      - name: Trim head/tail silence (prep)
        if: ${{ inputs.mode == '' && env.INPUT_FILE != '' }}
        shell: bash
        run: |
          set -euxo pipefail
          TRIM_WAV="${WORKDIR}/trimmed_${{ github.run_id }}.wav"
          ffmpeg -hide_banner -y -i "$INPUT_FILE" \
            -af "silenceremove=start_periods=1:start_silence=1:start_threshold=-45dB:detection=peak,areverse,silenceremove=start_periods=1:start_silence=1:start_threshold=-45dB:detection=peak,areverse" \
            -ar 48000 -ac 2 -c:a pcm_s16le "$TRIM_WAV"
          echo "AUDIO_IN=${TRIM_WAV}" >> "$GITHUB_ENV"

      - name: Loudness normalize → MP3
        if: ${{ inputs.mode == '' && env.AUDIO_IN != '' }}
        shell: bash
        run: |
          set -euxo pipefail
          PASS1_JSON="${WORKDIR}/loudnorm_pass1_${{ github.run_id }}.json"
          ffmpeg -hide_banner -y -i "$AUDIO_IN" -af loudnorm=I=-16:TP=-1.5:LRA=11:print_format=json -f null - 2>"${WORKDIR}/pass1.log" || true
          awk '/^{/{f=1} f{print} /}/{f=0}' "${WORKDIR}/pass1.log" > "$PASS1_JSON" || true
          ILOG="$(cat "$PASS1_JSON" 2>/dev/null || echo '{}')"
          I_VAL="$(jq -r '.input_i // "-16"' <<<"$ILOG")"
          TP_VAL="$(jq -r '.input_tp // "-1.5"' <<<"$ILOG")"
          LRA_VAL="$(jq -r '.input_lra // "11"' <<<"$ILOG")"
          ffmpeg -hide_banner -y -i "$AUDIO_IN" \
            -af "loudnorm=I=-16:TP=-1.5:LRA=11:measured_I=${I_VAL}:measured_TP=${TP_VAL}:measured_LRA=${LRA_VAL}:linear=true:print_format=summary" \
            -ar 48000 -ac 2 -codec:a libmp3lame -b:a 192k "${ARTDIR}/${BASE}.mp3"
          echo "MP3_PATH=${ARTDIR}/${BASE}.mp3" >> "$GITHUB_ENV"

      - name: Upload MP3 to GCS
        if: ${{ inputs.mode == '' && env.MP3_PATH != '' }}
        shell: bash
        run: |
          set -euxo pipefail
          DEST="gs://${GCS_BUCKET}/${BUCKET_PREFIX}/${BASE}.mp3"
          RAW="https://storage.googleapis.com/${GCS_BUCKET}/${BUCKET_PREFIX}/${BASE}.mp3"
          PROXY="https://media.chbmp.org/${PREFIX}/${BASE}.mp3"
          gsutil cp "${MP3_PATH}" "$DEST"
          if [ "${{ inputs.make_public }}" = "true" ]; then
            gsutil acl ch -u AllUsers:R "$DEST" || gsutil iam ch allUsers:objectViewer "gs://${GCS_BUCKET}" || true
          fi
          echo "audio_raw=${RAW}"     >> "$GITHUB_OUTPUT"
          echo "audio_proxy=${PROXY}" >> "$GITHUB_OUTPUT"

      - name: Upload VTT (if crawler captions)
        if: ${{ inputs.mode == '' && env.VTT_PATH != '' }}
        shell: bash
        run: |
          set -euxo pipefail
          DEST="gs://${GCS_BUCKET}/${BUCKET_PREFIX}/${BASE}.vtt"
          RAW="https://storage.googleapis.com/${GCS_BUCKET}/${BUCKET_PREFIX}/${BASE}.vtt"
          PROXY="https://media.chbmp.org/${PREFIX}/${BASE}.vtt"
          gsutil cp "${VTT_PATH}" "$DEST"
          if [ "${{ inputs.make_public }}" = "true" ]; then
            gsutil acl ch -u AllUsers:R "$DEST" || gsutil iam ch allUsers:objectViewer "gs://${GCS_BUCKET}" || true
          fi
          echo "vtt_raw=${RAW}"     >> "$GITHUB_OUTPUT"
          echo "vtt_proxy=${PROXY}" >> "$GITHUB_OUTPUT"

      - name: Patch WP (final assets & state)
        if: ${{ env.WP_BASE_URL != '' && env.WP_USER != '' && env.WP_APP_PASSWORD != '' && inputs.post_id != '' }}
        shell: bash
        env:
          AURL: ${{ steps.upload_attendees.outputs.proxy_attendees_url }}
          MP3:  ${{ steps.upload_attendees.outcome && steps.upload_attendees.outputs.nothing == 'nope' && steps.upload_attendees.outputs.nothing || '' }}
        run: |
          set -euo pipefail
          # Build artifacts object from any known URLs
          ART='{}'
          [ -n "${{ steps.upload_attendees.outputs.proxy_attendees_url }}" ] && ART="$(jq -n --arg u "${{ steps.upload_attendees.outputs.proxy_attendees_url }}" '{attendees_html_url:$u}')" || true
          [ -n "${{ steps.upload_attendees.outputs.raw_attendees_url }}" ] && ART="$(jq -n --arg u "${{ steps.upload_attendees.outputs.raw_attendees_url }}" --argjson prev "${ART}" '$prev + {attendees_html_url_raw:$u}')" || true
          [ -n "${{ steps.Upload_MP3.outputs.audio_proxy || '' }}" ] && ART="$(jq -n --arg u "${{ steps.Upload_MP3.outputs.audio_proxy }}" --argjson prev "${ART}" '$prev + {audio_url:$u}')" || true
          [ -n "${{ steps.Upload_MP3.outputs.audio_raw || '' }}" ] && ART="$(jq -n --arg u "${{ steps.Upload_MP3.outputs.audio_raw }}" --argjson prev "${ART}" '$prev + {audio_url_raw:$u}')" || true
          [ -n "${{ steps.Upload_VTT.outputs.vtt_proxy || '' }}" ] && ART="$(jq -n --arg u "${{ steps.Upload_VTT.outputs.vtt_proxy }}" --argjson prev "${ART}" '$prev + {vtt_url:$u}')" || true
          [ -n "${{ steps.Upload_VTT.outputs.vtt_raw || '' }}" ] && ART="$(jq -n --arg u "${{ steps.Upload_VTT.outputs.vtt_raw }}" --argjson prev "${ART}" '$prev + {vtt_url_raw:$u}')" || true

          BODY="$(jq -n --arg pid "${{ inputs.post_id }}" --argjson artifacts "${ART}" '
            { post_id: ($pid|tonumber), status:"complete", progress:100 }
            + (if ($artifacts|length)>0 then {artifacts:$artifacts} else {} end)
          ')"
          curl -sS -u "${WP_USER}:${WP_APP_PASSWORD}" -H "Content-Type: application/json" \
            -X POST "${WP_BASE_URL%/}/wp-json/ss3k/v1/patch-assets" -d "${BODY}"

      - name: Job summary
        shell: bash
        run: |
          {
            echo "### Space Worker Summary"
            echo "- Space URL: ${{ inputs.space_url }}"
            echo "- Space ID:  ${{ steps.ids.outputs.space_id }}"
            echo "- Prefix:    ${{ env.PREFIX }}"
            echo "- Crawler preflight OK: ${{ steps.x_preflight.outputs.ok == '1' && 'yes' || 'no' }} (reason ${{ steps.x_preflight.outputs.reason }})"
            if [ -n "${ATTN_HTML:-}" ]; then
              echo "- Attendees: extracted and uploaded"
            else
              echo "- Attendees: not found"
            fi
            if [ -n "${VTT_PATH:-}" ]; then
              echo "- Captions: crawler VTT"
            fi
            if [ -n "${MP3_PATH:-}" ]; then
              echo "- Audio: encoded MP3"
            elif [ -n "${INPUT_FILE:-}" ]; then
              echo "- Audio: source present"
            else
              echo "- Audio: none"
            fi
            echo "- Mode: ${{ inputs.mode }}"
          } >> "$GITHUB_STEP_SUMMARY"
