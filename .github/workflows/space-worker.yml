name: Space Worker

on:
  workflow_dispatch:
    inputs:
      space_url:
        description: X or Twitter Space URL
        required: false
        type: string
        default: ""
      post_id:
        description: Existing WordPress post ID (optional)
        required: false
        type: string
        default: ""
      gcs_prefix:
        description: GCS prefix (default spaces/YYYY/MM)
        required: false
        type: string
        default: ""
      make_public:
        description: Make uploaded artifacts public
        required: false
        type: choice
        options: ["true","false"]
        default: "true"
      do_transcript:
        description: Generate transcript when captions are not available
        required: false
        type: choice
        options: ["true","false"]
        default: "true"
      mode:
        description: Limit processing
        required: false
        type: choice
        options: ["","transcript_only","attendees_only","replies_only"]
        default: ""
      existing_mp3_url:
        description: For transcript_only provide URL to existing MP3
        required: false
        type: string
        default: ""
      aggressive_denoise:
        description: Use RNNoise arnndn denoiser
        required: false
        type: choice
        options: ["false","true"]
        default: "false"
      purple_tweet_url:
        description: Purple pill tweet URL (optional)
        required: false
        type: string
        default: ""
      audio_profile:
        description: Audio profile for encode (default 'radio')
        required: false
        type: choice
        options: ["transparent","radio","aggressive"]
        default: "radio"

permissions:
  contents: read
  packages: read

env:
  GCP_SA_KEY:       ${{ secrets.GCP_SA_KEY       || vars.GCP_SA_KEY }}
  GCS_BUCKET:       ${{ secrets.GCS_BUCKET       || vars.GCS_BUCKET }}
  WP_BASE_URL:      ${{ secrets.WP_BASE_URL      || secrets.WP_URL || vars.WP_BASE_URL || vars.WP_URL }}
  WP_USER:          ${{ secrets.WP_USER          || vars.WP_USER }}
  WP_APP_PASSWORD:  ${{ secrets.WP_APP_PASSWORD  || vars.WP_APP_PASSWORD }}
  DEEPGRAM_API_KEY: ${{ secrets.DEEPGRAM_API_KEY || vars.DEEPGRAM_API_KEY }}

  # X/Twitter auth
  TWITTER_AUTHORIZATION: ${{ secrets.TWITTER_AUTHORIZATION || secrets.X_BEARER     || vars.TWITTER_AUTHORIZATION || vars.X_BEARER }}
  TWITTER_AUTH_TOKEN:    ${{ secrets.TWITTER_AUTH_TOKEN    || secrets.X_AUTH_TOKEN || vars.TWITTER_AUTH_TOKEN    || vars.X_AUTH_TOKEN }}
  TWITTER_CSRF_TOKEN:    ${{ secrets.TWITTER_CSRF_TOKEN    || secrets.X_CSRF       || vars.TWITTER_CSRF_TOKEN    || vars.X_CSRF }}

  # Legacy (compat)
  TW_API_CONSUMER_KEY:        ${{ secrets.TW_API_CONSUMER_KEY        || vars.TW_API_CONSUMER_KEY }}
  TW_API_CONSUMER_SECRET:     ${{ secrets.TW_API_CONSUMER_SECRET     || vars.TW_API_CONSUMER_SECRET }}
  TW_API_ACCESS_TOKEN:        ${{ secrets.TW_API_ACCESS_TOKEN        || vars.TW_API_ACCESS_TOKEN }}
  TW_API_ACCESS_TOKEN_SECRET: ${{ secrets.TW_API_ACCESS_TOKEN_SECRET || vars.TW_API_ACCESS_TOKEN_SECRET }}

  WORKDIR: ${{ github.workspace }}/work
  ARTDIR:  ${{ github.workspace }}/out

jobs:
  process:
    name: Process Space
    runs-on: ubuntu-latest
    timeout-minutes: 180
    concurrency:
      group: ${{ format('space-worker-{0}-{1}', github.ref, github.event.inputs.post_id != '' && github.event.inputs.post_id || github.run_id) }}
      cancel-in-progress: false

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Export basic inputs to env
        shell: bash
        run: |
          echo "PURPLE_TWEET_URL=${{ github.event.inputs.purple_tweet_url }}" >> "$GITHUB_ENV"
          echo "SOURCE_KIND=" >> "$GITHUB_ENV"
          echo "SOURCE_URL="  >> "$GITHUB_ENV"

      - name: Notify WP queued
        if: ${{ env.WP_BASE_URL != '' && env.WP_USER != '' && env.WP_APP_PASSWORD != '' && github.event.inputs.post_id != '' && github.event.inputs.mode != 'replies_only' }}
        shell: bash
        run: |
          set -euo pipefail
          curl -sS -u "${WP_USER}:${WP_APP_PASSWORD}" \
            -H "Content-Type: application/json" \
            -X POST "${WP_BASE_URL%/}/wp-json/ss3k/v1/worker-status" \
            -d "$(jq -n --arg pid "${{ github.event.inputs.post_id }}" \
                       --arg status "queued" \
                       --arg msg "Workflow received and queued" \
                       --arg run "${{ github.run_id }}" \
                       --argjson progress 1 \
                       '{post_id: ($pid|tonumber), status:$status, message:$msg, run_id:$run, progress:$progress}')"

      - name: Install deps
        shell: bash
        run: |
          set -euxo pipefail
          sudo apt-get update
          sudo apt-get install -y --no-install-recommends ffmpeg jq python3 python3-pip ca-certificates gnupg
          python3 -m pip install --upgrade pip
          python3 -m pip install --no-cache-dir yt-dlp tldextract
          echo "deb [signed-by=/usr/share/keyrings/cloud.google.gpg] http://packages.cloud.google.com/apt cloud-sdk main" | sudo tee /etc/apt/sources.list.d/google-cloud-sdk.list
          curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo gpg --dearmor -o /usr/share/keyrings/cloud.google.gpg
          sudo apt-get update && sudo apt-get install -y google-cloud-sdk
          echo "${{ github.token }}" | docker login ghcr.io -u "${{ github.actor }}" --password-stdin || true

      - name: Validate config and prefixes
        id: cfg
        shell: bash
        run: |
          set -euxo pipefail
          test -n "${GCP_SA_KEY}" || { echo "GCP_SA_KEY missing"; exit 1; }
          test -n "${GCS_BUCKET}" || { echo "GCS_BUCKET missing"; exit 1; }
          mkdir -p "$WORKDIR" "$ARTDIR" "$ARTDIR/logs" ".github/workflows/scripts"
          PFX="$(echo "${{ github.event.inputs.gcs_prefix }}" | sed -E 's#^/*##; s#/*$##')"
          if [ -z "$PFX" ]; then PFX="spaces/$(date +%Y)/$(date +%m)"; fi
          echo "PREFIX=$PFX"                  >> "$GITHUB_ENV"
          echo "BUCKET_PREFIX=${PFX#spaces/}" >> "$GITHUB_ENV"

      - name: Derive Space ID and base
        id: ids
        shell: bash
        env:
          URL: ${{ github.event.inputs.space_url }}
        run: |
          set -euxo pipefail
          SID=""
          if [ -n "$URL" ]; then
            SID="$(echo "$URL" | sed -nE 's#^.*/i/spaces/([^/?#]+).*#\1#p')"
          fi
          [ -z "$SID" ] && SID="unknown"
          BASE="space-$(date +%m-%d-%Y)-${SID}"
          echo "SPACE_ID=${SID}" >> "$GITHUB_ENV"
          echo "BASE=${BASE}"    >> "$GITHUB_ENV"
          echo "space_id=${SID}" >> "$GITHUB_OUTPUT"
          echo "base=${BASE}"    >> "$GITHUB_OUTPUT"

      - name: GCP auth
        if: ${{ github.event.inputs.mode != 'replies_only' }}
        shell: bash
        run: |
          set -euxo pipefail
          printf '%s' "${GCP_SA_KEY}" > "${HOME}/gcp-key.json"
          gcloud auth activate-service-account --key-file="${HOME}/gcp-key.json" >/dev/null

      - name: X preflight auth
        id: x_preflight
        if: ${{ github.event.inputs.mode != 'replies_only' }}
        shell: bash
        run: |
          set -euo pipefail
          AUTH="${TWITTER_AUTHORIZATION:-}"
          AT="${TWITTER_AUTH_TOKEN:-}"
          CT="${TWITTER_CSRF_TOKEN:-}"
          if [ -n "$AUTH" ] && ! printf '%s' "$AUTH" | grep -q '^Bearer '; then AUTH=""; fi
          [ -n "${TWITTER_AUTHORIZATION:-}" ] && echo "::add-mask::${TWITTER_AUTHORIZATION}"
          [ -n "$AT" ] && echo "::add-mask::${AT}"
          [ -n "$CT" ] && echo "::add-mask::${CT}"
          OK=0; REASON="no_creds"
          [ -n "$AT" ] && [ -n "$CT" ] && OK=1 && REASON="cookie_ok" || true
          [ -n "$AUTH" ] && OK=1 && REASON="${REASON}_bearer_present" || true
          echo "ok=${OK}"         >> "$GITHUB_OUTPUT"
          echo "reason=${REASON}" >> "$GITHUB_OUTPUT"
          [ -n "$AUTH" ] && echo "TWITTER_AUTHORIZATION=$AUTH" >> "$GITHUB_ENV"

      - name: Run crawler
        id: crawl
        if: ${{ github.event.inputs.mode != 'replies_only' && steps.x_preflight.outputs.ok == '1' }}
        shell: bash
        env:
          SID: ${{ steps.ids.outputs.space_id }}
        run: |
          set -euxo pipefail
          mkdir -p "${ARTDIR}" "${ARTDIR}/logs"
          docker pull ghcr.io/hitomarukonpaku/twspace-crawler:latest || true
          LOG_STD="${ARTDIR}/logs/crawler_${SID}.out.log"
          LOG_ERR="${ARTDIR}/logs/crawler_${SID}.err.log"
          set +e
          timeout 20m docker run --rm \
            -e TWITTER_AUTHORIZATION \
            -e TWITTER_AUTH_TOKEN \
            -e TWITTER_CSRF_TOKEN \
            -v "${ARTDIR}:/app/download" \
            -v "${ARTDIR}/logs:/app/logs" \
            ghcr.io/hitomarukonpaku/twspace-crawler:latest \
            --id "${SID}" --force > >(tee -a "$LOG_STD") 2> >(tee -a "$LOG_ERR" >&2)
          RC=$?
          set -e
          echo "crawler_exit=${RC}"
          AUDIO_FILE="$(find "${ARTDIR}" -type f \( -iname '*.m4a' -o -iname '*.mp3' -o -iname '*.mp4' -o -iname '*.aac' -o -iname '*.webm' -o -iname '*.ogg' -o -iname '*.wav' -o -iname '*.ts' \) -printf '%T@ %p\n' | sort -nr | head -n1 | cut -d' ' -f2- || true)"
          if [ -n "${AUDIO_FILE:-}" ] && [ -f "${AUDIO_FILE}" ]; then
            echo "INPUT_FILE=${AUDIO_FILE}" >> "$GITHUB_ENV"
            echo "audio_file=${AUDIO_FILE}" >> "$GITHUB_OUTPUT"
            echo "SOURCE_KIND=crawler" >> "$GITHUB_ENV"
            echo "SOURCE_URL=${{ github.event.inputs.space_url }}" >> "$GITHUB_ENV"
          fi
          RAW="$(grep -hF 'getAudioSpaceById |' "$LOG_STD" "$LOG_ERR" | tail -n1 || true)"
          if [ -z "$RAW" ]; then
            RAW="$(grep -hF 'getAudioSpaceByRestId |' "$LOG_STD" "$LOG_ERR" | tail -n1 || true)"
          fi
          if [ -n "$RAW" ]; then
            printf '%s\n' "$RAW" | awk -F'\\| ' '{print $NF}' > "${ARTDIR}/_as_line.json" || true
          fi
          [ -s "${ARTDIR}/_as_line.json" ] && echo "as_line=${ARTDIR}/_as_line.json" >> "$GITHUB_OUTPUT" || true
          CC_JSONL="$(find "${ARTDIR}" -type f \( -iname '*cc.jsonl' -o -iname '*caption*.jsonl' -o -iname '*captions*.jsonl' \) -print | head -n1 || true)"
          if [ -n "${CC_JSONL:-}" ]; then
            echo "CRAWLER_CC=${CC_JSONL}" >> "$GITHUB_ENV"
          fi

      - name: Fallback download via yt-dlp
        if: ${{ github.event.inputs.mode != 'attendees_only' && github.event.inputs.mode != 'replies_only' && (steps.crawl.outputs.audio_file == '' || steps.crawl.outcome != 'success') && github.event.inputs.existing_mp3_url == '' && github.event.inputs.space_url != '' }}
        shell: bash
        working-directory: ${{ env.WORKDIR }}
        env:
          URL: ${{ github.event.inputs.space_url }}
        run: |
          set -euxo pipefail
          yt-dlp -o "%(title)s.%(ext)s" -f "bestaudio/best" "$URL"
          IN="$(ls -S | head -n1 || true)"
          test -f "$IN" || { echo "No file downloaded"; exit 1; }
          echo "INPUT_FILE=$PWD/$IN" >> "$GITHUB_ENV"
          echo "SOURCE_KIND=yt-dlp"  >> "$GITHUB_ENV"
          echo "SOURCE_URL=${URL}"   >> "$GITHUB_ENV"

      - name: Use provided MP3 for transcript_only
        if: ${{ github.event.inputs.mode == 'transcript_only' && github.event.inputs.existing_mp3_url != '' }}
        shell: bash
        run: |
          set -euxo pipefail
          curl -L "${{ github.event.inputs.existing_mp3_url }}" -o "${ARTDIR}/${BASE}.mp3"
          echo "INPUT_FILE=${ARTDIR}/${BASE}.mp3" >> "$GITHUB_ENV"
          echo "SOURCE_KIND=existing_mp3"         >> "$GITHUB_ENV"
          echo "SOURCE_URL=${{ github.event.inputs.existing_mp3_url }}" >> "$GITHUB_ENV"

      - name: Detect lead silence seconds
        id: detect
        if: ${{ github.event.inputs.mode != 'attendees_only' && github.event.inputs.mode != 'replies_only' && env.INPUT_FILE != '' }}
        shell: bash
        run: |
          set -euxo pipefail
          LOG="${WORKDIR}/silence.log"
          ffmpeg -hide_banner -i "$INPUT_FILE" -af "silencedetect=noise=-45dB:d=1" -f null - 2> "$LOG" || true
          LEAD="$(awk '/silence_end/ {print $5; exit}' "$LOG" || true)"
          case "$LEAD" in ''|*[^0-9.]* ) LEAD="0.0" ;; esac
          echo "TRIM_LEAD=${LEAD}" >> "$GITHUB_ENV"
          echo "lead=${LEAD}"       >> "$GITHUB_OUTPUT"

      - name: Trim head and tail (RF64-safe)
        if: ${{ github.event.inputs.mode != 'attendees_only' && github.event.inputs.mode != 'replies_only' && env.INPUT_FILE != '' }}
        shell: bash
        run: |
          set -euxo pipefail
          TRIM_WAV="${WORKDIR}/trim_${{ github.run_id }}.wav"
          ffmpeg -hide_banner -y -i "$INPUT_FILE" \
            -af "silenceremove=start_periods=1:start_silence=1:start_threshold=-45dB:detection=peak,areverse,silenceremove=start_periods=1:start_silence=1:start_threshold=-45dB:detection=peak,areverse" \
            -rf64 always -c:a pcm_s16le "$TRIM_WAV"
          echo "AUDIO_IN=${TRIM_WAV}" >> "$GITHUB_ENV"

      - name: Probe audio format
        id: probe
        if: ${{ github.event.inputs.mode != 'attendees_only' && github.event.inputs.mode != 'replies_only' && env.AUDIO_IN != '' }}
        shell: bash
        run: |
          set -euxo pipefail
          J="$(ffprobe -v error -select_streams a:0 -show_entries stream=channels,sample_rate -of json "$AUDIO_IN")"
          CH=$(echo "$J" | jq -r '.streams[0].channels // 1')
          SR=$(echo "$J" | jq -r '.streams[0].sample_rate // "48000"')
          echo "SRC_CH=${CH}" >> "$GITHUB_ENV"
          echo "SRC_SR=${SR}" >> "$GITHUB_ENV"

      - name: Encode MP3 with selected profile
        if: ${{ github.event.inputs.mode != 'attendees_only' && github.event.inputs.mode != 'replies_only' && env.AUDIO_IN != '' }}
        shell: bash
        env:
          PROF: ${{ github.event.inputs.audio_profile != '' && github.event.inputs.audio_profile || 'radio' }}
        run: |
          set -euxo pipefail
          OUT="${ARTDIR}/${BASE}.mp3"
          CH="${SRC_CH:-1}"
          SR="${SRC_SR:-48000}"
          if [ "${PROF}" = "transparent" ]; then
            ffmpeg -hide_banner -y -i "$AUDIO_IN" -map a:0 -c:a libmp3lame -q:a 0 -ar "$SR" -ac "$CH" "$OUT"
          elif [ "${PROF}" = "radio" ]; then
            PRE="highpass=f=60,lowpass=f=14000,afftdn=nr=4:nf=-28,deesser=i=0.12,acompressor=threshold=-18dB:ratio=2:attack=12:release=220:makeup=2"
            PASS1_JSON="${WORKDIR}/loudnorm1.json"
            ffmpeg -hide_banner -y -i "$AUDIO_IN" -af "${PRE},loudnorm=I=-16:TP=-1.5:LRA=11:print_format=json" -f null - 2>"${WORKDIR}/pass1.log" || true
            awk '/^{/{f=1} f{print} /}/{f=0}' "${WORKDIR}/pass1.log" > "$PASS1_JSON" || true
            if jq -e . "$PASS1_JSON" >/dev/null 2>&1; then
              I=$(jq -r '.input_i // "-16"'  "$PASS1_JSON")
              TP=$(jq -r '.input_tp // "-1.5"' "$PASS1_JSON")
              LRA=$(jq -r '.input_lra // "11"' "$PASS1_JSON")
              TH=$(jq -r '.input_thresh // "-26"' "$PASS1_JSON")
              ffmpeg -hide_banner -y -i "$AUDIO_IN" \
                -af "${PRE},loudnorm=I=-16:TP=-1.5:LRA=11:measured_I=$I:measured_TP=$TP:measured_LRA=$LRA:measured_thresh=$TH:linear=true" \
                -c:a libmp3lame -q:a 2 -ar "$SR" -ac "$CH" "$OUT"
            else
              ffmpeg -hide_banner -y -i "$AUDIO_IN" \
                -af "${PRE},loudnorm=I=-16:TP=-1.5:LRA=11" \
                -c:a libmp3lame -q:a 2 -ar "$SR" -ac "$CH" "$OUT"
            fi
          else
            PRE="highpass=f=70,lowpass=f=11500,afftdn=nr=8:nf=-25,deesser=i=0.2,acompressor=threshold=-18dB:ratio=2.8:attack=8:release=200:makeup=3"
            if [ "${{ github.event.inputs.aggressive_denoise }}" = "true" ]; then
              M="${WORKDIR}/rnnoise.rnnn"
              curl -fsSL -o "$M" https://raw.githubusercontent.com/GregorR/rnnoise-models/master/heavyrnnoise.rnnn || true
              if [ -s "$M" ]; then PRE="arnndn=m=${M},${PRE}"; fi
            fi
            PASS1_JSON="${WORKDIR}/loudnorm1.json"
            ffmpeg -hide_banner -y -i "$AUDIO_IN" -af "${PRE},loudnorm=I=-16:TP=-1.5:LRA=11:print_format=json" -f null - 2>"${WORKDIR}/pass1.log" || true
            awk '/^{/{f=1} f{print} /}/{f=0}' "${WORKDIR}/pass1.log" > "$PASS1_JSON" || true
            if jq -e . "$PASS1_JSON" >/dev/null 2>&1; then
              I=$(jq -r '.input_i // "-16"'  "$PASS1_JSON")
              TP=$(jq -r '.input_tp // "-1.5"' "$PASS1_JSON")
              LRA=$(jq -r '.input_lra // "11"' "$PASS1_JSON")
              TH=$(jq -r '.input_thresh // "-26"' "$PASS1_JSON")
              ffmpeg -hide_banner -y -i "$AUDIO_IN" \
                -af "${PRE},loudnorm=I=-16:TP=-1.5:LRA=11:measured_I=$I:measured_TP=$TP:measured_LRA=$LRA:measured_thresh=$TH:linear=true" \
                -c:a libmp3lame -q:a 2 -ar "$SR" -ac "$CH" "$OUT"
            else
              ffmpeg -hide_banner -y -i "$AUDIO_IN" -af "${PRE},loudnorm=I=-16:TP=-1.5:LRA=11" \
                -c:a libmp3lame -q:a 2 -ar "$SR" -ac "$CH" "$OUT"
            fi
          fi
          echo "MP3_PATH=${OUT}" >> "$GITHUB_ENV"

      - name: Upload MP3 to GCS
        id: upload_mp3
        if: ${{ github.event.inputs.mode != 'attendees_only' && github.event.inputs.mode != 'replies_only' && env.MP3_PATH != '' }}
        shell: bash
        run: |
          set -euxo pipefail
          DEST="gs://${GCS_BUCKET}/${BUCKET_PREFIX}/${BASE}.mp3"
          RAW="https://storage.googleapis.com/${GCS_BUCKET}/${BUCKET_PREFIX}/${BASE}.mp3"
          PROXY="https://media.chbmp.org/${PREFIX}/${BASE}.mp3"
          gsutil -m cp "${MP3_PATH}" "$DEST"
          if [ "${{ github.event.inputs.make_public }}" = "true" ]; then
            (gsutil acl ch -u AllUsers:R "$DEST" || gsutil iam ch allUsers:objectViewer "gs://${GCS_BUCKET}") || true
          fi
          echo "audio_raw=${RAW}"     >> "$GITHUB_OUTPUT"
          echo "audio_proxy=${PROXY}" >> "$GITHUB_OUTPUT"

      - name: Write helper scripts (gen_vtt, polish, replies)
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p ".github/workflows/scripts"

          # -------- gen_vtt.py --------
          cat > ".github/workflows/scripts/gen_vtt.py" << 'PY'
          #!/usr/bin/env python3
          import json, os, re, html, sys
          from datetime import datetime, timezone

          artdir = os.environ.get("ARTDIR") or ""
          base   = os.environ.get("BASE") or ""
          src    = os.environ.get("CC_JSONL") or ""
          shift  = float(os.environ.get("SHIFT_SECS") or "0")

          if not (artdir and base and src and os.path.isfile(src)):
              os.makedirs(artdir, exist_ok=True)
              open(os.path.join(artdir,f"{base}.vtt"),"w",encoding="utf-8").write("WEBVTT\n\n")
              open(os.path.join(artdir,f"{base}_transcript.html"),"w",encoding="utf-8").write("")
              open(os.path.join(artdir,f"{base}_reactions.json"),"w",encoding="utf-8").write("[]")
              open(os.path.join(artdir,f"{base}.start.txt"),"w",encoding="utf-8").write("")
              sys.exit(0)

          EMOJI_RE = re.compile("[" +
              "\U0001F1E6-\U0001F1FF" "\U0001F300-\U0001F5FF" "\U0001F600-\U0001F64F" "\U0001F680-\U0001F6FF" +
              "\U0001F700-\U0001F77F" "\U0001F780-\U0001F7FF" "\U0001F800-\U0001F8FF" "\U0001F900-\U0001F9FF" +
              "\U0001FA00-\U0001FAFF" "\u2600-\u26FF" "\u2700-\u27BF" + "]+", re.UNICODE)
          ONLY_PUNCT_SPACE = re.compile(r"^[\s\.,;:!?\-–—'\"“”‘’•·]+$")

          def is_emoji_only(s: str) -> bool:
              if not s or not s.strip(): return False
              t = ONLY_PUNCT_SPACE.sub("", s)
              t = EMOJI_RE.sub("", t)
              return len(t.strip()) == 0

          def parse_time_iso(s):
              if not s: return None
              s=s.strip()
              try:
                  if s.endswith('Z'): s=s[:-1]+'+00:00'
                  if re.search(r'[+-]\d{4}$', s):
                      s=s[:-5]+s[-5:-2]+':'+s[-2:]
                  dt=datetime.fromisoformat(s)
                  if dt.tzinfo is None: dt=dt.replace(tzinfo=timezone.utc)
                  return dt.timestamp()
              except: return None

          def to_float_seconds(x):
              try:
                  if x is None: return None
                  f=float(x)
                  return f/1000.0 if f>4_000_000 else f
              except: return None

          def first(*vals):
              for v in vals:
                  if v not in (None,""): return v
              return None

          def esc(s): return (s or "").replace("&","&amp;").replace("<","&lt;").replace(">","&gt;")

          REL_KEYS  = ("offset","startSec","startMs","start")
          ABS_KEYS  = ("timestamp","programDateTime","ts")

          raw_items=[]
          reactions=[]
          abs_candidates=[]

          with open(src,'r',encoding='utf-8',errors='ignore') as f:
              for line in f:
                  line=line.strip()
                  if not line: continue
                  try:
                      obj=json.loads(line)
                  except:
                      continue

                  layer=None; sender={}
                  if isinstance(obj,dict) and isinstance(obj.get("payload"),str):
                      try:
                          pl=json.loads(obj["payload"])
                          if isinstance(pl,dict) and isinstance(pl.get("body"),str):
                              try:
                                  layer=json.loads(pl["body"])
                                  sender=pl.get("sender") or {}
                              except: layer=None
                      except: pass
                  else:
                      layer=obj

                  def push_item(rel_ts, abs_ts, txt, disp, uname, avatar):
                      if not txt: return
                      if is_emoji_only(txt):
                          if abs_ts is not None or rel_ts is not None:
                              reactions.append({
                                  "t_abs": abs_ts,
                                  "t_rel": rel_ts,
                                  "emoji": txt,
                                  "name":  (disp or uname or "") or "",
                                  "handle": (uname or "").lstrip("@"),
                                  "avatar": avatar or ""
                              })
                          return
                      raw_items.append({
                          "rel": rel_ts, "abs": abs_ts,
                          "text": txt,
                          "name": (disp or uname or "Speaker"),
                          "username": (uname or "").lstrip("@"),
                          "avatar": avatar or ""
                      })
                      if abs_ts is not None:
                          abs_candidates.append(abs_ts)

                  def pick_rel_abs(d):
                      rel=None
                      for k in REL_KEYS:
                          if k in d and d[k] not in (None,""):
                              rel = to_float_seconds(d[k])
                              if rel is not None: break
                      abs_ts=None
                      for k in ABS_KEYS:
                          if k in d and d[k] not in (None,""):
                              if k=="programDateTime":
                                  abs_ts = parse_time_iso(d[k]); 
                              else:
                                  abs_ts = to_float_seconds(d[k])
                              if abs_ts is not None: break
                      return rel, abs_ts

                  candidates=[]
                  if isinstance(layer,dict) and layer:
                      d=layer
                      txt = first(d.get("body"), d.get("text"), d.get("caption"))
                      disp=first(d.get("displayName"), d.get("speaker_name"), d.get("speakerName"),
                                 (sender or {}).get("display_name"))
                      uname=first(d.get("username"), d.get("user_id"), (sender or {}).get("screen_name"))
                      avat=first((sender or {}).get("profile_image_url_https"),
                                 (sender or {}).get("profile_image_url"))
                      rel,abs_ts = pick_rel_abs(d)
                      if txt:
                          candidates.append((rel,abs_ts,txt,disp,uname,avat,None))

                  if isinstance(obj,dict):
                      txt = first(obj.get("text"), obj.get("caption"), obj.get("payloadText"))
                      disp=first(obj.get("displayName"), obj.get("speaker"), obj.get("user"), obj.get("name"))
                      uname=first(obj.get("username"), obj.get("handle"), obj.get("screen_name"))
                      avat=first(obj.get("profile_image_url_https"), obj.get("profile_image_url"))
                      rel,abs_ts = pick_rel_abs(obj)
                      if txt:
                          candidates.append((rel,abs_ts,txt,disp,uname,avat,None))

                  for (rel,abs_ts,txt,disp,uname,avat,_) in candidates:
                      if not re.search(r"[A-Za-z0-9]", txt) and not is_emoji_only(txt):
                          continue
                      push_item(rel,abs_ts,txt,disp,uname,avat)

          if not raw_items:
              os.makedirs(artdir, exist_ok=True)
              open(os.path.join(artdir,f"{base}.vtt"),"w",encoding="utf-8").write("WEBVTT\n\n")
              open(os.path.join(artdir,f"{base}_transcript.html"),"w",encoding="utf-8").write("")
              open(os.path.join(artdir,f"{base}_reactions.json"),"w",encoding="utf-8").write("[]")
              open(os.path.join(artdir,f"{base}.start.txt"),"w",encoding="utf-8").write("")
              sys.exit(0)

          abs0 = min(abs_candidates) if abs_candidates else None
          norm=[]
          for it in raw_items:
              if it["rel"] is not None:
                  t = it["rel"]
              elif it["abs"] is not None and abs0 is not None:
                  t = it["abs"] - abs0
              else:
                  t = 0.0
              t = max(0.0, t - shift)
              norm.append({ **it, "t": float(t) })

          norm.sort(key=lambda x: x["t"])
          EPS=0.0005
          last=-1e9
          for u in norm:
              if u["t"] <= last: u["t"] = last + EPS
              last = u["t"]

          def fmt_ts(t):
              if t<0: t=0.0
              h=int(t//3600); m=int((t%3600)//60); s=t%60
              return f"{h:02d}:{m:02d}:{s:06.3f}"

          MERGE_GAP=3.0
          groups=[]; cur=None
          for u in norm:
              if cur and u["username"]==cur["username"] and u["name"]==cur["name"] and (u["t"]-cur["end"])<=MERGE_GAP:
                  sep = "" if re.search(r'[.!?]"?$', cur["text"]) else " "
                  cur["text"]=(cur["text"]+sep+u["text"]).strip()
                  cur["end"]=max(cur["end"], u["t"]+0.8)
              else:
                  cur={"name":u["name"],"username":u["username"],"avatar":u["avatar"],
                       "start":u["t"],"end":u["t"]+0.8,"text":u["text"]}
                  groups.append(cur)

          MIN_DUR=0.80; MAX_DUR=10.0; GUARD=0.020
          for i,g in enumerate(groups):
              if i+1<len(groups):
                  nxt=groups[i+1]["start"]
                  dur=max(MIN_DUR, min(MAX_DUR, (nxt-g["start"])-GUARD))
                  g["end"]=g["start"]+dur
              else:
                  words=max(1, len(g["text"].split()))
                  dur=max(MIN_DUR, min(MAX_DUR, 0.33*words+0.7))
                  g["end"]=g["start"]+dur

          os.makedirs(artdir, exist_ok=True)
          with open(os.path.join(artdir,f"{base}.vtt"),"w",encoding="utf-8") as vf:
              vf.write("WEBVTT\n\n")
              for i,g in enumerate(groups,1):
                  vf.write(f"{i}\n{fmt_ts(g['start'])} --> {fmt_ts(g['end'])}\n")
                  vf.write(f"<v {esc(g['name'])}> {esc(g['text'])}\n\n")

          css='''
          <style>
          .ss3k-transcript{font:15px/1.5 system-ui,-apple-system,Segoe UI,Roboto,Arial,sans-serif;
            max-height:70vh; overflow-y:auto; scroll-behavior:smooth; border:1px solid #e5e7eb; border-radius:12px; padding:6px}
          .ss3k-seg{display:flex;gap:10px;padding:8px 10px;border-radius:10px;margin:6px 0}
          .ss3k-seg.active{background:#eef6ff;outline:1px solid #bfdbfe}
          .ss3k-avatar{width:26px;height:26px;border-radius:50%;flex:0 0 26px;margin-top:3px;background:#e5e7eb}
          .ss3k-meta{font-size:12px;color:#64748b;margin-bottom:2px}
          .ss3k-name a{color:#0f172a;text-decoration:none}
          .ss3k-text{white-space:pre-wrap;word-break:break-word;cursor:pointer}
          </style>
          '''
          js='''
          <script>
          (function(){
            function time(s){return parseFloat(s||'0')||0}
            function within(t,seg){return t>=time(seg.dataset.start) && t<time(seg.dataset.end)}
            function bind(){
              var audio=document.getElementById('ss3k-audio')||document.querySelector('audio[data-ss3k-player]');
              var cont=document.querySelector('.ss3k-transcript'); if(!audio||!cont) return;
              var segs=[].slice.call(cont.querySelectorAll('.ss3k-seg'));
              function tick(){
                var t=audio.currentTime||0, found=null;
                for(var i=0;i<segs.length;i++){ if(within(t,segs[i])){found=segs[i];break;} }
                segs.forEach(function(s){ s.classList.toggle('active', s===found); });
                if(found){
                  var top = found.offsetTop - cont.offsetTop;
                  if (Math.abs(cont.scrollTop - top) > 6) cont.scrollTop = top;
                }
              }
              audio.addEventListener('timeupdate', tick);
              audio.addEventListener('seeked', tick);
              segs.forEach(function(s){
                s.addEventListener('click', function(){
                  audio.currentTime = time(s.dataset.start)+0.05; audio.play && audio.play().catch(function(){});
                });
              });
              tick();
            }
            if(document.readyState!=="loading") bind(); else document.addEventListener('DOMContentLoaded', bind);
          })();
          </script>
          '''
          with open(os.path.join(artdir,f"{base}_transcript.html"),"w",encoding="utf-8") as tf:
              tf.write(css); tf.write('<div class="ss3k-transcript">\\n')
              for i,g in enumerate(groups,1):
                  uname=(g["username"] or "").lstrip("@")
                  prof=f"https://x.com/{html.escape(uname, True)}" if uname else ""
                  avatar=g.get("avatar") or (f"https://unavatar.io/x/{html.escape(uname, True)}" if uname else "")
                  if avatar and prof:
                      avtag=f'<a href="{prof}" target="_blank" rel="noopener"><img class="ss3k-avatar" src="{html.escape(avatar, True)}" alt=""></a>'
                  elif avatar:
                      avtag=f'<img class="ss3k-avatar" src="{html.escape(avatar, True)}" alt="">'
                  else:
                      avtag='<div class="ss3k-avatar" aria-hidden="true"></div>'
                  name_html = f'<span class="ss3k-name"><strong>{html.escape(g["name"], True)}</strong></span>'
                  if prof:
                      name_html = f'<span class="ss3k-name"><a href="{prof}" target="_blank" rel="noopener"><strong>{html.escape(g["name"], True)}</strong></a></span>'
                  tf.write(f'<div class="ss3k-seg" id="seg-{i:04d}" data-start="{g["start"]:.3f}" data-end="{g["end"]:.3f}"')
                  if uname: tf.write(f' data-handle="@{html.escape(uname, True)}"')
                  tf.write('>')
                  tf.write(avtag)
                  tf.write('<div class="ss3k-body">')
                  tf.write(f'<div class="ss3k-meta">{name_html} · <time>{fmt_ts(g["start"])}</time>–<time>{fmt_ts(g["end"])}</time></div>')
                  tf.write(f'<div class="ss3k-text">{html.escape(g["text"], True)}</div>')
                  tf.write('</div></div>\\n')
              tf.write('</div>\\n'); tf.write(js)

          rx=[]
          if reactions:
              for r in reactions:
                  if r["t_rel"] is not None:
                      t=r["t_rel"]
                  elif r["t_abs"] is not None and abs0 is not None:
                      t=r["t_abs"]-abs0
                  else:
                      continue
                  t=max(0.0, t - shift)
                  rx.append({
                      "t": round(t,3),
                      "emoji": r["emoji"],
                      "name": r["name"],
                      "handle": r["handle"],
                      "avatar": r["avatar"]
                  })
          with open(os.path.join(artdir,f"{base}_reactions.json"),"w",encoding="utf-8") as rf:
              json.dump(rx, rf, ensure_ascii=False)

          start_iso=""
          if abs_candidates:
              start_iso = datetime.fromtimestamp(min(abs_candidates), timezone.utc).isoformat(timespec='seconds').replace('+00:00','Z')
          with open(os.path.join(artdir,f"{base}.start.txt"),"w",encoding="utf-8") as sf:
              sf.write((start_iso or "") + "\\n")
          PY
          chmod +x ".github/workflows/scripts/gen_vtt.py"

          # -------- polish_transcript.py --------
          cat > ".github/workflows/scripts/polish_transcript.py" << 'PY'
          #!/usr/bin/env python3
          # Polishes the HTML transcript ONLY (preserves speakers/timestamps).
          import os, re, html
          ARTDIR = os.environ.get("ARTDIR",".")
          BASE   = os.environ.get("BASE","space")
          INP    = os.path.join(ARTDIR, f"{BASE}_transcript.html")
          OUT    = os.path.join(ARTDIR, f"{BASE}_transcript_polished.html")
          if not os.path.exists(INP) or os.path.getsize(INP) == 0: raise SystemExit(0)
          raw_html = open(INP, "r", encoding="utf-8", errors="ignore").read()
          TEXT_NODE = re.compile(r'(<(?:div|span)\s+class="ss3k-text"[^>]*>)(.*?)(</(?:div|span)>)', re.S | re.I)
          EMOJI_RE = re.compile("[" + "\U0001F1E6-\U0001F1FF" "\U0001F300-\U0001F5FF" "\U0001F600-\U0001F64F" "\U0001F680-\U0001F6FF" + "\U0001F700-\U0001F77F" "\U0001F780-\U0001F7FF" "\U0001F800-\U0001F8FF" "\U0001F900-\U0001F9FF" + "\U0001FA00-\U0001FAFF" "\u2600-\u26FF" "\u2700-\u27BF" + "]+", re.UNICODE)
          ONLY_PUNCT_SPACE = re.compile(r"^[\s\.,;:!?\-–—'\"“”‘’•·]+$")
          def is_emoji_only(s:str)->bool:
              if not s.strip(): return False
              t = ONLY_PUNCT_SPACE.sub("", s); t = EMOJI_RE.sub("", t); return len(t.strip())==0
          def clean_text(t:str)->str:
            if is_emoji_only(t): return ""
            t=t.replace("ɱ 2e","’re").replace("ɱ 2","m ").replace(" 2e","’re").replace(" 2 "," to ")
            t = re.sub(r"\s+", " ", t).strip()
            t = re.sub(r"\s+([,.;:!?])", r"\1", t)
            t = re.sub(r"([,;:])([^ \n])", r"\1 \2", t)
            t = re.sub(r"\bi\b", "I", t)
            return t
          spans=[]; 
          def _collect(m): spans.append(m.group(2)); return m.group(0)
          TEXT_NODE.sub(_collect, raw_html)
          cleaned=[clean_text(t) for t in spans]
          it=iter(cleaned)
          def _replace(m):
              open_tag, old_text, close_tag=m.group(1), m.group(2), m.group(3)
              try: new_text=next(it)
              except StopIteration: new_text=old_text
              return f"{open_tag}{html.escape(new_text, True)}{close_tag}"
          polished_html=TEXT_NODE.sub(_replace, raw_html)
          polished_html=re.sub(r"\n{3,}", "\n\n", polished_html)
          open(OUT,"w",encoding="utf-8").write(polished_html)
          PY
          chmod +x ".github/workflows/scripts/polish_transcript.py"

          # -------- replies.py (improved) --------
          cat > ".github/workflows/scripts/replies.py" << 'PY'
          #!/usr/bin/env python3
          import os, re, sys, json, html, time
          from collections import defaultdict
          try:
              import tldextract
          except Exception:
              tldextract = None

          ARTDIR = os.environ.get("ARTDIR",".")
          BASE   = os.environ.get("BASE","space")
          PURPLE = (os.environ.get("PURPLE_TWEET_URL","") or "").strip()

          REPLIES_OUT = os.path.join(ARTDIR, f"{BASE}_replies.html")
          LINKS_OUT   = os.path.join(ARTDIR, f"{BASE}_links.html")

          def write_empty():
              os.makedirs(ARTDIR, exist_ok=True)
              open(REPLIES_OUT,"w",encoding="utf-8").write("")
              open(LINKS_OUT,"w",encoding="utf-8").write("")

          def esc(x): return html.escape(x or "")

          def http_json(url, method="GET", headers=None, data=None, timeout=30):
              import urllib.request
              req = urllib.request.Request(url=url, method=method)
              if headers:
                  for k, v in headers.items(): req.add_header(k, v)
              body = data.encode("utf-8") if isinstance(data, str) else data
              try:
                  with urllib.request.urlopen(req, data=body, timeout=timeout) as r:
                      txt = r.read().decode("utf-8", "ignore")
                      return json.loads(txt)
              except Exception:
                  return None

          def get_guest_token(bearer):
              if not bearer: return None
              headers = {"authorization": bearer, "content-type": "application/json", "user-agent": "Mozilla/5.0"}
              d = http_json("https://api.twitter.com/1.1/guest/activate.json", method="POST", headers=headers, data="{}")
              return (d or {}).get("guest_token")

          def fetch_conversation(tid_str):
              bearer = (os.environ.get("TWITTER_AUTHORIZATION","") or "").strip()
              at     = (os.environ.get("TWITTER_AUTH_TOKEN","") or "").strip()
              ct0    = (os.environ.get("TWITTER_CSRF_TOKEN","") or "").strip()
              headers = {"user-agent":"Mozilla/5.0","accept":"application/json, text/plain, */*"}
              if at and ct0:
                  if bearer: headers["authorization"]=bearer
                  headers["x-csrf-token"]=ct0
                  headers["cookie"]=f"auth_token={at}; ct0={ct0}"
              elif bearer:
                  gt = get_guest_token(bearer)
                  if not gt: return None
                  headers["authorization"]=bearer
                  headers["x-guest-token"]=gt
              else:
                  return None
              url=f"https://api.twitter.com/2/timeline/conversation/{tid_str}.json?tweet_mode=extended&include_ext_alt_text=true"
              data=http_json(url, headers=headers)
              if not data: return None
              tweets=(data.get("globalObjects", {}) or {}).get("tweets", {}) or {}
              users =(data.get("globalObjects", {}) or {}).get("users", {}) or {}
              return (tweets, users) if tweets else None

          HTTP_RE = re.compile(r"(https?://[^\s<>'\")]+)")
          MENTION_RE = re.compile(r"(?<!\w)@([A-Za-z0-9_]{1,15})")
          HASH_RE = re.compile(r"(?<!\w)#([A-Za-z0-9_]{2,60})")

          def expand_text_with_entities(text, entities):
              text=text or ""; entities=entities or {}
              for u in sorted(entities.get("urls") or [], key=lambda x: len(x.get("url","")), reverse=True):
                  short=u.get("url") or ""; expanded=u.get("expanded_url") or u.get("unwound_url") or short
                  if short and expanded and short in text: text=text.replace(short, expanded)
              out=esc(text)
              out=HTTP_RE.sub(lambda m: f'<a href="{esc(m.group(1))}" target="_blank" rel="noopener">{esc(m.group(1))}</a>', out)
              out=MENTION_RE.sub(lambda m: f'<a href="https://x.com/{esc(m.group(1))}" target="_blank" rel="noopener">@{esc(m.group(1))}</a>', out)
              out=HASH_RE.sub(lambda m: f'<a href="https://x.com/hashtag/{esc(m.group(1))}" target="_blank" rel="noopener">#{esc(m.group(1))}</a>', out)
              return out.replace("\r\n","\n").replace("\r","\n").replace("\n","<br>")

          def add_link(bucket, url):
              if not url or not url.startswith("http"): return
              dom=url
              if tldextract:
                  try:
                      ext=tldextract.extract(url); dom=".".join([p for p in [ext.domain, ext.suffix] if p])
                  except Exception: pass
              bucket[dom].add(url)

          def pretty_link_title(url):
              try:
                  m=re.match(r"https?://([^/]+)(/[^?#]*)?", url); host=m.group(1) if m else ""; path=(m.group(2) or "/").strip("/")
                  h=host.lower()
                  if "youtube." in h or "youtu.be" in h: return "YouTube"
                  if "substack" in h: return "Substack"
                  if "x.com" in h or "twitter.com" in h: return "Tweet"
                  if "chbmp" in h: return "CHBMP"
                  if "who.int" in h: return "WHO"
                  if "pubmed" in h or "nih.gov" in h: return "PubMed"
                  if "github.com" in h: return "GitHub"
                  parts=[p for p in re.split(r"[-_/]+", path) if p and len(p)>2][:3]
                  parts=[re.sub(r"[^A-Za-z0-9]+","",p).title() for p in parts][:3]
                  if parts: return " ".join(parts[:3])
                  brand = host.split("."); brand = brand[-2] if len(brand)>1 else brand[0]
                  return brand.title()
              except Exception:
                  return "Link"

          def parse_time(ts):
              try: return time.mktime(time.strptime(ts, "%a %b %d %H:%M:%S %z %Y"))
              except Exception: return 0.0

          def collect_links_from_tweet(tw, links_by_domain):
              ent=tw.get("entities") or {}
              for u in (ent.get("urls") or []):
                  add_link(links_by_domain, u.get("expanded_url") or u.get("unwound_url") or u.get("url"))
              ext_ent=tw.get("extended_entities") or {}
              for m in (ext_ent.get("media") or []):
                  add_link(links_by_domain, m.get("expanded_url") or m.get("media_url_https") or m.get("media_url"))
              q=tw.get("quoted_status_permalink") or {}
              add_link(links_by_domain, q.get("expanded") or q.get("url"))

          def build_tree(tweets, users, root_id):
              nodes={}; children=defaultdict(list); links_by_domain=defaultdict(set)
              for tid, tw in tweets.items():
                  conv=str(tw.get("conversation_id_str") or tw.get("conversation_id") or "")
                  if conv == root_id: nodes[tid]=tw
              if root_id in tweets and root_id not in nodes: nodes[root_id]=tweets[root_id]
              for tid, tw in nodes.items(): collect_links_from_tweet(tw, links_by_domain)
              for tid, tw in nodes.items():
                  parent = tw.get("in_reply_to_status_id_str") or ""
                  cur=parent; attached=False
                  while cur:
                      if cur in nodes:
                          children[cur].append(tid); attached=True; break
                      nxt=tweets.get(cur, {}); cur=nxt.get("in_reply_to_status_id_str") or ""
                  if not attached and tid != root_id: children[root_id].append(tid)
              for p in list(children.keys()):
                  children[p].sort(key=lambda k: parse_time(nodes[k].get("created_at","")))
              return nodes, children, links_by_domain

          CSS = """
          <style>
          .ss3k-reply{display:flex;gap:10px;padding:10px 8px;border-bottom:1px solid #eee}
          .ss3k-ravatar{width:32px;height:32px;border-radius:50%}
          .ss3k-rname{font:600 14px/1.2 system-ui,-apple-system,Segoe UI,Roboto,Arial}
          .ss3k-rhandle,.ss3k-rtime{font:12px/1.2 system-ui,-apple-system,Segoe UI,Roboto,Arial;color:#64748b;text-decoration:none}
          .ss3k-rcontent{flex:1}
          .ss3k-rtext{margin-top:4px;font:14px/1.45 system-ui,-apple-system,Segoe UI,Roboto,Arial}
          details.ss3k-thread{margin:6px 0 8px 42px}
          details.ss3k-thread > summary{cursor:pointer;color:#2563eb}
          .ss3k-links h4{margin:14px 0 6px 0;font:600 14px/1.2 system-ui}
          .ss3k-links ul{margin:0 0 10px 16px;padding:0}
          .ss3k-links li{margin:2px 0}
          </style>
          """.strip()

          def render_thread(nodes, children, users, root_id):
              def expanded_text(tw): return expand_text_with_entities(tw.get("full_text") or tw.get("text") or "", tw.get("entities") or {})
              def render_item(tid, depth=0):
                  t = nodes[tid]; uid=str(t.get("user_id_str") or ""); u=users.get(uid, {})
                  name=u.get("name") or "User"; handle=u.get("screen_name") or ""
                  avatar=(u.get("profile_image_url_https") or u.get("profile_image_url") or "").replace("_normal.","_bigger.")
                  text_html=expanded_text(t); url=f"https://x.com/{handle}/status/{tid}"
                  ts=t.get("created_at","")
                  try: ts_short=time.strftime("%Y-%m-%d %H:%M:%SZ", time.strptime(ts, "%a %b %d %H:%M:%S %z %Y"))
                  except Exception: ts_short=ts
                  kids=children.get(tid, [])
                  head=(f'<div class="ss3k-reply" style="margin-left:{depth*16}px">'
                        f'  <a href="https://x.com/{esc(handle)}" target="_blank" rel="noopener">'
                        f'    <img class="ss3k-ravatar" src="{esc(avatar)}" alt=""></a>'
                        f'  <div class="ss3k-rcontent">'
                        f'    <div class="ss3k-rname">'
                        f'      <a href="https://x.com/{esc(handle)}" target="_blank" rel="noopener">{esc(name)}</a>'
                        f'      <span class="ss3k-rhandle">@{esc(handle)}</span>'
                        f'      · <a class="ss3k-rtime" href="{esc(url)}" target="_blank" rel="noopener">{esc(ts_short)}</a>'
                        f'    </div>'
                        f'    <div class="ss3k-rtext">{text_html}</div>'
                        f'  </div>'
                        f'</div>')
                  if not kids: return head
                  body="".join(render_item(k, depth+1) for k in kids)
                  return head + f'<details class="ss3k-thread" style="margin-left:{depth*16}px"><summary>Show {len(kids)} repl{"y" if len(kids)==1 else "ies"}</summary>{body}</details>'
              roots = children.get(root_id, [])
              roots.sort(key=lambda k: parse_time(nodes[k].get("created_at","")))
              return CSS + "".join(render_item(tid,0) for tid in roots)

          def render_links_list(links_by_domain):
              lines=["<div class='ss3k-links'>"]
              for dom in sorted(links_by_domain):
                  group=sorted(links_by_domain[dom]); 
                  if not group: continue
                  lines.append(f"<h4>{esc(dom)}</h4>"); lines.append("<ul>")
                  for u in group:
                      try: nm = pretty_link_title(u)
                      except Exception: nm = u
                      lines.append(f'<li><a href="{esc(u)}" target="_blank" rel="noopener">{esc(nm)}</a></li>')
                  lines.append("</ul>")
              lines.append("</div>"); return "\n".join(lines)

          def main():
              if not PURPLE: write_empty(); return
              m=re.search(r"/status/(\d+)", PURPLE)
              if not m: write_empty(); return
              tid_str=m.group(1); out=fetch_conversation(tid_str)
              if out is None: write_empty(); return
              tweets, users = out
              nodes, children, links_by_domain = build_tree(tweets, users, tid_str)
              if not nodes: write_empty(); return
              os.makedirs(ARTDIR, exist_ok=True)
              open(REPLIES_OUT,"w",encoding="utf-8").write(render_thread(nodes, children, users, tid_str))
              open(LINKS_OUT,"w",encoding="utf-8").write(render_links_list(links_by_domain))
          if __name__ == "__main__": main()
          PY
          chmod +x ".github/workflows/scripts/replies.py"

      - name: Build VTT and transcript after trim
        if: ${{ github.event.inputs.mode != 'attendees_only' && github.event.inputs.mode != 'replies_only' }}
        shell: bash
        env:
          CC_JSONL: ${{ env.CRAWLER_CC }}
          SHIFT_SECS: ${{ steps.detect.outputs.lead || '0' }}
        run: |
          set -euxo pipefail
          if [ -n "${CC_JSONL:-}" ] && [ -s "${CC_JSONL}" ]; then
            CC_JSONL="${CC_JSONL}" ARTDIR="${ARTDIR}" BASE="${BASE}" SHIFT_SECS="${SHIFT_SECS}" \
              python3 ".github/workflows/scripts/gen_vtt.py"
            [ -s "${ARTDIR}/${BASE}.vtt" ] && echo "VTT_PATH=${ARTDIR}/${BASE}.vtt" >> "$GITHUB_ENV" || true
            [ -s "${ARTDIR}/${BASE}_transcript.html" ] && echo "TRANSCRIPT_PATH=${ARTDIR}/${BASE}_transcript.html" >> "$GITHUB_ENV" || true
            [ -s "${ARTDIR}/${BASE}_reactions.json" ] && echo "REACTIONS_PATH=${ARTDIR}/${BASE}_reactions.json" >> "$GITHUB_ENV" || true
          fi

      - name: Polish transcript (optional)
        if: ${{ github.event.inputs.mode != 'attendees_only' && github.event.inputs.mode != 'replies_only' && env.TRANSCRIPT_PATH != '' }}
        shell: bash
        run: |
          set -euxo pipefail
          python3 ".github/workflows/scripts/polish_transcript.py" || true
          if [ -s "${ARTDIR}/${BASE}_transcript_polished.html" ]; then
            echo "TRANSCRIPT_PATH=${ARTDIR}/${BASE}_transcript_polished.html" >> "$GITHUB_ENV"
          fi

      - name: VTT via Deepgram fallback
        id: deepgram
        if: ${{ github.event.inputs.mode != 'attendees_only' && github.event.inputs.mode != 'replies_only' && env.VTT_PATH == '' && env.DEEPGRAM_API_KEY != '' && github.event.inputs.do_transcript == 'true' && env.MP3_PATH != '' }}
        shell: bash
        run: |
          set -euxo pipefail
          curl -sS -X POST \
            -H "Authorization: Token ${DEEPGRAM_API_KEY}" \
            -H "Content-Type: audio/mpeg" \
            --data-binary @"${MP3_PATH}" \
            "https://api.deepgram.com/v1/listen?model=nova-2&smart_format=true&punctuate=true&format=vtt" \
            -o "${ARTDIR}/${BASE}.vtt" || true
          [ -s "${ARTDIR}/${BASE}.vtt" ] && echo "VTT_PATH=${ARTDIR}/${BASE}.vtt" >> "$GITHUB_ENV" || true

      - name: Upload VTT to GCS
        id: upload_vtt
        if: ${{ github.event.inputs.mode != 'attendees_only' && github.event.inputs.mode != 'replies_only' && env.VTT_PATH != '' }}
        shell: bash
        run: |
          set -euxo pipefail
          DEST="gs://${GCS_BUCKET}/${BUCKET_PREFIX}/${BASE}.vtt"
          RAW="https://storage.googleapis.com/${GCS_BUCKET}/${BUCKET_PREFIX}/${BASE}.vtt"
          PROXY="https://media.chbmp.org/${PREFIX}/${BASE}.vtt"
          gsutil -m cp "${VTT_PATH}" "$DEST"
          if [ "${{ github.event.inputs.make_public }}" = "true" ]; then
            (gsutil acl ch -u AllUsers:R "$DEST" || gsutil iam ch allUsers:objectViewer "gs://${GCS_BUCKET}") || true
          fi
          echo "vtt_raw=${RAW}"     >> "$GITHUB_OUTPUT"
          echo "vtt_proxy=${PROXY}" >> "$GITHUB_OUTPUT"

      - name: Build attendees HTML
        id: attendees
        if: ${{ github.event.inputs.mode != 'replies_only' && steps.crawl.outcome == 'success' && steps.crawl.outputs.as_line != '' }}
        shell: bash
        env:
          CAND: ${{ steps.crawl.outputs.as_line }}
        run: |
          set -euxo pipefail
          OUT_JSON="${ARTDIR}/attendees.json"
          OUT_HTML="${ARTDIR}/attendees.html"
          jq -r '
            def mkp:
              { handle: (.twitter_screen_name // .user_results?.result?.legacy?.screen_name),
                name:   (.display_name       // .user_results?.result?.legacy?.name)
              }
              | select(.handle!=null and .handle!="" )
              | . + { url: ("https://x.com/" + .handle) };
            (.audioSpace // .) as $a
            | ($a.metadata?.creator_results?.result?.legacy?) as $h
            | ($h.screen_name // empty) as $H
            | {
                host:    ( if $H != "" then [ {handle:$H, name:($h.name // ""), url:("https://x.com/" + $H)} ] else [] end ),
                cohosts: ( ($a.participants?.admins   // []) | map(mkp) | map(select(.handle != $H)) | unique_by(.handle) ),
                speakers:( ($a.participants?.speakers // []) | map(mkp) | unique_by(.handle) )
              }
          ' "${CAND}" > "$OUT_JSON" || true
          if [ -s "$OUT_JSON" ]; then
            jq -r '
              def li: "  <li><a href=\"" + (.url//"#") + "\">" + ((.name // "") + " (@" + (.handle // "") + ")") + "</a></li>";
              def section(title; items):
                if (items|length) > 0
                then "<h3>" + title + "</h3>\n<ul>\n" + (items|map(li)|join("\n")) + "\n</ul>\n"
                else ""
                end;
              . as $d
              | section("Host"; $d.host)
              + section( (if ($d.cohosts|length)==1 then "Co-host" else "Co-hosts" end); $d.cohosts)
              + section("Speakers"; $d.speakers)
            ' "$OUT_JSON" > "$OUT_HTML"
            if grep -qi '<li><a ' "$OUT_HTML"; then
              echo "ATTN_HTML=${OUT_HTML}" >> "$GITHUB_ENV"
              echo "ATTENDEES_OK=1"       >> "$GITHUB_ENV"
            fi
          fi

      - name: Scrape replies and shared links (web)
        shell: bash
        env:
          PURPLE_TWEET_URL: ${{ github.event.inputs.purple_tweet_url }}
        run: |
          set -euo pipefail
          python3 ".github/workflows/scripts/replies.py" || true
          if [ -s "${ARTDIR}/${BASE}_replies.html" ]; then
            echo "REPLIES_PATH=${ARTDIR}/${BASE}_replies.html" >> "$GITHUB_ENV"
          fi
          if [ -s "${ARTDIR}/${BASE}_links.html" ]; then
            echo "LINKS_PATH=${ARTDIR}/${BASE}_links.html" >> "$GITHUB_ENV"
          fi

      - name: Derive Space title and publish date
        id: meta
        shell: bash
        env:
          AS_LINE: ${{ steps.crawl.outputs.as_line }}
        run: |
          set -euo pipefail
          TTL=""
          if [ -n "${AS_LINE:-}" ] && [ -s "${AS_LINE}" ]; then
            TTL="$(jq -r '(.audioSpace // .) as $a | ($a.metadata.title // $a.metadata.name // .title // "")' "${AS_LINE}" | sed -E 's/^[[:space:]]+|[[:space:]]+$//g')"
          fi
          if [ -z "$TTL" ]; then TTL="${BASE}"; fi
          echo "TTL_FINAL=$TTL" >> "$GITHUB_ENV"

          START_ISO=""
          if [ -n "${AS_LINE:-}" ] && [ -s "${AS_LINE}" ]; then
            MS="$(jq -r '(.audioSpace // .) as $a | ($a.metadata.started_at // $a.metadata.created_at // $a.metadata.start // empty)' "${AS_LINE}")" || true
            if [[ "$MS" =~ ^[0-9]+$ ]]; then
              if [ ${#MS} -gt 10 ]; then SECS=$((MS/1000)); else SECS=$MS; fi
              START_ISO="$(date -u -d "@$SECS" +%Y-%m-%dT%H:%M:%SZ || true)"
            fi
          fi
          if [ -z "$START_ISO" ] && [ -s "${ARTDIR}/${BASE}.start.txt" ]; then
            START_ISO="$(head -n1 "${ARTDIR}/${BASE}.start.txt" | tr -d '\r\n')"
          fi
          if [ -z "$START_ISO" ]; then START_ISO="$(date -u +%Y-%m-%dT%H:%M:%SZ)"; fi
          echo "START_ISO=$START_ISO" >> "$GITHUB_ENV"

      - name: Register/Update in WP (assets, transcript, replies, links, emoji)
        if: ${{ env.WP_BASE_URL != '' && env.WP_USER != '' && env.WP_APP_PASSWORD != '' && github.event.inputs.post_id != '' }}
        shell: bash
        env:
          PID:  ${{ github.event.inputs.post_id }}
          AUD:  ${{ steps.upload_mp3.outputs.audio_proxy || steps.upload_mp3.outputs.audio_raw }}
          VTTU: ${{ steps.upload_vtt.outputs.vtt_proxy   || steps.upload_vtt.outputs.vtt_raw }}
        run: |
          set -euo pipefail
          TTL="${TTL_FINAL:-${BASE}}"

          ATH_FILE="${WORKDIR}/empty_attendees.html"; : > "$ATH_FILE"
          [ -n "${ATTN_HTML:-}" ] && [ -s "${ATTN_HTML:-}" ] && ATH_FILE="${ATTN_HTML}"

          TR_FILE="${WORKDIR}/empty_transcript.html"; : > "$TR_FILE"
          [ -n "${TRANSCRIPT_PATH:-}" ] && [ -s "${TRANSCRIPT_PATH}" ] && TR_FILE="${TRANSCRIPT_PATH}"

          REP_FILE="${WORKDIR}/empty_replies.html"; : > "$REP_FILE"
          [ -n "${REPLIES_PATH:-}" ] && [ -s "${REPLIES_PATH}" ] && REP_FILE="${REPLIES_PATH}"

          LNK_FILE="${WORKDIR}/empty_links.html"; : > "$LNK_FILE"
          [ -n "${LINKS_PATH:-}" ] && [ -s "${LINKS_PATH}" ] && LNK_FILE="${LINKS_PATH}"

          RX_FILE="${WORKDIR}/empty_reactions.json"; echo "[]" > "$RX_FILE"
          if [ -s "${ARTDIR}/${BASE}_reactions.json" ]; then
            RX_FILE="${ARTDIR}/${BASE}_reactions.json"
          fi

          REQ="${WORKDIR}/wp_register_body.json"
          jq -n \
            --arg pid   "${PID}" \
            --arg ttl   "${TTL}" \
            --arg when  "${START_ISO:-}" \
            --arg gcs   "${AUD}" \
            --arg mime  "audio/mpeg" \
            --arg vtt   "${VTTU}" \
            --rawfile ath "${ATH_FILE}" \
            --rawfile tr  "${TR_FILE}" \
            --rawfile rep "${REP_FILE}" \
            --rawfile lnk "${LNK_FILE}" \
            --rawfile rx  "${RX_FILE}" \
            '{
               post_id: ($pid|tonumber),
               title:   $ttl
             }
             + (if ($when|length)>0 then {post_date_gmt:$when, space_started_at:$when, publish_date:$when} else {} end)
             + (if ($gcs|length)>0 then {gcs_url:$gcs, mime:$mime} else {} end)
             + (if ($vtt|length)>0 then {vtt_url:$vtt} else {} end)
             + (if ($ath|gsub("\\s";"")|length)>0 then {attendees_html:$ath} else {} end)
             + (if ($tr|gsub("\\s";"")|length)>0 then {transcript:$tr, has_transcript:true} else {} end)
             + (if ($rep|gsub("\\s";"")|length)>0 then {ss3k_replies_html:$rep} else {} end)
             + (if ($lnk|gsub("\\s";"")|length)>0 then {shared_links_html:$lnk} else {} end)
             + (if ($rx|gsub("\\s";"")|length)>2 then {reactions_json:$rx} else {} end)
            ' > "$REQ"

          curl -sS -u "${WP_USER}:${WP_APP_PASSWORD}" \
            -H "Content-Type: application/json" \
            -X POST "${WP_BASE_URL%/}/wp-json/ss3k/v1/register" \
            --data-binary @"$REQ" | jq -r .

      - name: Done / finalize status
        if: ${{ env.WP_BASE_URL != '' && env.WP_USER != '' && env.WP_APP_PASSWORD != '' && github.event.inputs.post_id != '' }}
        shell: bash
        run: |
          set -euo pipefail
          curl -sS -u "${WP_USER}:${WP_APP_PASSWORD}" \
            -H "Content-Type: application/json" \
            -X POST "${WP_BASE_URL%/}/wp-json/ss3k/v1/worker-status" \
            -d "$(jq -n --arg pid "${{ github.event.inputs.post_id }}" \
                       --arg status "complete" \
                       --arg msg "Artifacts processed and registered" \
                       --arg run "${{ github.run_id }}" \
                       --argjson progress 100 \
                       '{post_id: ($pid|tonumber), status:$status, message:$msg, run_id:$run, progress:$progress}')"

      - name: Summary
        shell: bash
        env:
          SID: ${{ steps.ids.outputs.space_id }}
        run: |
          {
            echo "### Space Worker Summary"
            echo "- Mode: ${{ github.event.inputs.mode }}"
            echo "- Source kind: ${SOURCE_KIND}"
            echo "- Source URL: ${SOURCE_URL}"
            echo "- Purple URL: ${PURPLE_TWEET_URL}"
            echo "- Space ID: ${SID}"
            echo "- Post ID: ${{ github.event.inputs.post_id }}"
            echo "- Title: ${TTL_FINAL:-}"
            echo "- Start (UTC): ${START_ISO:-}"
            if [ -n "${{ steps.upload_mp3.outputs.audio_proxy }}" ]; then
              echo "- Audio: ${{ steps.upload_mp3.outputs.audio_proxy }}"
            elif [ -n "${{ steps.upload_mp3.outputs.audio_raw }}" ]; then
              echo "- Audio: ${{ steps.upload_mp3.outputs.audio_raw }}"
            fi
            if [ -n "${{ steps.upload_vtt.outputs.vtt_proxy }}" ]; then
              echo "- VTT: ${{ steps.upload_vtt.outputs.vtt_proxy }}"
            elif [ -n "${{ steps.upload_vtt.outputs.vtt_raw }}" ]; then
              echo "- VTT: ${{ steps.upload_vtt.outputs.vtt_raw }}"
            fi
            if [ -n "${REPLIES_PATH:-}" ]; then
              echo "- Replies HTML: ${REPLIES_PATH}"
            fi
            if [ -n "${LINKS_PATH:-}" ]; then
              echo "- Links HTML: ${LINKS_PATH}"
            fi
            if [ -n "${REACTIONS_PATH:-}" ]; then
              echo "- Reactions: ${REACTIONS_PATH}"
            fi
          } >> "$GITHUB_STEP_SUMMARY"
