name: Space Worker

on:
  workflow_dispatch:
    inputs:
      space_url:
        description: X or Twitter Space URL
        required: false
        type: string
        default: ""
      post_id:
        description: Existing WordPress post ID optional
        required: false
        type: string
        default: ""
      title:
        description: Fallback post title optional
        required: false
        type: string
        default: ""
      gcs_prefix:
        description: GCS prefix default spaces YYYY MM
        required: false
        type: string
        default: ""
      make_public:
        description: Make uploaded artifacts public
        required: false
        type: choice
        options: ["true","false"]
        default: "true"
      do_transcript:
        description: Generate transcript when captions are not available
        required: false
        type: choice
        options: ["true","false"]
        default: "true"
      mode:
        description: Limit processing
        required: false
        type: choice
        options: ["","transcript_only","attendees_only","replies_only"]
        default: ""
      existing_mp3_url:
        description: For transcript only provide URL to existing MP3
        required: false
        type: string
        default: ""
      purple_tweet_url:
        description: Purple pill tweet URL optional
        required: false
        type: string
        default: ""
      audio_profile:
        description: Audio profile for encode
        required: false
        type: choice
        options: ["transparent","radio","aggressive","transparent_rnnoise","radio_rnnoise","aggressive_rnnoise"]
        default: "transparent"

permissions:
  contents: read
  packages: read

env:
  GCP_SA_KEY:       ${{ secrets.GCP_SA_KEY       || vars.GCP_SA_KEY }}
  GCS_BUCKET:       ${{ secrets.GCS_BUCKET       || vars.GCS_BUCKET }}
  WP_BASE_URL:      ${{ secrets.WP_BASE_URL      || secrets.WP_URL || vars.WP_BASE_URL || vars.WP_URL }}
  WP_USER:          ${{ secrets.WP_USER          || vars.WP_USER }}
  WP_APP_PASSWORD:  ${{ secrets.WP_APP_PASSWORD  || vars.WP_APP_PASSWORD }}
  DEEPGRAM_API_KEY: ${{ secrets.DEEPGRAM_API_KEY || vars.DEEPGRAM_API_KEY }}

  TWITTER_AUTHORIZATION: ${{ secrets.TWITTER_AUTHORIZATION || secrets.X_BEARER     || vars.TWITTER_AUTHORIZATION || vars.X_BEARER }}
  TWITTER_AUTH_TOKEN:    ${{ secrets.TWITTER_AUTH_TOKEN    || secrets.X_AUTH_TOKEN || vars.TWITTER_AUTH_TOKEN    || vars.X_AUTH_TOKEN }}
  TWITTER_CSRF_TOKEN:    ${{ secrets.TWITTER_CSRF_TOKEN    || secrets.X_CSRF       || vars.TWITTER_CSRF_TOKEN    || vars.X_CSRF }}

  TW_API_CONSUMER_KEY:        ${{ secrets.TW_API_CONSUMER_KEY        || vars.TW_API_CONSUMER_KEY }}
  TW_API_CONSUMER_SECRET:     ${{ secrets.TW_API_CONSUMER_SECRET     || vars.TW_API_CONSUMER_SECRET }}
  TW_API_ACCESS_TOKEN:        ${{ secrets.TW_API_ACCESS_TOKEN        || vars.TW_API_ACCESS_TOKEN }}
  TW_API_ACCESS_TOKEN_SECRET: ${{ secrets.TW_API_ACCESS_TOKEN_SECRET || vars.TW_API_ACCESS_TOKEN_SECRET }}

  WORKDIR: ${{ github.workspace }}/work
  ARTDIR:  ${{ github.workspace }}/out

jobs:
  process:
    name: Process Space
    runs-on: ubuntu-latest
    timeout-minutes: 180
    concurrency:
      group: ${{ format('space-worker-{0}-{1}', github.ref, github.event.inputs.post_id != '' && github.event.inputs.post_id || github.run_id) }}
      cancel-in-progress: false

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Notify WP queued
        if: ${{ env.WP_BASE_URL != '' && env.WP_USER != '' && env.WP_APP_PASSWORD != '' && github.event.inputs.post_id != '' && github.event.inputs.mode != 'replies_only' }}
        shell: bash
        run: |
          set -euo pipefail
          curl -sS -u "${WP_USER}:${WP_APP_PASSWORD}" \
            -H "Content-Type: application/json" \
            -X POST "${WP_BASE_URL%/}/wp-json/ss3k/v1/worker-status" \
            -d "$(jq -n --arg pid "${{ github.event.inputs.post_id }}" \
                       --arg status "queued" \
                       --arg msg "Workflow received and queued" \
                       --arg run "${{ github.run_id }}" \
                       --argjson progress 1 \
                       '{post_id: ($pid|tonumber), status:$status, message:$msg, run_id:$run, progress:$progress}')"

      - name: Install deps
        shell: bash
        run: |
          set -euxo pipefail
          sudo apt-get update
          sudo apt-get install -y --no-install-recommends ffmpeg jq python3 python3-pip ca-certificates gnupg
          python3 -m pip install --upgrade pip
          python3 -m pip install --no-cache-dir yt-dlp python-twitter tldextract transformers==4.45.0 sentencepiece
          echo "deb [signed-by=/usr/share/keyrings/cloud.google.gpg] http://packages.cloud.google.com/apt cloud-sdk main" | sudo tee /etc/apt/sources.list.d/google-cloud-sdk.list
          curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo gpg --dearmor -o /usr/share/keyrings/cloud.google.gpg
          sudo apt-get update && sudo apt-get install -y google-cloud-sdk
          echo "${{ github.token }}" | docker login ghcr.io -u "${{ github.actor }}" --password-stdin || true

      - name: Validate config and prefixes
        id: cfg
        shell: bash
        run: |
          set -euxo pipefail
          test -n "${GCP_SA_KEY}" || { echo "GCP_SA_KEY missing"; exit 1; }
          test -n "${GCS_BUCKET}" || { echo "GCS_BUCKET missing"; exit 1; }
          mkdir -p "$WORKDIR" "$ARTDIR" "$ARTDIR/logs" ".github/workflows/scripts"
          PFX="$(echo "${{ github.event.inputs.gcs_prefix }}" | sed -E 's#^/*##; s#/*$##')"
          if [ -z "$PFX" ]; then PFX="spaces/$(date +%Y)/$(date +%m)"; fi
          echo "PREFIX=$PFX"                  >> "$GITHUB_ENV"
          echo "BUCKET_PREFIX=${PFX#spaces/}" >> "$GITHUB_ENV"

      - name: Derive Space ID and base
        id: ids
        shell: bash
        env:
          URL: ${{ github.event.inputs.space_url }}
        run: |
          set -euxo pipefail
          SID=""
          if [ -n "$URL" ]; then
            SID="$(echo "$URL" | sed -nE 's#^.*/i/spaces/([^/?#]+).*#\1#p')"
          fi
          [ -z "$SID" ] && SID="unknown"
          BASE="space-$(date +%m-%d-%Y)-${SID}"
          echo "SPACE_ID=${SID}" >> "$GITHUB_ENV"
          echo "BASE=${BASE}"    >> "$GITHUB_ENV"
          echo "space_id=${SID}" >> "$GITHUB_OUTPUT"
          echo "base=${BASE}"    >> "$GITHUB_OUTPUT"

      - name: GCP auth
        if: ${{ github.event.inputs.mode != 'replies_only' }}
        shell: bash
        run: |
          set -euxo pipefail
          printf '%s' "${GCP_SA_KEY}" > "${HOME}/gcp-key.json"
          gcloud auth activate-service-account --key-file="${HOME}/gcp-key.json" >/dev/null

      - name: X preflight auth
        id: x_preflight
        if: ${{ github.event.inputs.mode != 'replies_only' }}
        shell: bash
        run: |
          set -euo pipefail
          AUTH="${TWITTER_AUTHORIZATION:-}"
          AT="${TWITTER_AUTH_TOKEN:-}"
          CT="${TWITTER_CSRF_TOKEN:-}"
          if [ -n "$AUTH" ] && ! printf '%s' "$AUTH" | grep -q '^Bearer '; then AUTH=""; fi
          [ -n "${TWITTER_AUTHORIZATION:-}" ] && echo "::add-mask::${TWITTER_AUTHORIZATION}"
          [ -n "$AT" ] && echo "::add-mask::${AT}"
          [ -n "$CT" ] && echo "::add-mask::${CT}"
          OK=0; REASON="no_creds"
          [ -n "$AT" ] && [ -n "$CT" ] && OK=1 && REASON="cookie_ok" || true
          [ -n "$AUTH" ] && OK=1 && REASON="${REASON}_bearer_present" || true
          echo "ok=${OK}"         >> "$GITHUB_OUTPUT"
          echo "reason=${REASON}" >> "$GITHUB_OUTPUT"
          [ -n "$AUTH" ] && echo "TWITTER_AUTHORIZATION=$AUTH" >> "$GITHUB_ENV"

      - name: Run crawler
        id: crawl
        if: ${{ github.event.inputs.mode != 'replies_only' && steps.x_preflight.outputs.ok == '1' }}
        shell: bash
        env:
          SID: ${{ steps.ids.outputs.space_id }}
        run: |
          set -euxo pipefail
          mkdir -p "${ARTDIR}" "${ARTDIR}/logs"
          docker pull ghcr.io/hitomarukonpaku/twspace-crawler:latest || true
          LOG_STD="${ARTDIR}/logs/crawler_${SID}.out.log"
          LOG_ERR="${ARTDIR}/logs/crawler_${SID}.err.log"
          set +e
          timeout 20m docker run --rm \
            -e TWITTER_AUTHORIZATION \
            -e TWITTER_AUTH_TOKEN \
            -e TWITTER_CSRF_TOKEN \
            -v "${ARTDIR}:/app/download" \
            -v "${ARTDIR}/logs:/app/logs" \
            ghcr.io/hitomarukonpaku/twspace-crawler:latest \
            --id "${SID}" --force > >(tee -a "$LOG_STD") 2> >(tee -a "$LOG_ERR" >&2)
          RC=$?
          set -e
          echo "crawler_exit=${RC}"
          AUDIO_FILE="$(find "${ARTDIR}" -type f \( -iname '*.m4a' -o -iname '*.mp3' -o -iname '*.mp4' -o -iname '*.aac' -o -iname '*.webm' -o -iname '*.ogg' -o -iname '*.wav' -o -iname '*.ts' \) -printf '%T@ %p\n' | sort -nr | head -n1 | cut -d' ' -f2- || true)"
          if [ -n "${AUDIO_FILE:-}" ] && [ -f "${AUDIO_FILE}" ]; then
            echo "INPUT_FILE=${AUDIO_FILE}" >> "$GITHUB_ENV"
            echo "audio_file=${AUDIO_FILE}" >> "$GITHUB_OUTPUT"
          fi
          RAW="$(grep -hF 'getAudioSpaceById |' "$LOG_STD" "$LOG_ERR" | tail -n1 || true)"
          if [ -z "$RAW" ]; then
            RAW="$(grep -hF 'getAudioSpaceByRestId |' "$LOG_STD" "$LOG_ERR" | tail -n1 || true)"
          fi
          if [ -n "$RAW" ]; then
            printf '%s\n' "$RAW" | awk -F'\\| ' '{print $NF}' > "${ARTDIR}/_as_line.json" || true
          fi
          [ -s "${ARTDIR}/_as_line.json" ] && echo "as_line=${ARTDIR}/_as_line.json" >> "$GITHUB_OUTPUT" || true
          CC_JSONL="$(find "${ARTDIR}" -type f \( -iname '*cc.jsonl' -o -iname '*caption*.jsonl' -o -iname '*captions*.jsonl' \) -print | head -n1 || true)"
          if [ -n "${CC_JSONL:-}" ]; then
            echo "CRAWLER_CC=${CC_JSONL}" >> "$GITHUB_ENV"
          fi

      - name: Fallback download via yt dlp
        if: ${{ github.event.inputs.mode != 'attendees_only' && github.event.inputs.mode != 'replies_only' && (steps.crawl.outputs.audio_file == '' || steps.crawl.outcome != 'success') && github.event.inputs.existing_mp3_url == '' && github.event.inputs.space_url != '' }}
        shell: bash
        working-directory: ${{ env.WORKDIR }}
        env:
          URL: ${{ github.event.inputs.space_url }}
        run: |
          set -euxo pipefail
          yt-dlp -o "%(title)s.%(ext)s" -f "bestaudio/best" "$URL"
          IN="$(ls -S | head -n1 || true)"
          test -f "$IN" || { echo "No file downloaded"; exit 1; }
          echo "INPUT_FILE=$PWD/$IN" >> "$GITHUB_ENV"

      - name: Use provided MP3 for transcript only
        if: ${{ github.event.inputs.mode == 'transcript_only' && github.event.inputs.existing_mp3_url != '' }}
        shell: bash
        run: |
          set -euxo pipefail
          curl -L "${{ github.event.inputs.existing_mp3_url }}" -o "${ARTDIR}/${BASE}.mp3"
          echo "INPUT_FILE=${ARTDIR}/${BASE}.mp3" >> "$GITHUB_ENV"

      - name: Detect lead silence seconds
        id: detect
        if: ${{ github.event.inputs.mode != 'attendees_only' && github.event.inputs.mode != 'replies_only' && env.INPUT_FILE != '' }}
        shell: bash
        run: |
          set -euxo pipefail
          LOG="${WORKDIR}/silence.log"
          ffmpeg -hide_banner -i "$INPUT_FILE" -af "silencedetect=noise=-45dB:d=1" -f null - 2> "$LOG" || true
          LEAD="$(awk '/silence_end/ {print $5; exit}' "$LOG" || true)"
          case "$LEAD" in ''|*[^0-9.]* ) LEAD="0.0" ;; esac
          echo "TRIM_LEAD=${LEAD}" >> "$GITHUB_ENV"
          echo "lead=${LEAD}"       >> "$GITHUB_OUTPUT"

      - name: Trim head and tail
        if: ${{ github.event.inputs.mode != 'attendees_only' && github.event.inputs.mode != 'replies_only' && env.INPUT_FILE != '' }}
        shell: bash
        run: |
          set -euxo pipefail
          TRIM_WAV="${WORKDIR}/trim_${{ github.run_id }}.wav"
          ffmpeg -hide_banner -y -i "$INPUT_FILE" \
            -af "silenceremove=start_periods=1:start_silence=1:start_threshold=-45dB:detection=peak,areverse,silenceremove=start_periods=1:start_silence=1:start_threshold=-45dB:detection=peak,areverse" \
            -c:a pcm_s16le "$TRIM_WAV"
          echo "AUDIO_IN=${TRIM_WAV}" >> "$GITHUB_ENV"

      - name: Probe audio format
        id: probe
        if: ${{ github.event.inputs.mode != 'attendees_only' && github.event.inputs.mode != 'replies_only' && env.AUDIO_IN != '' }}
        shell: bash
        run: |
          set -euxo pipefail
          J="$(ffprobe -v error -select_streams a:0 -show_entries stream=channels,sample_rate -of json "$AUDIO_IN")"
          CH=$(echo "$J" | jq -r '.streams[0].channels // 1')
          SR=$(echo "$J" | jq -r '.streams[0].sample_rate // "48000"')
          echo "SRC_CH=${CH}" >> "$GITHUB_ENV"
          echo "SRC_SR=${SR}" >> "$GITHUB_ENV"

      - name: Encode MP3 with selected profile
        if: ${{ github.event.inputs.mode != 'attendees_only' && github.event.inputs.mode != 'replies_only' && env.AUDIO_IN != '' }}
        shell: bash
        env:
          PROF: ${{ github.event.inputs.audio_profile }}
        run: |
          set -euxo pipefail
          OUT="${ARTDIR}/${BASE}.mp3"
          CH="${SRC_CH:-1}"
          SR="${SRC_SR:-48000}"

          use_rnnoise=0
          case "${PROF}" in
            *_rnnoise) use_rnnoise=1 ;;
          esac

          if [ "${PROF%%_*}" = "transparent" ]; then
            PRE=""
          elif [ "${PROF%%_*}" = "radio" ]; then
            PRE="highpass=f=60,lowpass=f=14000,afftdn=nr=4:nf=-28,deesser=i=0.12,acompressor=threshold=-18dB:ratio=2:attack=12:release=220:makeup=2"
          else
            PRE="highpass=f=70,lowpass=f=11500,afftdn=nr=8:nf=-25,deesser=i=0.2,acompressor=threshold=-18dB:ratio=2.8:attack=8:release=200:makeup=3"
          fi

          if [ $use_rnnoise -eq 1 ]; then
            M="${WORKDIR}/rnnoise.rnnn"
            curl -fsSL -o "$M" https://raw.githubusercontent.com/GregorR/rnnoise-models/master/heavyrnnoise.rnnn || true
            if [ -s "$M" ]; then
              if [ -n "$PRE" ]; then PRE="arnndn=m=${M},${PRE}"; else PRE="arnndn=m=${M}"; fi
            fi
          fi

          if [ -z "$PRE" ]; then
            ffmpeg -hide_banner -y -i "$AUDIO_IN" -map a:0 -c:a libmp3lame -q:a 0 -ar "$SR" -ac "$CH" "$OUT"
          else
            PASS1_JSON="${WORKDIR}/loudnorm1.json"
            ffmpeg -hide_banner -y -i "$AUDIO_IN" -af "${PRE},loudnorm=I=-16:TP=-1.5:LRA=11:print_format=json" -f null - 2>"${WORKDIR}/pass1.log" || true
            awk '/^{/{f=1} f{print} /}/{f=0}' "${WORKDIR}/pass1.log" > "$PASS1_JSON" || true
            if jq -e . "$PASS1_JSON" >/devnull 2>&1; then
              I=$(jq -r '.input_i // "-16"'  "$PASS1_JSON")
              TP=$(jq -r '.input_tp // "-1.5"' "$PASS1_JSON")
              LRA=$(jq -r '.input_lra // "11"' "$PASS1_JSON")
              TH=$(jq -r '.input_thresh // "-26"' "$PASS1_JSON")
              ffmpeg -hide_banner -y -i "$AUDIO_IN" \
                -af "${PRE},loudnorm=I=-16:TP=-1.5:LRA=11:measured_I=$I:measured_TP=$TP:measured_LRA=$LRA:measured_thresh=$TH:linear=true" \
                -c:a libmp3lame -q:a 2 -ar "$SR" -ac "$CH" "$OUT"
            else
              ffmpeg -hide_banner -y -i "$AUDIO_IN" \
                -af "${PRE},loudnorm=I=-16:TP=-1.5:LRA=11" \
                -c:a libmp3lame -q:a 2 -ar "$SR" -ac "$CH" "$OUT"
            fi
          fi

          echo "MP3_PATH=${OUT}" >> "$GITHUB_ENV"

      - name: Upload MP3 to GCS
        id: upload_mp3
        if: ${{ github.event.inputs.mode != 'attendees_only' && github.event.inputs.mode != 'replies_only' && env.MP3_PATH != '' }}
        shell: bash
        run: |
          set -euxo pipefail
          DEST="gs://${GCS_BUCKET}/${BUCKET_PREFIX}/${BASE}.mp3"
          RAW="https://storage.googleapis.com/${GCS_BUCKET}/${BUCKET_PREFIX}/${BASE}.mp3"
          PROXY="https://media.chbmp.org/${PREFIX}/${BASE}.mp3"
          gsutil -m cp "${MP3_PATH}" "$DEST"
          if [ "${{ github.event.inputs.make_public }}" = "true" ]; then
            (gsutil acl ch -u AllUsers:R "$DEST" || gsutil iam ch allUsers:objectViewer "gs://${GCS_BUCKET}") || true
          fi
          echo "audio_raw=${RAW}"     >> "$GITHUB_OUTPUT"
          echo "audio_proxy=${PROXY}" >> "$GITHUB_OUTPUT"

      - name: Write helper scripts
        shell: bash
        env:
          PURPLE_TWEET_URL: ${{ github.event.inputs.purple_tweet_url }}
        run: |
          set -euo pipefail
          mkdir -p ".github/workflows/scripts"

          cat > ".github/workflows/scripts/gen_vtt.py" << 'PY'
          import os, sys, json, html
          ARTDIR = os.environ.get("ARTDIR","."); BASE=os.environ.get("BASE","space")
          CC=os.environ.get("CC_JSONL") or ""; SHIFT=float(os.environ.get("SHIFT_SECS","0") or "0")
          vtt_path=os.path.join(ARTDIR,f"{BASE}.vtt"); tr_path=os.path.join(ARTDIR,f"{BASE}_transcript.html")
          def load_jsonl(p):
              out=[]
              with open(p,'r',encoding='utf-8',errors='ignore') as f:
                  for line in f:
                      line=line.strip()
                      if line:
                          try: out.append(json.loads(line))
                          except: pass
              return out
          def pick(o,*ks):
              for k in ks:
                  if k in o and o[k] is not None: return o[k]
              return None
          def fmt(s):
              h=int(s//3600); m=int((s%3600)//60); sec=s-h*3600-m*60
              return f"{h:02d}:{m:02d}:{sec:06.3f}".replace('.',',')
          if not CC or not os.path.exists(CC):
              open(vtt_path,'w').write("WEBVTT\\n\\n"); open(tr_path,'w').write(""); sys.exit(0)
          raw=load_jsonl(CC); cues=[]
          for it in raw:
              st=pick(it,'start','offset','startSec','startMs','ts','time'); en=pick(it,'end','endSec','endMs')
              tx=(pick(it,'text','caption','content','payloadText') or "").strip()
              sp=(pick(it,'speaker','from','user','name','speaker_name','speakerName') or "")
              hd=(pick(it,'username','handle','screen_name') or "")
              try: st=float(st)
              except: st=0.0
              if st>86400: st/=1000.0
              if en:
                  try: en=float(en)
                  except: en=None
                  if en and en>86400: en/=1000.0
              if not en: en=st+max(1.2,len(tx)/14.0)
              st=max(0.0,st-SHIFT); en=max(st+0.01,en-SHIFT)
              cues.append({'start':st,'end':en,'text':tx,'speaker':sp,'handle':hd})
          cues.sort(key=lambda c:c['start'])
          with open(vtt_path,'w',encoding='utf-8') as v:
              v.write("WEBVTT\\n\\n")
              for c in cues:
                  v.write(f"{fmt(c['start'])} --> {fmt(c['end'])}\\n")
                  line = c['text']
                  if c['speaker']:
                      line=f"<v {html.escape(c['speaker'])}> {line}"
                  v.write(line+"\\n\\n")
          out=[]
          for c in cues:
              name = c['speaker'] or (("@"+c['handle']) if c['handle'] else "Speaker")
              avatar = f"https://unavatar.io/twitter/{c['handle']}" if c['handle'] else ""
              out.append(
                f'<div class="ss3k-line" data-start="{c["start"]:.3f}" data-end="{c["end"]:.3f}" data-avatar="{html.escape(avatar)}">'
                f'<span class="ss3k-avatar" aria-hidden="true"></span>'
                f'<span class="ss3k-name">{html.escape(name)}</span>'
                f'<span class="ss3k-text">{html.escape(c["text"])}</span>'
                f'</div>'
              )
          open(tr_path,'w',encoding='utf-8').write("\\n".join(out))
          PY

          cat > ".github/workflows/scripts/replies.py" << 'PY'
          import os, re, sys, html, tldextract
          import twitter
          from collections import defaultdict
          ARTDIR=os.environ.get("ARTDIR","."); BASE=os.environ.get("BASE","space")
          PURPLE=os.environ.get("PURPLE_TWEET_URL","").strip()
          repl=os.path.join(ARTDIR,f"{BASE}_replies.html"); links=os.path.join(ARTDIR,f"{BASE}_links.html")
          def empty():
              open(repl,"w").write(""); open(links,"w").write("")
          if not PURPLE: empty(); sys.exit(0)
          m=re.search(r"/([^/]+)/status/(\\d+)",PURPLE)
          if not m: empty(); sys.exit(0)
          screen_name, tid = m.group(1), int(m.group(2))
          ck=os.environ.get("TW_API_CONSUMER_KEY",""); cs=os.environ.get("TW_API_CONSUMER_SECRET","")
          at=os.environ.get("TW_API_ACCESS_TOKEN",""); ats=os.environ.get("TW_API_ACCESS_TOKEN_SECRET","")
          if not all([ck,cs,at,ats]): empty(); sys.exit(0)
          api=twitter.Api(consumer_key=ck, consumer_secret=cs, access_token_key=at, access_token_secret=ats, tweet_mode="extended", sleep_on_rate_limit=True)
          try:
              root=api.GetStatus(status_id=tid, include_my_retweet=False)
          except Exception:
              empty(); sys.exit(0)
          results=[]
          try:
              rs=api.GetSearch(term=f"to:{screen_name}", since_id=tid, count=100, result_type="recent", include_entities=True)
              for t in rs:
                  if getattr(t,'in_reply_to_status_id',None)==tid:
                      results.append(t)
          except Exception:
              pass
          def esc(x): return html.escape(x or "")
          blocks=[]
          for t in results:
              u=t.user
              name=f"{u.name} (@{u.screen_name})" if u and u.screen_name else "User"
              avatar=getattr(u,'profile_image_url_https', '') or ""
              text=esc(getattr(t,'full_text',None) or getattr(t,'text',None) or "")
              blocks.append(f'<div class="ss3k-reply"><img class="ss3k-ravatar" src="{esc(avatar)}" alt=""><div class="ss3k-rcontent"><div class="ss3k-rname">{esc(name)}</div><div class="ss3k-rtext">{text}</div></div></div>')
          open(repl,"w").write("\\n".join(blocks))
          doms=defaultdict(set)
          def add_urls(status):
              for u in getattr(status,"urls",[]) or []:
                  u2=getattr(u,"expanded_url",None) or getattr(u,"url",None)
                  if u2:
                      ext=tldextract.extract(u2); dom=".".join([p for p in [ext.domain,ext.suffix] if p]); doms[dom].add(u2)
          try: add_urls(root)
          except: pass
          for t in results:
              try: add_urls(t)
              except: pass
          lines=[]
          for dom in sorted(doms):
              lines.append(f"<h4>{esc(dom)}</h4>"); lines.append("<ul>")
              for u in sorted(doms[dom]): e=esc(u); lines.append(f'<li><a href="{e}" target="_blank" rel="noopener">{e}</a></li>')
              lines.append("</ul>")
          open(links,"w").write("\\n".join(lines))
          PY

          cat > ".github/workflows/scripts/polish_transcript.py" << 'PY'
          #!/usr/bin/env python3
          import os, re, html
          from typing import List, Tuple

          ARTDIR = os.environ.get("ARTDIR",".")
          BASE   = os.environ.get("BASE","space")
          INP    = os.path.join(ARTDIR, f"{BASE}_transcript.html")
          OUT    = os.path.join(ARTDIR, f"{BASE}_transcript_polished.html")

          USE_GEC = os.environ.get("TRANSCRIPT_GEC", "true").lower() in ("1","true","yes","on")
          GEC_MODEL = os.environ.get("TRANSCRIPT_GEC_MODEL", "prithivida/grammar_error_correcter_v1")
          GEC_MAX_LINES = int(os.environ.get("TRANSCRIPT_GEC_MAX_LINES", "0"))  # 0 means unlimited
          GEC_BATCH_SIZE = int(os.environ.get("TRANSCRIPT_GEC_BATCH", "4"))
          GEC_SELECT = os.environ.get("TRANSCRIPT_GEC_SELECT", "auto")

          if not os.path.exists(INP) or os.path.getsize(INP) == 0:
              raise SystemExit(0)

          with open(INP, "r", encoding="utf-8", errors="ignore") as f:
              raw_html = f.read()

          TEXT_SPAN_RE = re.compile(r'(<span\\s+class="ss3k-text"[^>]*>)(.*?)(</span>)', re.S | re.I)
          URL_RE = re.compile(r"https?://[^\\s<>\\"]+")

          FILLER_WORDS = [
              r"uh+", r"um+", r"er+", r"ah+", r"mm+h*", r"hmm+", r"eh+", r"uh\\-huh", r"uhhuh", r"uh\\-uh", r"uhuh",
          ]
          FILLER_PHRASES = [
              r"you\\s+know", r"i\\s+mean", r"kind\\s+of", r"sort\\s+of", r"you\\s+see",
          ]
          FILLERS_RE = re.compile(r"\\b(?:" + "|".join(FILLER_WORDS + FILLER_PHRASES) + r")\\b", re.I)
          STUTTER_RE = re.compile(r"\\b([A-Za-z])(?:\\s+\\1\\b){1,5}")
          REPEAT_RE  = re.compile(r"\\b([A-Za-z]{2,})\\b(?:\\s+\\1\\b){1,4}", re.I)

          def sentence_case(s: str) -> str:
              s = re.sub(r"\\bi\\b", "I", s)
              def cap_first(m):
                  pre = m.group(1) or ""
                  ch  = m.group(2).upper()
                  return pre + ch
              s = re.sub(r"(^|\\.\\s+|\\?\\s+|!\\s+)([a-z])", cap_first, s)
              return s

          def ensure_end_punct(s: str) -> str:
              t = s.rstrip()
              if not t: return s
              if t[-1] in ".!?\\\":)””’'»]>": return s
              if len(re.findall(r"\\b\\w+\\b", t)) >= 6 and not URL_RE.search(t[-40:]):
                  return t + "."
              return s

          def match_case(repl: str, orig: str) -> str:
              if orig.isupper(): return repl.upper()
              if orig.islower(): return repl.lower()
              if orig[:1].isupper() and orig[1:].islower(): return repl.capitalize()
              return repl

          EGGCORNS = [
              (r"\\byouth\\s*[- ]\\s*in\\s*[- ]\\s*asia\\b", "euthanasia"),
              (r"\\beuthin(?:a|e)sia\\b", "euthanasia"),
              (r"\\bcould\\s+of\\b", "could have"),
              (r"\\bshould\\s+of\\b", "should have"),
              (r"\\bwould\\s+of\\b", "would have"),
              (r"\\bmute\\s+point\\b", "moot point"),
              (r"\\bfor\\s+all\\s+intensive\\s+purposes\\b", "for all intents and purposes"),
              (r"\\bcase\\s+and\\s+point\\b", "case in point"),
              (r"\\bdeep\\s+seeded\\b", "deep-seated"),
              (r"\\bslight\\s+of\\s+hand\\b", "sleight of hand"),
              (r"\\bescape\\s+goat\\b", "scapegoat"),
              (r"\\bbaited\\s+breath\\b", "bated breath"),
              (r"\\bpeaked\\s+my\\s+interest\\b", "piqued my interest"),
              (r"\\bwet\\s+your\\s+appetite\\b", "whet your appetite"),
              (r"\\btounge\\b", "tongue"),
              (r"\\btounge\\s*[- ]\\s*in\\s*[- ]\\s*cheek\\b", "tongue-in-cheek"),
              (r"\\btow\\s+the\\s+line\\b", "toe the line"),
              (r"\\bplay\\s+it\\s+by\\s+year\\b", "play it by ear"),
              (r"\\bfree\\s+reign\\b", "free rein"),
              (r"\\bold\\s*[- ]?\\s*timer'?s\\s+disease\\b", "Alzheimer's disease"),
              (r"\\bwreckless\\s+driving\\b", "reckless driving"),
              (r"\\bminus\\s+well\\b", "might as well"),
              (r"\\bfirst\\s+come\\s*,?\\s*first\\s+serve\\b", "first come, first served"),
              (r"\\bnip\\s+it\\s+in\\s+the\\s+butt\\b", "nip it in the bud"),
              (r"\\bhome\\s+in\\s+on\\b", "home in on"),
              (r"\\bhone\\s+in\\s+on\\b", "home in on"),
              (r"\\bchest\\s*[- ]\\s*of\\s*[- ]\\s*drawers\\b", "chest of drawers"),
          ]
          EGG_REPLACERS = [(re.compile(p, re.I), r) for p, r in EGGCORNS]

          def apply_eggcorns(s: str) -> str:
              def sub_with_case(rx, rep, txt):
                  def _f(m): return match_case(rep, m.group(0))
                  return rx.sub(_f, txt)
              for rx, rep in EGG_REPLACERS:
                  s = sub_with_case(rx, rep, s)
              return s

          def protect_urls(s: str) -> Tuple[str, List[str]]:
              urls = []
              def stash(m):
                  urls.append(m.group(0))
                  return f"<<<URL{len(urls)-1}>>>"
              return URL_RE.sub(stash, s), urls

          def restore_urls(s: str, urls: List[str]) -> str:
              for i,u in enumerate(urls):
                  s = s.replace(f"<<<URL{i}>>>", u)
              return s

          def clean_text(txt: str) -> str:
              if not txt.strip(): return txt
              txt, urls = protect_urls(txt)
              txt = FILLERS_RE.sub("", txt)
              txt = STUTTER_RE.sub(lambda m: m.group(1), txt)
              txt = REPEAT_RE.sub(lambda m: m.group(1), txt)
              txt = re.sub(r"\\s{2,}", " ", txt).strip()
              txt = re.sub(r"\\bi\\b", "I", txt)
              txt = re.sub(r"\\s+([,.;:!?])", r"\\1", txt)
              txt = re.sub(r"([,;:])([^\\s])", r"\\1 \\2", txt)
              txt = apply_eggcorns(txt)
              txt = sentence_case(txt)
              txt = ensure_end_punct(txt)
              txt = restore_urls(txt, urls)
              txt = txt.replace("<","&lt;").replace(">","&gt;")
              return txt

          spans: List[str] = []
          def _collect(m):
              spans.append(m.group(2))
              return m.group(0)
          _ = TEXT_SPAN_RE.sub(_collect, raw_html)

          cleaned = [clean_text(t) for t in spans]

          def quality_score(s: str) -> float:
              plain = html.unescape(s)
              longness = min(len(plain), 2000) / 10.0
              no_punct = 15.0 if not re.search(r"[.!?]", plain) else 0.0
              mostly_lower = 12.0 if (re.sub(r"[^A-Za-z]+","",plain).islower() and len(plain) > 20) else 0.0
              many_commas = -3.0 if plain.count(",") >= 3 else 0.0
              return longness + no_punct + mostly_lower + many_commas

          indices = list(range(len(cleaned)))
          if GEC_MAX_LINES and GEC_MAX_LINES > 0:
              if GEC_SELECT == "first":
                  candidate_idxs = indices[:GEC_MAX_LINES]
              else:
                  if GEC_SELECT == "longest":
                      scored = sorted(indices, key=lambda i: len(cleaned[i]), reverse=True)
                  else:
                      scored = sorted(indices, key=lambda i: quality_score(cleaned[i]), reverse=True)
                  candidate_idxs = scored[:max(0, min(GEC_MAX_LINES, len(scored)))]
          else:
              candidate_idxs = indices

          def apply_gec(lines: List[str]) -> List[str]:
              try:
                  from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
                  import torch
              except Exception:
                  return lines
              try:
                  tok = AutoTokenizer.from_pretrained(GEC_MODEL)
                  mdl = AutoModelForSeq2SeqLM.from_pretrained(GEC_MODEL)
                  mdl.eval()
                  device = torch.device("cpu")
                  mdl.to(device)
              except Exception:
                  return lines

              out: List[str] = []
              buf: List[str] = []
              url_buckets: List[List[str]] = []

              def protect_urls_for_model(line: str):
                  pl = html.unescape(line)
                  urls=[]
                  def stash(m):
                      urls.append(m.group(0))
                      return f"<<<URL{len(urls)-1}>>>"
                  return re.sub(r"https?://[^\\s<>\\"]+", stash, pl), urls

              def flush():
                  nonlocal out, buf, url_buckets
                  if not buf: return
                  inputs = [("gec: " + b) for b in buf]
                  enc = tok(inputs, return_tensors="pt", padding=True, truncation=True, max_length=512)
                  with torch.no_grad():
                      gen = mdl.generate(
                          input_ids=enc["input_ids"],
                          attention_mask=enc["attention_mask"],
                          max_new_tokens=96,
                          num_beams=4,
                          length_penalty=1.0,
                          early_stopping=True,
                      )
                  outs = tok.batch_decode(gen, skip_special_tokens=True)
                  for i, o in enumerate(outs):
                      o = o.strip()
                      o = o.replace("<","&lt;").replace(">","&gt;")
                      o = ensure_end_punct(sentence_case(o))
                      out.append(o)
                  buf = []; url_buckets = []

              for line in lines:
                  pl, urls = protect_urls_for_model(line)
                  url_buckets.append(urls)
                  buf.append(pl)
                  if len(buf) >= GEC_BATCH_SIZE:
                      flush()
              flush()
              return out

          if USE_GEC and candidate_idxs:
              selected = [cleaned[i] for i in candidate_idxs]
              corrected = apply_gec(selected)
              for pos, idx in enumerate(candidate_idxs):
                  cleaned[idx] = corrected[pos]

          it = iter(cleaned)
          def _replace(m):
              open_tag, _, close_tag = m.group(1), m.group(2), m.group(3)
              try:
                  new_text = next(it)
              except StopIteration:
                  new_text = m.group(2)
              return f"{open_tag}{new_text}{close_tag}"

          polished_html = TEXT_SPAN_RE.sub(_replace, raw_html)
          polished_html = re.sub(r"\\n{3,}", "\\n\\n", polished_html)

          with open(OUT, "w", encoding="utf-8") as f:
              f.write(polished_html)
          PY

      - name: Build VTT and transcript after trim
        if: ${{ github.event.inputs.mode != 'attendees_only' && github.event.inputs.mode != 'replies_only' }}
        shell: bash
        env:
          CC_JSONL: ${{ env.CRAWLER_CC }}
          SHIFT_SECS: ${{ steps.detect.outputs.lead || '0' }}
        run: |
          set -euxo pipefail
          if [ -n "${CC_JSONL:-}" ] && [ -s "${CC_JSONL}" ]; then
            CC_JSONL="${CC_JSONL}" ARTDIR="${ARTDIR}" BASE="${BASE}" SHIFT_SECS="${SHIFT_SECS}" \
              python3 ".github/workflows/scripts/gen_vtt.py"
            [ -s "${ARTDIR}/${BASE}.vtt" ] && echo "VTT_PATH=${ARTDIR}/${BASE}.vtt" >> "$GITHUB_ENV" || true
            [ -s "${ARTDIR}/${BASE}_transcript.html" ] && echo "TRANSCRIPT_PATH=${ARTDIR}/${BASE}_transcript.html" >> "$GITHUB_ENV" || true
          fi

      - name: Polish transcript with rules and free GEC
        if: ${{ github.event.inputs.mode != 'attendees_only' && github.event.inputs.mode != 'replies_only' }}
        shell: bash
        env:
          TRANSCRIPT_GEC: "true"
          TRANSCRIPT_GEC_MAX_LINES: "0"
          TRANSCRIPT_GEC_MODEL: "prithivida/grammar_error_correcter_v1"
          TRANSCRIPT_GEC_SELECT: "auto"
        run: |
          set -euxo pipefail
          python3 ".github/workflows/scripts/polish_transcript.py" || true

      - name: VTT via Deepgram fallback
        id: deepgram
        if: ${{ github.event.inputs.mode != 'attendees_only' && github.event.inputs.mode != 'replies_only' && env.VTT_PATH == '' && env.DEEPGRAM_API_KEY != '' && github.event.inputs.do_transcript == 'true' && env.MP3_PATH != '' }}
        shell: bash
        run: |
          set -euxo pipefail
          curl -sS -X POST \
            -H "Authorization: Token ${DEEPGRAM_API_KEY}" \
            -H "Content-Type: audio/mpeg" \
            --data-binary @"${MP3_PATH}" \
            "https://api.deepgram.com/v1/listen?model=nova-2&smart_format=true&punctuate=true&format=vtt" \
            -o "${ARTDIR}/${BASE}.vtt" || true
          [ -s "${ARTDIR}/${BASE}.vtt" ] && echo "VTT_PATH=${ARTDIR}/${BASE}.vtt" >> "$GITHUB_ENV" || true

      - name: Upload VTT to GCS
        id: upload_vtt
        if: ${{ github.event.inputs.mode != 'attendees_only' && github.event.inputs.mode != 'replies_only' && env.VTT_PATH != '' }}
        shell: bash
        run: |
          set -euxo pipefail
          DEST="gs://${GCS_BUCKET}/${BUCKET_PREFIX}/${BASE}.vtt"
          RAW="https://storage.googleapis.com/${GCS_BUCKET}/${BUCKET_PREFIX}/${BASE}.vtt"
          PROXY="https://media.chbmp.org/${PREFIX}/${BASE}.vtt"
          gsutil -m cp "${VTT_PATH}" "$DEST"
          if [ "${{ github.event.inputs.make_public }}" = "true" ]; then
            (gsutil acl ch -u AllUsers:R "$DEST" || gsutil iam ch allUsers:objectViewer "gs://${GCS_BUCKET}") || true
          fi
          echo "vtt_raw=${RAW}"     >> "$GITHUB_OUTPUT"
          echo "vtt_proxy=${PROXY}" >> "$GITHUB_OUTPUT"

      - name: Build attendees HTML
        id: attendees
        if: ${{ github.event.inputs.mode != 'replies_only' && steps.crawl.outcome == 'success' && steps.crawl.outputs.as_line != '' }}
        shell: bash
        env:
          CAND: ${{ steps.crawl.outputs.as_line }}
        run: |
          set -euxo pipefail
          OUT_JSON="${ARTDIR}/attendees.json"
          OUT_HTML="${ARTDIR}/attendees.html"
          jq -r '
            def mkp:
              { handle: (.twitter_screen_name // .user_results?.result?.legacy?.screen_name),
                name:   (.display_name       // .user_results?.result?.legacy?.name)
              }
              | select(.handle!=null and .handle!="")
              | . + { url: ("https://x.com/" + .handle) };
            (.audioSpace // .) as $a
            | ($a.metadata?.creator_results?.result?.legacy?) as $h
            | ($h.screen_name // empty) as $H
            | {
                host:    ( if $H != "" then [ {handle:$H, name:($h.name // ""), url:("https://x.com/" + $H)} ] else [] end ),
                cohosts: ( ($a.participants?.admins   // []) | map(mkp) | map(select(.handle != $H)) | unique_by(.handle) ),
                speakers:( ($a.participants?.speakers // []) | map(mkp) | unique_by(.handle) )
              }
          ' "${CAND}" > "$OUT_JSON" || true
          if [ -s "$OUT_JSON" ]; then
            jq -r '
              def li: "  <li><a href=\"" + (.url//"#") + "\">" + ((.name // "") + " (@" + (.handle // "") + ")") + "</a></li>";
              def section(title; items):
                if (items|length) > 0
                then "<h3>" + title + "</h3>\n<ul>\n" + (items|map(li)|join("\n")) + "\n</ul>\n"
                else ""
                end;
              . as $d
              | section("Host"; $d.host)
              + section( (if ($d.cohosts|length)==1 then "Co-host" else "Co-hosts" end); $d.cohosts)
              + section("Speakers"; $d.speakers)
            ' "$OUT_JSON" > "$OUT_HTML"
            if grep -qi '<li><a ' "$OUT_HTML"; then
              echo "ATTN_HTML=${OUT_HTML}" >> "$GITHUB_ENV"
              echo "ATTENDEES_OK=1"       >> "$GITHUB_ENV"
            fi
          fi

      - name: Scrape replies and shared links
        shell: bash
        env:
          PURPLE_TWEET_URL: ${{ github.event.inputs.purple_tweet_url }}
        run: |
          set -euo pipefail
          set +e
          python3 ".github/workflows/scripts/replies.py"
          rc=$?
          set -e
          if [ -s "${ARTDIR}/${BASE}_replies.html" ]; then
            echo "REPLIES_PATH=${ARTDIR}/${BASE}_replies.html" >> "$GITHUB_ENV"
          fi
          if [ -s "${ARTDIR}/${BASE}_links.html" ]; then
            echo "LINKS_PATH=${ARTDIR}/${BASE}_links.html" >> "$GITHUB_ENV"
          fi

      - name: Register assets in WP
        if: ${{ github.event.inputs.mode == '' && env.WP_BASE_URL != '' && env.WP_USER != '' && env.WP_APP_PASSWORD != '' && github.event.inputs.post_id != '' && (steps.upload_mp3.outputs.audio_proxy != '' || steps.upload_mp3.outputs.audio_raw != '') }}
        shell: bash
        env:
          PID:  ${{ github.event.inputs.post_id }}
          AUD:  ${{ steps.upload_mp3.outputs.audio_proxy || steps.upload_mp3.outputs.audio_raw }}
          VTTU: ${{ steps.upload_vtt.outputs.vtt_proxy   || steps.upload_vtt.outputs.vtt_raw }}
        run: |
          set -euo pipefail
          TTL="${TTL_FINAL:-${{ github.event.inputs.title }}}"
          [ -z "$TTL" ] && TTL="${BASE}"

          ATH_FILE="${WORKDIR}/empty_attendees.html"; : > "$ATH_FILE"
          [ -n "${ATTN_HTML:-}" ] && [ -s "${ATTN_HTML:-}" ] && ATH_FILE="${ATTN_HTML}"

          TR_FILE="${WORKDIR}/empty_transcript.html"; : > "$TR_FILE"
          if [ -s "${ARTDIR}/${BASE}_transcript_polished.html" ]; then
            TR_FILE="${ARTDIR}/${BASE}_transcript_polished.html"
          elif [ -s "${ARTDIR}/${BASE}_transcript.html" ]; then
            TR_FILE="${ARTDIR}/${BASE}_transcript.html"
          fi

          REP_FILE="${WORKDIR}/empty_replies.html"; : > "$REP_FILE"
          [ -n "${REPLIES_PATH:-}" ] && [ -s "${REPLIES_PATH}" ] && REP_FILE="${REPLIES_PATH}"

          LNK_FILE="${WORKDIR}/empty_links.html"; : > "$LNK_FILE"
          [ -n "${LINKS_PATH:-}" ] && [ -s "${LINKS_PATH}" ] && LNK_FILE="${LINKS_PATH}"

          REQ="${WORKDIR}/wp_register_body.json"
          jq -n \
            --arg gcs   "${AUD}" \
            --arg mime  "audio/mpeg" \
            --arg pid   "${PID}" \
            --arg ttl   "${TTL}" \
            --arg vtt   "${VTTU}" \
            --rawfile ath "${ATH_FILE}" \
            --rawfile tr  "${TR_FILE}" \
            --rawfile rep "${REP_FILE}" \
            --rawfile lnk "${LNK_FILE}" \
            '{
               gcs_url: $gcs,
               mime:    $mime,
               post_id: ($pid|tonumber),
               title:   $ttl
             }
             + (if ($vtt|length)>0 then {vtt_url:$vtt} else {} end)
             + (if ($ath|gsub("\\s";"")|length)>0 then {attendees_html:$ath} else {} end)
             + (if ($tr|gsub("\\s";"")|length)>0 then {transcript:$tr, has_transcript:true} else {} end)
             + (if ($rep|gsub("\\s";"")|length)>0 then {ss3k_replies_html:$rep} else {} end)
             + (if ($lnk|gsub("\\s";"")|length)>0 then {ss3k_shared_links_html:$lnk} else {} end)
            ' > "$REQ"

          curl -sS -u "${WP_USER}:${WP_APP_PASSWORD}" \
            -H "Content-Type: application/json" \
            -X POST "${WP_BASE_URL%/}/wp-json/ss3k/v1/register" \
            --data-binary @"$REQ" | jq -r .

      - name: Patch WP attendees only
        if: ${{ github.event.inputs.mode == 'attendees_only' && env.WP_BASE_URL != '' && env.WP_USER != '' && env.WP_APP_PASSWORD != '' && github.event.inputs.post_id != '' }}
        shell: bash
        run: |
          set -euo pipefail
          AT_HTML=""
          if [ -n "${ATTN_HTML:-}" ] && [ -s "${ATTN_HTML:-}" ]; then AT_HTML="$(cat "${ATTN_HTML}")"; fi
          BODY="$(jq -n --arg pid "${{ github.event.inputs.post_id }}" --arg ath "${AT_HTML}" \
            '{post_id: ($pid|tonumber), status:"complete", progress:100}
             + (if ($ath|length)>0 then {attendees_html:$ath} else {} end)')"
          curl -sS -u "${WP_USER}:${WP_APP_PASSWORD}" -H "Content-Type: application/json" \
            -X POST "${WP_BASE_URL%/}/wp-json/ss3k/v1/patch-assets" -d "$BODY" | jq -r .

      - name: Patch WP replies only
        if: ${{ github.event.inputs.mode == 'replies_only' && env.WP_BASE_URL != '' && env.WP_USER != '' && env.WP_APP_PASSWORD != '' && github.event.inputs.post_id != '' }}
        shell: bash
        run: |
          set -euo pipefail
          REP="$( [ -n "${REPLIES_PATH:-}" ] && [ -s "${REPLIES_PATH:-}" ] && cat "${REPLIES_PATH}" || echo "" )"
          LNK="$( [ -n "${LINKS_PATH:-}" ] && [ -s "${LINKS_PATH:-}" ] && cat "${LINKS_PATH}" || echo "" )"
          BODY="$(jq -n --arg pid "${{ github.event.inputs.post_id }}" --arg rep "${REP}" --arg lnk "${LNK}" \
            '{post_id: ($pid|tonumber), status:"complete", progress:100}
             + (if ($rep|length)>0 then {ss3k_replies_html:$rep} else {} end)
             + (if ($lnk|length)>0 then {ss3k_shared_links_html:$lnk} else {} end)')"
          curl -sS -u "${WP_USER}:${WP_APP_PASSWORD}" -H "Content-Type: application/json" \
            -X POST "${WP_BASE_URL%/}/wp-json/ss3k/v1/patch-assets" -d "$BODY" | jq -r .

      - name: Summary
        shell: bash
        env:
          SID: ${{ steps.ids.outputs.space_id }}
        run: |
          {
            echo "### Space Worker Summary"
            echo "- Mode ${{ github.event.inputs.mode }}"
            echo "- Space URL ${{ github.event.inputs.space_url }}"
            echo "- Purple URL ${{ github.event.inputs.purple_tweet_url }}"
            echo "- Space ID ${SID}"
            echo "- Post ID ${{ github.event.inputs.post_id }}"
            if [ -n "${{ steps.upload_mp3.outputs.audio_proxy }}" ]; then
              echo "- Audio ${{ steps.upload_mp3.outputs.audio_proxy }}"
            elif [ -n "${{ steps.upload_mp3.outputs.audio_raw }}" ]; then
              echo "- Audio ${{ steps.upload_mp3.outputs.audio_raw }}"
            fi
            if [ -n "${{ steps.upload_vtt.outputs.vtt_proxy }}" ]; then
              echo "- VTT ${{ steps.upload_vtt.outputs.vtt_proxy }}"
            elif [ -n "${{ steps.upload_vtt.outputs.vtt_raw }}" ]; then
              echo "- VTT ${{ steps.upload_vtt.outputs.vtt_raw }}"
            fi
          } >> "$GITHUB_STEP_SUMMARY"
