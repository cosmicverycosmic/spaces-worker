name: Space Worker

on:
  workflow_dispatch:
    inputs:
      space_url:
        description: X or Twitter Space URL
        required: false
        type: string
        default: ""
      post_id:
        description: Existing WordPress post ID optional
        required: false
        type: string
        default: ""
      gcs_prefix:
        description: GCS prefix default spaces YYYY MM
        required: false
        type: string
        default: ""
      make_public:
        description: Make uploaded artifacts public
        required: false
        type: choice
        options: ["true","false"]
        default: "true"
      do_transcript:
        description: Generate transcript when captions are not available
        required: false
        type: choice
        options: ["true","false"]
        default: "true"
      mode:
        description: Limit processing
        required: false
        type: choice
        options: ["","transcript_only","attendees_only","replies_only"]
        default: ""
      existing_mp3_url:
        description: For transcript only provide URL to existing MP3
        required: false
        type: string
        default: ""
      aggressive_denoise:
        description: Use RNNoise arnndn denoiser
        required: false
        type: choice
        options: ["false","true"]
        default: "false"
      purple_tweet_url:
        description: Purple pill tweet URL optional
        required: false
        type: string
        default: ""
      audio_profile:
        description: Audio profile for encode (default 'radio')
        required: false
        type: choice
        options: ["transparent","radio","aggressive"]
        default: "radio"

permissions:
  contents: read
  packages: read

env:
  GCP_SA_KEY:       ${{ secrets.GCP_SA_KEY       || vars.GCP_SA_KEY }}
  GCS_BUCKET:       ${{ secrets.GCS_BUCKET       || vars.GCS_BUCKET }}
  WP_BASE_URL:      ${{ secrets.WP_BASE_URL      || secrets.WP_URL || vars.WP_BASE_URL || vars.WP_URL }}
  WP_USER:          ${{ secrets.WP_USER          || vars.WP_USER }}
  WP_APP_PASSWORD:  ${{ secrets.WP_APP_PASSWORD  || vars.WP_APP_PASSWORD }}
  DEEPGRAM_API_KEY: ${{ secrets.DEEPGRAM_API_KEY || vars.DEEPGRAM_API_KEY }}

  TWITTER_AUTHORIZATION: ${{ secrets.TWITTER_AUTHORIZATION || secrets.X_BEARER     || vars.TWITTER_AUTHORIZATION || vars.X_BEARER }}
  TWITTER_AUTH_TOKEN:    ${{ secrets.TWITTER_AUTH_TOKEN    || secrets.X_AUTH_TOKEN || vars.TWITTER_AUTH_TOKEN    || vars.X_AUTH_TOKEN }}
  TWITTER_CSRF_TOKEN:    ${{ secrets.TWITTER_CSRF_TOKEN    || secrets.X_CSRF       || vars.TWITTER_CSRF_TOKEN    || vars.X_CSRF }}

  TW_API_CONSUMER_KEY:        ${{ secrets.TW_API_CONSUMER_KEY        || vars.TW_API_CONSUMER_KEY }}
  TW_API_CONSUMER_SECRET:     ${{ secrets.TW_API_CONSUMER_SECRET     || vars.TW_API_CONSUMER_SECRET }}
  TW_API_ACCESS_TOKEN:        ${{ secrets.TW_API_ACCESS_TOKEN        || vars.TW_API_ACCESS_TOKEN }}
  TW_API_ACCESS_TOKEN_SECRET: ${{ secrets.TW_API_ACCESS_TOKEN_SECRET || vars.TW_API_ACCESS_TOKEN_SECRET }}

  WORKDIR: ${{ github.workspace }}/work
  ARTDIR:  ${{ github.workspace }}/out

jobs:
  process:
    name: Process Space
    runs-on: ubuntu-latest
    timeout-minutes: 180
    concurrency:
      group: ${{ format('space-worker-{0}-{1}', github.ref, github.event.inputs.post_id != '' && github.event.inputs.post_id || github.run_id) }}
      cancel-in-progress: false

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Notify WP queued
        if: ${{ env.WP_BASE_URL != '' && env.WP_USER != '' && env.WP_APP_PASSWORD != '' && github.event.inputs.post_id != '' && github.event.inputs.mode != 'replies_only' }}
        shell: bash
        run: |
          set -euo pipefail
          curl -sS -u "${WP_USER}:${WP_APP_PASSWORD}" \
            -H "Content-Type: application/json" \
            -X POST "${WP_BASE_URL%/}/wp-json/ss3k/v1/worker-status" \
            -d "$(jq -n --arg pid "${{ github.event.inputs.post_id }}" \
                       --arg status "queued" \
                       --arg msg "Workflow received and queued" \
                       --arg run "${{ github.run_id }}" \
                       --argjson progress 1 \
                       '{post_id: ($pid|tonumber), status:$status, message:$msg, run_id:$run, progress:$progress}')"

      - name: Install deps
        shell: bash
        run: |
          set -euxo pipefail
          sudo apt-get update
          sudo apt-get install -y --no-install-recommends ffmpeg jq python3 python3-pip ca-certificates gnupg
          python3 -m pip install --upgrade pip
          python3 -m pip install --no-cache-dir yt-dlp python-twitter tldextract
          echo "deb [signed-by=/usr/share/keyrings/cloud.google.gpg] http://packages.cloud.google.com/apt cloud-sdk main" | sudo tee /etc/apt/sources.list.d/google-cloud-sdk.list
          curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo gpg --dearmor -o /usr/share/keyrings/cloud.google.gpg
          sudo apt-get update && sudo apt-get install -y google-cloud-sdk
          echo "${{ github.token }}" | docker login ghcr.io -u "${{ github.actor }}" --password-stdin || true

      - name: Validate config and prefixes
        id: cfg
        shell: bash
        run: |
          set -euxo pipefail
          test -n "${GCP_SA_KEY}" || { echo "GCP_SA_KEY missing"; exit 1; }
          test -n "${GCS_BUCKET}" || { echo "GCS_BUCKET missing"; exit 1; }
          mkdir -p "$WORKDIR" "$ARTDIR" "$ARTDIR/logs" ".github/workflows/scripts"
          PFX="$(echo "${{ github.event.inputs.gcs_prefix }}" | sed -E 's#^/*##; s#/*$##')"
          if [ -z "$PFX" ]; then PFX="spaces/$(date +%Y)/$(date +%m)"; fi
          echo "PREFIX=$PFX"                  >> "$GITHUB_ENV"
          echo "BUCKET_PREFIX=${PFX#spaces/}" >> "$GITHUB_ENV"

      - name: Derive Space ID and base
        id: ids
        shell: bash
        env:
          URL: ${{ github.event.inputs.space_url }}
        run: |
          set -euxo pipefail
          SID=""
          if [ -n "$URL" ]; then
            SID="$(echo "$URL" | sed -nE 's#^.*/i/spaces/([^/?#]+).*#\1#p')"
          fi
          [ -z "$SID" ] && SID="unknown"
          BASE="space-$(date +%m-%d-%Y)-${SID}"
          echo "SPACE_ID=${SID}" >> "$GITHUB_ENV"
          echo "BASE=${BASE}"    >> "$GITHUB_ENV"
          echo "space_id=${SID}" >> "$GITHUB_OUTPUT"
          echo "base=${BASE}"    >> "$GITHUB_OUTPUT"

      - name: GCP auth
        if: ${{ github.event.inputs.mode != 'replies_only' }}
        shell: bash
        run: |
          set -euxo pipefail
          printf '%s' "${GCP_SA_KEY}" > "${HOME}/gcp-key.json"
          gcloud auth activate-service-account --key-file="${HOME}/gcp-key.json" >/dev/null

      - name: X preflight auth
        id: x_preflight
        if: ${{ github.event.inputs.mode != 'replies_only' }}
        shell: bash
        run: |
          set -euo pipefail
          AUTH="${TWITTER_AUTHORIZATION:-}"
          AT="${TWITTER_AUTH_TOKEN:-}"
          CT="${TWITTER_CSRF_TOKEN:-}"
          if [ -n "$AUTH" ] && ! printf '%s' "$AUTH" | grep -q '^Bearer '; then AUTH=""; fi
          [ -n "${TWITTER_AUTHORIZATION:-}" ] && echo "::add-mask::${TWITTER_AUTHORIZATION}"
          [ -n "$AT" ] && echo "::add-mask::${AT}"
          [ -n "$CT" ] && echo "::add-mask::${CT}"
          OK=0; REASON="no_creds"
          [ -n "$AT" ] && [ -n "$CT" ] && OK=1 && REASON="cookie_ok" || true
          [ -n "$AUTH" ] && OK=1 && REASON="${REASON}_bearer_present" || true
          echo "ok=${OK}"         >> "$GITHUB_OUTPUT"
          echo "reason=${REASON}" >> "$GITHUB_OUTPUT"
          [ -n "$AUTH" ] && echo "TWITTER_AUTHORIZATION=$AUTH" >> "$GITHUB_ENV"

      - name: Run crawler
        id: crawl
        if: ${{ github.event.inputs.mode != 'replies_only' && steps.x_preflight.outputs.ok == '1' }}
        shell: bash
        env:
          SID: ${{ steps.ids.outputs.space_id }}
        run: |
          set -euxo pipefail
          mkdir -p "${ARTDIR}" "${ARTDIR}/logs"
          docker pull ghcr.io/hitomarukonpaku/twspace-crawler:latest || true
          LOG_STD="${ARTDIR}/logs/crawler_${SID}.out.log"
          LOG_ERR="${ARTDIR}/logs/crawler_${SID}.err.log"
          set +e
          timeout 20m docker run --rm \
            -e TWITTER_AUTHORIZATION \
            -e TWITTER_AUTH_TOKEN \
            -e TWITTER_CSRF_TOKEN \
            -v "${ARTDIR}:/app/download" \
            -v "${ARTDIR}/logs:/app/logs" \
            ghcr.io/hitomarukonpaku/twspace-crawler:latest \
            --id "${SID}" --force > >(tee -a "$LOG_STD") 2> >(tee -a "$LOG_ERR" >&2)
          RC=$?
          set -e
          echo "crawler_exit=${RC}"
          AUDIO_FILE="$(find "${ARTDIR}" -type f \( -iname '*.m4a' -o -iname '*.mp3' -o -iname '*.mp4' -o -iname '*.aac' -o -iname '*.webm' -o -iname '*.ogg' -o -iname '*.wav' -o -iname '*.ts' \) -printf '%T@ %p\n' | sort -nr | head -n1 | cut -d' ' -f2- || true)"
          if [ -n "${AUDIO_FILE:-}" ] && [ -f "${AUDIO_FILE}" ]; then
            echo "INPUT_FILE=${AUDIO_FILE}" >> "$GITHUB_ENV"
            echo "audio_file=${AUDIO_FILE}" >> "$GITHUB_OUTPUT"
          fi
          RAW="$(grep -hF 'getAudioSpaceById |' "$LOG_STD" "$LOG_ERR" | tail -n1 || true)"
          if [ -z "$RAW" ]; then
            RAW="$(grep -hF 'getAudioSpaceByRestId |' "$LOG_STD" "$LOG_ERR" | tail -n1 || true)"
          fi
          if [ -n "$RAW" ]; then
            printf '%s\n' "$RAW" | awk -F'\\| ' '{print $NF}' > "${ARTDIR}/_as_line.json" || true
          fi
          [ -s "${ARTDIR}/_as_line.json" ] && echo "as_line=${ARTDIR}/_as_line.json" >> "$GITHUB_OUTPUT" || true
          CC_JSONL="$(find "${ARTDIR}" -type f \( -iname '*cc.jsonl' -o -iname '*caption*.jsonl' -o -iname '*captions*.jsonl' \) -print | head -n1 || true)"
          if [ -n "${CC_JSONL:-}" ]; then
            echo "CRAWLER_CC=${CC_JSONL}" >> "$GITHUB_ENV"
          fi

      - name: Fallback download via yt dlp
        if: ${{ github.event.inputs.mode != 'attendees_only' && github.event.inputs.mode != 'replies_only' && (steps.crawl.outputs.audio_file == '' || steps.crawl.outcome != 'success') && github.event.inputs.existing_mp3_url == '' && github.event.inputs.space_url != '' }}
        shell: bash
        working-directory: ${{ env.WORKDIR }}
        env:
          URL: ${{ github.event.inputs.space_url }}
        run: |
          set -euxo pipefail
          yt-dlp -o "%(title)s.%(ext)s" -f "bestaudio/best" "$URL"
          IN="$(ls -S | head -n1 || true)"
          test -f "$IN" || { echo "No file downloaded"; exit 1; }
          echo "INPUT_FILE=$PWD/$IN" >> "$GITHUB_ENV"

      - name: Use provided MP3 for transcript only
        if: ${{ github.event.inputs.mode == 'transcript_only' && github.event.inputs.existing_mp3_url != '' }}
        shell: bash
        run: |
          set -euxo pipefail
          curl -L "${{ github.event.inputs.existing_mp3_url }}" -o "${ARTDIR}/${BASE}.mp3"
          echo "INPUT_FILE=${ARTDIR}/${BASE}.mp3" >> "$GITHUB_ENV"

      - name: Detect lead silence seconds
        id: detect
        if: ${{ github.event.inputs.mode != 'attendees_only' && github.event.inputs.mode != 'replies_only' && env.INPUT_FILE != '' }}
        shell: bash
        run: |
          set -euxo pipefail
          LOG="${WORKDIR}/silence.log"
          ffmpeg -hide_banner -i "$INPUT_FILE" -af "silencedetect=noise=-45dB:d=1" -f null - 2> "$LOG" || true
          LEAD="$(awk '/silence_end/ {print $5; exit}' "$LOG" || true)"
          case "$LEAD" in ''|*[^0-9.]* ) LEAD="0.0" ;; esac
          echo "TRIM_LEAD=${LEAD}" >> "$GITHUB_ENV"
          echo "lead=${LEAD}"       >> "$GITHUB_OUTPUT"

      - name: Trim head and tail (RF64-safe)
        if: ${{ github.event.inputs.mode != 'attendees_only' && github.event.inputs.mode != 'replies_only' && env.INPUT_FILE != '' }}
        shell: bash
        run: |
          set -euxo pipefail
          TRIM_WAV="${WORKDIR}/trim_${{ github.run_id }}.wav"
          ffmpeg -hide_banner -y -i "$INPUT_FILE" \
            -af "silenceremove=start_periods=1:start_silence=1:start_threshold=-45dB:detection=peak,areverse,silenceremove=start_periods=1:start_silence=1:start_threshold=-45dB:detection=peak,areverse" \
            -rf64 always -c:a pcm_s16le "$TRIM_WAV"
          echo "AUDIO_IN=${TRIM_WAV}" >> "$GITHUB_ENV"

      - name: Probe audio format
        id: probe
        if: ${{ github.event.inputs.mode != 'attendees_only' && github.event.inputs.mode != 'replies_only' && env.AUDIO_IN != '' }}
        shell: bash
        run: |
          set -euxo pipefail
          J="$(ffprobe -v error -select_streams a:0 -show_entries stream=channels,sample_rate -of json "$AUDIO_IN")"
          CH=$(echo "$J" | jq -r '.streams[0].channels // 1')
          SR=$(echo "$J" | jq -r '.streams[0].sample_rate // "48000"')
          echo "SRC_CH=${CH}" >> "$GITHUB_ENV"
          echo "SRC_SR=${SR}" >> "$GITHUB_ENV"

      - name: Encode MP3 with selected profile
        if: ${{ github.event.inputs.mode != 'attendees_only' && github.event.inputs.mode != 'replies_only' && env.AUDIO_IN != '' }}
        shell: bash
        env:
          PROF: ${{ github.event.inputs.audio_profile != '' && github.event.inputs.audio_profile || 'radio' }}
        run: |
          set -euxo pipefail
          OUT="${ARTDIR}/${BASE}.mp3"
          CH="${SRC_CH:-1}"
          SR="${SRC_SR:-48000}"

          if [ "${PROF}" = "transparent" ]; then
            ffmpeg -hide_banner -y -i "$AUDIO_IN" -map a:0 -c:a libmp3lame -q:a 0 -ar "$SR" -ac "$CH" "$OUT"

          elif [ "${PROF}" = "radio" ]; then
            PRE="highpass=f=60,lowpass=f=14000,afftdn=nr=4:nf=-28,deesser=i=0.12,acompressor=threshold=-18dB:ratio=2:attack=12:release=220:makeup=2"
            PASS1_JSON="${WORKDIR}/loudnorm1.json"
            ffmpeg -hide_banner -y -i "$AUDIO_IN" -af "${PRE},loudnorm=I=-16:TP=-1.5:LRA=11:print_format=json" -f null - 2>"${WORKDIR}/pass1.log" || true
            awk '/^{/{f=1} f{print} /}/{f=0}' "${WORKDIR}/pass1.log" > "$PASS1_JSON" || true
            if jq -e . "$PASS1_JSON" >/dev/null 2>&1; then
              I=$(jq -r '.input_i // "-16"'  "$PASS1_JSON")
              TP=$(jq -r '.input_tp // "-1.5"' "$PASS1_JSON")
              LRA=$(jq -r '.input_lra // "11"' "$PASS1_JSON")
              TH=$(jq -r '.input_thresh // "-26"' "$PASS1_JSON")
              ffmpeg -hide_banner -y -i "$AUDIO_IN" \
                -af "${PRE},loudnorm=I=-16:TP=-1.5:LRA=11:measured_I=$I:measured_TP=$TP:measured_LRA=$LRA:measured_thresh=$TH:linear=true" \
                -c:a libmp3lame -q:a 2 -ar "$SR" -ac "$CH" "$OUT"
            else
              ffmpeg -hide_banner -y -i "$AUDIO_IN" \
                -af "${PRE},loudnorm=I=-16:TP=-1.5:LRA=11" \
                -c:a libmp3lame -q:a 2 -ar "$SR" -ac "$CH" "$OUT"
            fi

          else
            PRE="highpass=f=70,lowpass=f=11500,afftdn=nr=8:nf=-25,deesser=i=0.2,acompressor=threshold=-18dB:ratio=2.8:attack=8:release=200:makeup=3"
            if [ "${{ github.event.inputs.aggressive_denoise }}" = "true" ]; then
              M="${WORKDIR}/rnnoise.rnnn"
              curl -fsSL -o "$M" https://raw.githubusercontent.com/GregorR/rnnoise-models/master/heavyrnnoise.rnnn || true
              if [ -s "$M" ]; then PRE="arnndn=m=${M},${PRE}"; fi
            fi
            PASS1_JSON="${WORKDIR}/loudnorm1.json"
            ffmpeg -hide_banner -y -i "$AUDIO_IN" -af "${PRE},loudnorm=I=-16:TP=-1.5:LRA=11:print_format=json" -f null - 2>"${WORKDIR}/pass1.log" || true
            awk '/^{/{f=1} f{print} /}/{f=0}' "${WORKDIR}/pass1.log" > "$PASS1_JSON" || true
            if jq -e . "$PASS1_JSON" >/dev/null 2>&1; then
              I=$(jq -r '.input_i // "-16"'  "$PASS1_JSON")
              TP=$(jq -r '.input_tp // "-1.5"' "$PASS1_JSON")
              LRA=$(jq -r '.input_lra // "11"' "$PASS1_JSON")
              TH=$(jq -r '.input_thresh // "-26"' "$PASS1_JSON")
              ffmpeg -hide_banner -y -i "$AUDIO_IN" \
                -af "${PRE},loudnorm=I=-16:TP=-1.5:LRA=11:measured_I=$I:measured_TP=$TP:measured_LRA=$LRA:measured_thresh=$TH:linear=true" \
                -c:a libmp3lame -q:a 2 -ar "$SR" -ac "$CH" "$OUT"
            else
              ffmpeg -hide_banner -y -i "$AUDIO_IN" -af "${PRE},loudnorm=I=-16:TP=-1.5:LRA=11" \
                -c:a libmp3lame -q:a 2 -ar "$SR" -ac "$CH" "$OUT"
            fi
          fi
          echo "MP3_PATH=${OUT}" >> "$GITHUB_ENV"

      - name: Upload MP3 to GCS
        id: upload_mp3
        if: ${{ github.event.inputs.mode != 'attendees_only' && github.event.inputs.mode != 'replies_only' && env.MP3_PATH != '' }}
        shell: bash
        run: |
          set -euxo pipefail
          DEST="gs://${GCS_BUCKET}/${BUCKET_PREFIX}/${BASE}.mp3"
          RAW="https://storage.googleapis.com/${GCS_BUCKET}/${BUCKET_PREFIX}/${BASE}.mp3"
          PROXY="https://media.chbmp.org/${PREFIX}/${BASE}.mp3"
          gsutil -m cp "${MP3_PATH}" "$DEST"
          if [ "${{ github.event.inputs.make_public }}" = "true" ]; then
            (gsutil acl ch -u AllUsers:R "$DEST" || gsutil iam ch allUsers:objectViewer "gs://${GCS_BUCKET}") || true
          fi
          echo "audio_raw=${RAW}"     >> "$GITHUB_OUTPUT"
          echo "audio_proxy=${PROXY}" >> "$GITHUB_OUTPUT"

      - name: Write helper scripts (gen_vtt, polish, replies_web)
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p ".github/workflows/scripts"

          # ---------------- gen_vtt.py ----------------
          cat > ".github/workflows/scripts/gen_vtt.py" << 'PY'
          #!/usr/bin/env python3
          import json, os, re, html, sys
          from datetime import datetime, timezone

          artdir = os.environ.get("ARTDIR") or ""
          base   = os.environ.get("BASE") or ""
          src    = os.environ.get("CC_JSONL") or ""
          shift  = float(os.environ.get("SHIFT_SECS") or "0")

          if not (artdir and base and src and os.path.isfile(src)):
              os.makedirs(artdir, exist_ok=True)
              open(os.path.join(artdir,f"{base}.vtt"),"w",encoding="utf-8").write("WEBVTT\n\n")
              open(os.path.join(artdir,f"{base}_emoji.vtt"),"w",encoding="utf-8").write("WEBVTT\n\n")
              open(os.path.join(artdir,f"{base}_transcript.html"),"w",encoding="utf-8").write("")
              sys.exit(0)

          def parse_time_iso(s):
              if not s: return None
              s=s.strip()
              try:
                  if s.endswith('Z'): s=s[:-1]+'+00:00'
                  if re.search(r'[+-]\\d{4}$', s):
                      s=s[:-5]+s[-5:-2]+':'+s[-2:]
                  dt=datetime.fromisoformat(s)
                  if dt.tzinfo is None: dt=dt.replace(tzinfo=timezone.utc)
                  return dt.timestamp()
              except: return None

          def to_float(x):
              try:
                  if x is None: return None
                  f=float(x)
                  return f/1000.0 if f>86400 else f
              except: return None

          def fmt_ts(t):
              if t<0: t=0.0
              h=int(t//3600); m=int((t%3600)//60); s=t%60
              return f"{h:02d}:{m:02d}:{s:06.3f}"

          def clean_name(s):
              s=(s or "").strip()
              s=re.sub(r'[<>&]','',s)
              s=''.join(ch for ch in s if (ord(ch)<0x1F000 and not (0xD800<=ord(ch)<=0xDFFF)))
              return s or "Speaker"

          def esc(s): return (s or "").replace("&","&amp;").replace("<","&lt;").replace(">","&gt;")

          def norm_text(s):
              if not s: return ""
              s=s.replace("\\u2028"," ").replace("\\u2029"," ")
              s=re.sub(r'\\s+',' ',s).strip()
              if s.lower() in {"n","uh","um"}: return ""
              return s

          def first(*vals):
              for v in vals:
                  if v not in (None,""): return v
              return None

          raw_utts=[]
          with open(src,'r',encoding='utf-8',errors='ignore') as f:
              for line in f:
                  line=line.strip()
                  if not line: continue
                  try: obj=json.loads(line)
                  except: obj=None

                  layer=None; sender={}
                  if isinstance(obj,dict) and isinstance(obj.get("payload"),str):
                      try:
                          pl=json.loads(obj["payload"])
                          if isinstance(pl,dict) and isinstance(pl.get("body"),str):
                              try:
                                  layer=json.loads(pl["body"])
                                  sender=pl.get("sender") or {}
                              except: layer=None
                      except: pass
                  else:
                      layer=obj

                  def push(ts_abs, txt, disp, uname, avatar, te_abs=None):
                      if ts_abs is None or not txt: return
                      t2=norm_text(txt); 
                      if not t2: return
                      raw_utts.append({
                          "ts": float(ts_abs),
                          "text": t2,
                          "name": clean_name(disp or uname or "Speaker"),
                          "username": (uname or "").lstrip("@"),
                          "avatar": avatar or "",
                          "end_ts": float(te_abs) if te_abs is not None else None
                      })

                  if isinstance(layer,dict) and layer:
                      ttype=layer.get("type")
                      txt  = first(layer.get("body"),layer.get("text"),layer.get("caption"))
                      disp = first(layer.get("displayName"), (sender or {}).get("display_name"), layer.get("speaker_name"), layer.get("speakerName"))
                      uname= first(layer.get("username"), (sender or {}).get("screen_name"), layer.get("user_id"))
                      avat = first((sender or {}).get("profile_image_url_https"), (sender or {}).get("profile_image_url"))

                      ts_abs = first(
                          to_float(layer.get("timestamp")),
                          parse_time_iso(layer.get("programDateTime")),
                          to_float(layer.get("start")), to_float(layer.get("startSec")), to_float(layer.get("startMs")), to_float(layer.get("ts")), to_float(layer.get("offset"))
                      )
                      te_abs = first(to_float(layer.get("end")), to_float(layer.get("endSec")), to_float(layer.get("endMs")))

                      if txt and (ttype is None or ttype==45 or any(k in layer for k in ("start","startMs","timestamp","programDateTime"))):
                          if ts_abs is not None:
                              push(ts_abs, txt, disp, uname, avat, te_abs)
                          continue

                  if isinstance(obj,dict):
                      txt = first(obj.get("text"), obj.get("caption"), obj.get("payloadText"))
                      ts_abs = first(
                          to_float(obj.get("timestamp")),
                          parse_time_iso(obj.get("programDateTime")),
                          to_float(obj.get("start")), to_float(obj.get("startMs")), to_float(obj.get("ts"))
                      )
                      disp = first(obj.get("displayName"), obj.get("speaker"), obj.get("user"), obj.get("name"))
                      uname= first(obj.get("username"), obj.get("handle"), obj.get("screen_name"))
                      avat = first(obj.get("profile_image_url_https"), obj.get("profile_image_url"))
                      if txt and ts_abs is not None:
                          push(ts_abs, txt, disp, uname, avat)

          if not raw_utts:
              os.makedirs(artdir, exist_ok=True)
              open(os.path.join(artdir,f"{base}.vtt"),"w",encoding="utf-8").write("WEBVTT\n\n")
              open(os.path.join(artdir,f"{base}_emoji.vtt"),"w",encoding="utf-8").write("WEBVTT\n\n")
              open(os.path.join(artdir,f"{base}_transcript.html"),"w",encoding="utf-8").write("")
              sys.exit(0)

          raw_utts.sort(key=lambda x: x["ts"])
          EPS=0.0005; last=-1e9
          for u in raw_utts:
              if u["ts"]<=last: u["ts"]=last+EPS
              last=u["ts"]

          t0=raw_utts[0]["ts"]

          utts=[]
          for u in raw_utts:
              st=(u["ts"]-t0)-shift
              if st<0: st=0.0
              utts.append({
                  "start_rel": st,
                  "end_rel": None,
                  "text": u["text"],
                  "name": u["name"],
                  "username": u["username"],
                  "avatar": u["avatar"],
              })

          MIN_DUR=0.80; MAX_DUR=10.0; GUARD=0.020
          for i,u in enumerate(utts):
              if i+1<len(utts):
                  nxt=utts[i+1]["start_rel"]
                  dur=max(MIN_DUR, min(MAX_DUR, (nxt-u["start_rel"])-GUARD))
                  if dur<=0: dur=MIN_DUR
                  u["end_rel"]=u["start_rel"]+dur
              else:
                  words=max(1, len(u["text"].split()))
                  dur=max(MIN_DUR, min(MAX_DUR, 0.33*words+0.7))
                  u["end_rel"]=u["start_rel"]+dur

          MERGE_GAP=3.0
          groups=[]; cur=None
          for u in utts:
              if (cur is not None and u["name"]==cur["name"] and u["username"]==cur["username"] and (u["start_rel"]-cur["end_rel"])<=MERGE_GAP):
                  sep="" if re.search(r'[.!?]"?$', cur["text"]) else " "
                  cur["text"]=(cur["text"]+sep+u["text"]).strip()
                  cur["end_rel"]=max(cur["end_rel"], u["end_rel"])
              else:
                  cur={"name":u["name"],"username":u["username"],"avatar":u["avatar"],
                       "start_rel":u["start_rel"],"end_rel":u["end_rel"],"text":u["text"]}
                  groups.append(cur)

          prev=0.0
          for g in groups:
              if g["start_rel"]<prev+0.02: g["start_rel"]=prev+0.02
              if g["end_rel"]<g["start_rel"]+MIN_DUR: g["end_rel"]=g["start_rel"]+MIN_DUR
              prev=g["end_rel"]

          os.makedirs(artdir, exist_ok=True)
          # full captions VTT
          vtt_path=os.path.join(artdir,f"{base}.vtt")
          with open(vtt_path,"w",encoding="utf-8") as vf:
              vf.write("WEBVTT\n\n")
              for i,g in enumerate(groups,1):
                  vf.write(f"{i}\n{fmt_ts(g['start_rel'])} --> {fmt_ts(g['end_rel'])}\n")
                  vf.write(f"<v {esc(g['name'])}> {esc(g['text'])}\n\n")

          # emoji-only VTT
          EMOJI_RE = re.compile(
              "["                       # broad emoji blocks
              "\\U0001F1E6-\\U0001F1FF" # flags
              "\\U0001F300-\\U0001FAD6" # misc pictographs
              "\\U0001FAE0-\\U0001FAFF" # newer emoji
              "\\U00002700-\\U000027BF" # dingbats
              "\\U00002600-\\U000026FF" # misc symbols
              "\\U0001F900-\\U0001F9FF" # supplemental
              "\\U0001F680-\\U0001F6FF" # transport/map
              "\\U0001F100-\\U0001F5FF" # enclosed alphanum/symbols
              "\\U0001FA70-\\U0001FAFF" # more symbols
              "\\U00002300-\\U000023FF" # misc tech
              "]+", flags=re.UNICODE
          )
          def only_emoji(s:str)->str:
              if not s: return ""
              return "".join(EMOJI_RE.findall(s))

          evtt_path=os.path.join(artdir,f"{base}_emoji.vtt")
          with open(evtt_path,"w",encoding="utf-8") as ef:
              ef.write("WEBVTT\n\n")
              j=1
              for g in groups:
                  em=only_emoji(g["text"])
                  if not em: continue
                  ef.write(f"{j}\n{fmt_ts(g['start_rel'])} --> {fmt_ts(g['end_rel'])}\n")
                  ef.write(f"{em}\n\n")
                  j+=1

          # rich transcript HTML (avatars + names)
          css='''
          <style>
          .ss3k-transcript{font:15px/1.5 system-ui,-apple-system,Segoe UI,Roboto,Arial,sans-serif;
            max-height:70vh; overflow-y:auto; scroll-behavior:smooth; border:1px solid #e5e7eb; border-radius:12px; padding:6px 6px;}
          .ss3k-seg{display:flex;gap:10px;padding:8px 10px;border-radius:10px;margin:6px 0}
          .ss3k-seg.active{background:#eef6ff;outline:1px solid #bfdbfe}
          .ss3k-avatar{width:26px;height:26px;border-radius:50%;flex:0 0 26px;margin-top:3px;background:#e5e7eb}
          .ss3k-meta{font-size:12px;color:#64748b;margin-bottom:2px}
          .ss3k-name a{color:#0f172a;text-decoration:none}
          .ss3k-text{white-space:pre-wrap;word-break:break-word;cursor:pointer}
          </style>
          '''
          js='''
          <script>
          (function(){
            function time(s){return parseFloat(s||'0')||0}
            function within(t,seg){return t>=time(seg.dataset.start) && t<time(seg.dataset.end)}
            function bind(){
              var audio=document.getElementById('ss3k-audio')||document.querySelector('audio[data-ss3k-player]');
              var cont=document.querySelector('.ss3k-transcript'); if(!audio||!cont) return;
              var segs=[].slice.call(cont.querySelectorAll('.ss3k-seg')); var lastId="";
              function tick(){
                var t=audio.currentTime||0, found=null;
                for(var i=0;i<segs.length;i++){ if(within(t,segs[i])){found=segs[i];break;} }
                segs.forEach(function(s){ s.classList.toggle('active', s===found); });
                if(found){
                  var id=found.id||"";
                  if(id!==lastId){
                    var top = found.offsetTop - cont.offsetTop;
                    if (Math.abs(cont.scrollTop - top) > 6) cont.scrollTop = top;
                    lastId=id;
                  }
                }
              }
              audio.addEventListener('timeupdate', tick);
              audio.addEventListener('seeked', tick);
              segs.forEach(function(s){
                s.addEventListener('click', function(){
                  audio.currentTime = time(s.dataset.start)+0.05; audio.play().catch(function(){});
                });
              });
              tick();
            }
            if(document.readyState!=="loading") bind(); else document.addEventListener('DOMContentLoaded', bind);
          })();
          </script>
          '''

          tr_path=os.path.join(artdir,f"{base}_transcript.html")
          with open(tr_path,"w",encoding="utf-8") as tf:
              tf.write(css)
              tf.write('<div class="ss3k-transcript">\n')
              for i,g in enumerate(groups,1):
                  name=g["name"]; uname=(g.get("username") or "").strip().lstrip("@")
                  prof=f"https://x.com/{html.escape(uname, True)}" if uname else ""
                  avatar=g.get("avatar") or (f"https://unavatar.io/x/{html.escape(uname, True)}" if uname else "")
                  if avatar and prof:
                      avtag=f'<a href="{prof}" target="_blank" rel="noopener"><img class="ss3k-avatar" src="{html.escape(avatar, True)}" alt=""></a>'
                  elif avatar:
                      avtag=f'<img class="ss3k-avatar" src="{html.escape(avatar, True)}" alt="">'
                  else:
                      avtag='<div class="ss3k-avatar" aria-hidden="true"></div>'
                  name_html = f'<span class="ss3k-name"><strong>{html.escape(name, True)}</strong></span>'
                  if prof:
                      name_html = f'<span class="ss3k-name"><a href="{prof}" target="_blank" rel="noopener"><strong>{html.escape(name, True)}</strong></a></span>'

                  tf.write(f'<div class="ss3k-seg" id="seg-{i:04d}" data-start="{g["start_rel"]:.3f}" data-end="{g["end_rel"]:.3f}" data-speaker="{html.escape(name, True)}"')
                  if uname: tf.write(f' data-handle="@{html.escape(uname, True)}"')
                  tf.write('>')
                  tf.write(avtag)
                  tf.write('<div class="ss3k-body">')
                  tf.write(f'<div class="ss3k-meta">{name_html} · <time>{fmt_ts(g["start_rel"])}</time>–<time>{fmt_ts(g["end_rel"])}</time></div>')
                  tf.write(f'<div class="ss3k-text">{html.escape(g["text"], True)}</div>')
                  tf.write('</div></div>\n')
              tf.write('</div>\n')
              tf.write(js)

          start_iso = datetime.fromtimestamp(raw_utts[0]["ts"], timezone.utc).isoformat(timespec='seconds').replace('+00:00','Z')
          with open(os.path.join(artdir,f"{base}.start.txt"),"w",encoding="utf-8") as sf:
              sf.write(start_iso+"\n")
          PY

          # ---------------- polish_transcript.py ----------------
          cat > ".github/workflows/scripts/polish_transcript.py" << 'PY'
          #!/usr/bin/env python3
          import os, re, html
          from typing import List

          ARTDIR = os.environ.get("ARTDIR",".")
          BASE   = os.environ.get("BASE","space")
          INP    = os.path.join(ARTDIR, f"{BASE}_transcript.html")
          OUT    = os.path.join(ARTDIR, f"{BASE}_transcript_polished.html")

          if not os.path.exists(INP) or os.path.getsize(INP) == 0:
              raise SystemExit(0)

          raw_html = open(INP, "r", encoding="utf-8", errors="ignore").read()

          TEXT_NODE = re.compile(r'(<(?:div|span)\s+class="ss3k-text"[^>]*>)(.*?)(</(?:div|span)>)', re.S | re.I)
          URL_RE = re.compile(r"https?://[^\s<>\"]+")

          FILLER_WORDS = [r"uh+", r"um+", r"er+", r"ah+", r"mm+h*", r"hmm+", r"eh+", r"uh\-huh", r"uhhuh", r"uh\-uh", r"uhuh"]
          FILLER_PHRASES = [r"you\s+know", r"i\s+mean", r"kind\s+of", r"sort\s+of", r"you\s+see"]
          FILLERS_RE = re.compile(r"\b(?:" + "|".join(FILLER_WORDS + FILLER_PHRASES) + r")\b", re.I)
          STUTTER_RE = re.compile(r"\b([A-Za-z])(?:\s+\1\b){1,5}")
          REPEAT_RE  = re.compile(r"\b([A-Za-z]{2,})\b(?:\s+\1\b){1,4}", re.I)

          def sentence_case(s: str) -> str:
              s = re.sub(r"\bi\b", "I", s)
              def cap_first(m):
                  pre = m.group(1) or ""
                  ch  = m.group(2).upper()
                  return pre + ch
              return re.sub(r"(^|\.\s+|\?\s+|!\s+)([a-z])", cap_first, s)

          def ensure_end_punct(s: str) -> str:
              t = s.rstrip()
              if not t: return s
              if t[-1] in ".!?\":)””’'»]>": return s
              if URL_RE.search(t[-80:]): return s
              if len(re.findall(r"\b\w+\b", t)) >= 6:
                  return t + "."
              return s

          def apply_rules(txt: str) -> str:
              if not txt.strip(): return txt
              txt = FILLERS_RE.sub("", txt)
              txt = STUTTER_RE.sub(lambda m: m.group(1), txt)
              txt = REPEAT_RE.sub(lambda m: m.group(1), txt)
              txt = re.sub(r"\s{2,}", " ", txt).strip()
              txt = re.sub(r"\bi\b", "I", txt)
              txt = re.sub(r"\s+([,.;:!?])", r"\1", txt)
              txt = re.sub(r"([,;:])([^\s])", r"\1 \2", txt)
              txt = sentence_case(txt)
              txt = ensure_end_punct(txt)
              txt = txt.replace("<","&lt;").replace(">","&gt;")
              return txt

          spans = []
          def _collect(m):
              spans.append(m.group(2))
              return m.group(0)
          TEXT_NODE.sub(_collect, raw_html)

          cleaned = [apply_rules(t) for t in spans]
          it = iter(cleaned)
          def _replace(m):
              open_tag, _, close_tag = m.group(1), m.group(2), m.group(3)
              try:
                  new_text = next(it)
              except StopIteration:
                  new_text = m.group(2)
              return f"{open_tag}{new_text}{close_tag}"

          polished_html = TEXT_NODE.sub(_replace, raw_html)
          polished_html = re.sub(r"\n{3,}", "\n\n", polished_html)
          with open(OUT, "w", encoding="utf-8") as f:
              f.write(polished_html)
          PY

          # ---------------- replies_web.py ----------------
          cat > ".github/workflows/scripts/replies_web.py" << 'PY'
          #!/usr/bin/env python3
          import os, re, json, html, time
          from urllib.parse import urlencode
          from urllib.request import Request, urlopen
          from urllib.error import HTTPError, URLError
          from collections import defaultdict

          ARTDIR = os.environ.get("ARTDIR",".")
          BASE   = os.environ.get("BASE","space")
          PURPLE = os.environ.get("PURPLE_TWEET_URL","").strip()

          OUT_REPLIES = os.path.join(ARTDIR, f"{BASE}_replies.html")
          OUT_LINKS   = os.path.join(ARTDIR, f"{BASE}_links.html")

          AUTH = os.environ.get("TWITTER_AUTHORIZATION","").strip()
          AUTH_COOKIE = os.environ.get("TWITTER_AUTH_TOKEN","").strip()
          CSRF = os.environ.get("TWITTER_CSRF_TOKEN","").strip()

          def write_empty():
              open(OUT_REPLIES, "w").write("")
              open(OUT_LINKS, "w").write("")

          m = re.search(r"https?://(?:x|twitter)\.com/([^/]+)/status/(\d+)", PURPLE)
          if not m:
              write_empty(); raise SystemExit(0)

          screen_name, root_id = m.group(1), m.group(2)
          if not (AUTH.startswith("Bearer ") and AUTH_COOKIE and CSRF):
              write_empty(); raise SystemExit(0)

          def headers():
              ck = f"auth_token={AUTH_COOKIE}; ct0={CSRF}"
              return {
                  "Authorization": AUTH,
                  "x-csrf-token": CSRF,
                  "x-twitter-active-user": "yes",
                  "x-twitter-client-language": "en",
                  "Pragma": "no-cache",
                  "Cache-Control": "no-cache",
                  "User-Agent": "Mozilla/5.0",
                  "Accept": "application/json, text/plain, */*",
                  "Referer": f"https://x.com/{screen_name}/status/{root_id}",
                  "Cookie": ck,
              }

          BASE_URL = "https://twitter.com/i/api/2/search/adaptive.json"
          Q = f"conversation_id:{root_id}"

          def fetch_page(cursor=None, retries=2):
              params = {
                  "q": Q,
                  "count": 100,
                  "tweet_search_mode": "live",
                  "query_source": "typed_query",
                  "tweet_mode": "extended",
                  "pc": "ContextualServices",
                  "spelling_corrections": "1",
                  "include_quote_count": "true",
                  "include_reply_count": "true",
                  "ext": "mediaStats,highlightedLabel,hashtags,antispam_media_platform,voiceInfo,superFollowMetadata,unmentionInfo,editControl,emoji_reaction"
              }
              if cursor: params["cursor"] = cursor
              url = BASE_URL + "?" + urlencode(params)
              req = Request(url, headers=headers())
              try:
                  with urlopen(req, timeout=30) as r:
                      return json.loads(r.read().decode("utf-8", "ignore"))
              except HTTPError as e:
                  if e.code in (429, 403) and retries>0:
                      time.sleep(3); return fetch_page(cursor, retries-1)
                  return None
              except URLError:
                  return None

          def bottom_cursor(obj):
              if isinstance(obj, dict):
                  if obj.get("cursorType") == "Bottom" and "value" in obj:
                      return obj["value"]
                  for v in obj.values():
                      c = bottom_cursor(v)
                      if c: return c
              elif isinstance(obj, list):
                  for it in obj:
                      c = bottom_cursor(it)
                      if c: return c
              return None

          def collect():
              tweets, users = {}, {}
              cursor, pages = None, 0
              while pages < 40:
                  data = fetch_page(cursor)
                  if not data: break
                  pages += 1
                  for k, v in (data.get("globalObjects", {}).get("tweets") or {}).items():
                      tweets[k] = v
                  for k, v in (data.get("globalObjects", {}).get("users") or {}).items():
                      users[k] = v
                  nxt = bottom_cursor(data.get("timeline") or data)
                  if not nxt or nxt == cursor: break
                  cursor = nxt
                  time.sleep(0.6)
              return tweets, users

          tweets, users = collect()

          replies = []
          for tid, t in tweets.items():
              if str(t.get("conversation_id_str") or t.get("conversation_id")) != str(root_id):
                  continue
              if str(t.get("id_str") or t.get("id")) == str(root_id):
                  continue
              replies.append(t)

          def tstamp(t):
              try:
                  import time as _t
                  return _t.mktime(_t.strptime(t.get("created_at",""), "%a %b %d %H:%M:%S %z %Y"))
              except Exception:
                  return 0
          replies.sort(key=tstamp)

          blocks = []
          for t in replies:
              uid = str(t.get("user_id_str") or t.get("user_id") or "")
              u = users.get(uid, {})
              name = u.get("name") or "User"
              handle = u.get("screen_name") or ""
              avatar = (u.get("profile_image_url_https") or u.get("profile_image_url") or "").replace("_normal.","_bigger.")
              url = f"https://x.com/{handle}/status/{t.get('id_str') or t.get('id')}"
              text = html.escape(t.get("full_text") or t.get("text") or "")
              imgtag = f'<img class="ss3k-ravatar" src="{html.escape(avatar)}" alt="">' if avatar else '<div class="ss3k-ravatar" style="width:32px;height:32px;border-radius:50%;background:#eee"></div>'
              who = html.escape(f"{name} (@{handle})") if handle else html.escape(name)
              blocks.append(
                  f'<div class="ss3k-reply"><a href="{url}" target="_blank" rel="noopener">{imgtag}</a>'
                  f'<div class="ss3k-rcontent"><div class="ss3k-rname">{who}</div>'
                  f'<div class="ss3k-rtext">{text}</div></div></div>'
              )
          open(OUT_REPLIES,"w").write("\n".join(blocks))

          from collections import defaultdict as _dd
          doms = _dd(set)
          def add_urls_from(t):
              ent = t.get("entities") or {}
              for u in (ent.get("urls") or []):
                  u2 = u.get("expanded_url") or u.get("url")
                  if not u2: continue
                  m = re.search(r"https?://([^/]+)/?", u2)
                  dom = m.group(1) if m else "links"
                  doms[dom].add(u2)

          for t in replies:
              add_urls_from(t)

          lines = []
          for dom in sorted(doms):
              lines.append(f"<h4>{html.escape(dom)}</h4>")
              lines.append("<ul>")
              for u in sorted(doms[dom]):
                  e = html.escape(u)
                  lines.append(f'<li><a href="{e}" target="_blank" rel="noopener">{e}</a></li>')
              lines.append("</ul>")
          open(OUT_LINKS,"w").write("\n".join(lines))
          PY
          chmod +x ".github/workflows/scripts/"*.py

      - name: Build VTT (full & emoji) + rich transcript
        if: ${{ github.event.inputs.mode != 'attendees_only' && github.event.inputs.mode != 'replies_only' }}
        shell: bash
        env:
          CC_JSONL: ${{ env.CRAWLER_CC }}
          SHIFT_SECS: ${{ steps.detect.outputs.lead || '0' }}
        run: |
          set -euxo pipefail
          if [ -n "${CC_JSONL:-}" ] && [ -s "${CC_JSONL}" ]; then
            CC_JSONL="${CC_JSONL}" ARTDIR="${ARTDIR}" BASE="${BASE}" SHIFT_SECS="${SHIFT_SECS}" \
              python3 ".github/workflows/scripts/gen_vtt.py"
            [ -s "${ARTDIR}/${BASE}.vtt" ] && echo "VTT_PATH=${ARTDIR}/${BASE}.vtt" >> "$GITHUB_ENV" || true
            [ -s "${ARTDIR}/${BASE}_emoji.vtt" ] && echo "EMOJI_VTT_PATH=${ARTDIR}/${BASE}_emoji.vtt" >> "$GITHUB_ENV" || true
            [ -s "${ARTDIR}/${BASE}_transcript.html" ] && echo "TRANSCRIPT_PATH=${ARTDIR}/${BASE}_transcript.html" >> "$GITHUB_ENV" || true
          fi

      - name: Polish transcript (optional)
        if: ${{ github.event.inputs.mode != 'attendees_only' && github.event.inputs.mode != 'replies_only' && env.TRANSCRIPT_PATH != '' }}
        shell: bash
        run: |
          set -euxo pipefail
          python3 ".github/workflows/scripts/polish_transcript.py" || true
          if [ -s "${ARTDIR}/${BASE}_transcript_polished.html" ]; then
            echo "TRANSCRIPT_PATH=${ARTDIR}/${BASE}_transcript_polished.html" >> "$GITHUB_ENV"
          fi

      - name: VTT via Deepgram fallback
        id: deepgram
        if: ${{ github.event.inputs.mode != 'attendees_only' && github.event.inputs.mode != 'replies_only' && env.VTT_PATH == '' && env.DEEPGRAM_API_KEY != '' && github.event.inputs.do_transcript == 'true' && env.MP3_PATH != '' }}
        shell: bash
        run: |
          set -euxo pipefail
          curl -sS -X POST \
            -H "Authorization: Token ${DEEPGRAM_API_KEY}" \
            -H "Content-Type: audio/mpeg" \
            --data-binary @"${MP3_PATH}" \
            "https://api.deepgram.com/v1/listen?model=nova-2&smart_format=true&punctuate=true&format=vtt" \
            -o "${ARTDIR}/${BASE}.vtt" || true
          [ -s "${ARTDIR}/${BASE}.vtt" ] && echo "VTT_PATH=${ARTDIR}/${BASE}.vtt" >> "$GITHUB_ENV" || true

      - name: Upload VTT to GCS
        id: upload_vtt
        if: ${{ github.event.inputs.mode != 'attendees_only' && github.event.inputs.mode != 'replies_only' && env.VTT_PATH != '' }}
        shell: bash
        run: |
          set -euxo pipefail
          DEST="gs://${GCS_BUCKET}/${BUCKET_PREFIX}/${BASE}.vtt"
          RAW="https://storage.googleapis.com/${GCS_BUCKET}/${BUCKET_PREFIX}/${BASE}.vtt"
          PROXY="https://media.chbmp.org/${PREFIX}/${BASE}.vtt"
          gsutil -m cp "${VTT_PATH}" "$DEST"
          if [ "${{ github.event.inputs.make_public }}" = "true" ]; then
            (gsutil acl ch -u AllUsers:R "$DEST" || gsutil iam ch allUsers:objectViewer "gs://${GCS_BUCKET}") || true
          fi
          echo "vtt_raw=${RAW}"     >> "$GITHUB_OUTPUT"
          echo "vtt_proxy=${PROXY}" >> "$GITHUB_OUTPUT"

      - name: Upload Emoji VTT to GCS
        id: upload_emoji_vtt
        if: ${{ github.event.inputs.mode != 'attendees_only' && github.event.inputs.mode != 'replies_only' && env.EMOJI_VTT_PATH != '' }}
        shell: bash
        run: |
          set -euxo pipefail
          DEST="gs://${GCS_BUCKET}/${BUCKET_PREFIX}/${BASE}_emoji.vtt"
          RAW="https://storage.googleapis.com/${GCS_BUCKET}/${BUCKET_PREFIX}/${BASE}_emoji.vtt"
          PROXY="https://media.chbmp.org/${PREFIX}/${BASE}_emoji.vtt"
          gsutil -m cp "${EMOJI_VTT_PATH}" "$DEST"
          if [ "${{ github.event.inputs.make_public }}" = "true" ]; then
            (gsutil acl ch -u AllUsers:R "$DEST" || gsutil iam ch allUsers:objectViewer "gs://${GCS_BUCKET}") || true
          fi
          echo "emoji_vtt_raw=${RAW}"     >> "$GITHUB_OUTPUT"
          echo "emoji_vtt_proxy=${PROXY}" >> "$GITHUB_OUTPUT"

      - name: Build attendees HTML
        id: attendees
        if: ${{ github.event.inputs.mode != 'replies_only' && steps.crawl.outcome == 'success' && steps.crawl.outputs.as_line != '' }}
        shell: bash
        env:
          CAND: ${{ steps.crawl.outputs.as_line }}
        run: |
          set -euxo pipefail
          OUT_JSON="${ARTDIR}/attendees.json"
          OUT_HTML="${ARTDIR}/attendees.html"
          jq -r '
            def mkp:
              { handle: (.twitter_screen_name // .user_results?.result?.legacy?.screen_name),
                name:   (.display_name       // .user_results?.result?.legacy?.name)
              }
              | select(.handle!=null and .handle!="" )
              | . + { url: ("https://x.com/" + .handle) };
            (.audioSpace // .) as $a
            | ($a.metadata?.creator_results?.result?.legacy?) as $h
            | ($h.screen_name // empty) as $H
            | {
                host:    ( if $H != "" then [ {handle:$H, name:($h.name // ""), url:("https://x.com/" + $H)} ] else [] end ),
                cohosts: ( ($a.participants?.admins   // []) | map(mkp) | map(select(.handle != $H)) | unique_by(.handle) ),
                speakers:( ($a.participants?.speakers // []) | map(mkp) | unique_by(.handle) )
              }
          ' "${CAND}" > "$OUT_JSON" || true
          if [ -s "$OUT_JSON" ]; then
            jq -r '
              def li: "  <li><a href=\"" + (.url//"#") + "\">" + ((.name // "") + " (@" + (.handle // "") + ")") + "</a></li>";
              def section(title; items):
                if (items|length) > 0
                then "<h3>" + title + "</h3>\n<ul>\n" + (items|map(li)|join("\n")) + "\n</ul>\n"
                else ""
                end;
              . as $d
              | section("Host"; $d.host)
              + section( (if ($d.cohosts|length)==1 then "Co-host" else "Co-hosts" end); $d.cohosts)
              + section("Speakers"; $d.speakers)
            ' "$OUT_JSON" > "$OUT_HTML"
            if grep -qi '<li><a ' "$OUT_HTML"; then
              echo "ATTN_HTML=${OUT_HTML}" >> "$GITHUB_ENV"
              echo "ATTENDEES_OK=1"       >> "$GITHUB_ENV"
            fi
          fi

      - name: Scrape replies and shared links (web)
        shell: bash
        env:
          PURPLE_TWEET_URL: ${{ github.event.inputs.purple_tweet_url }}
        run: |
          set -euo pipefail
          python3 ".github/workflows/scripts/replies_web.py" || true
          if [ -s "${ARTDIR}/${BASE}_replies.html" ]; then
            echo "REPLIES_PATH=${ARTDIR}/${BASE}_replies.html" >> "$GITHUB_ENV"
          fi
          if [ -s "${ARTDIR}/${BASE}_links.html" ]; then
            echo "LINKS_PATH=${ARTDIR}/${BASE}_links.html" >> "$GITHUB_ENV"
          fi

      - name: Derive Space title and publish date
        id: meta
        shell: bash
        env:
          AS_LINE: ${{ steps.crawl.outputs.as_line }}
        run: |
          set -euo pipefail
          TTL=""
          if [ -n "${AS_LINE:-}" ] && [ -s "${AS_LINE}" ]; then
            TTL="$(jq -r '(.audioSpace // .) as $a | ($a.metadata.title // $a.metadata.name // .title // "")' "${AS_LINE}" | sed -E 's/^[[:space:]]+|[[:space:]]+$//g')"
          fi
          if [ -z "$TTL" ]; then TTL="${BASE}"; fi
          echo "TTL_FINAL=$TTL" >> "$GITHUB_ENV"

          START_ISO=""
          if [ -n "${AS_LINE:-}" ] && [ -s "${AS_LINE}" ]; then
            MS="$(jq -r '(.audioSpace // .) as $a | ($a.metadata.started_at // $a.metadata.created_at // $a.metadata.start // empty)' "${AS_LINE}")" || true
            if [[ "$MS" =~ ^[0-9]+$ ]]; then
              if [ ${#MS} -gt 10 ]; then SECS=$((MS/1000)); else SECS=$MS; fi
              START_ISO="$(date -u -d "@$SECS" +%Y-%m-%dT%H:%M:%SZ || true)"
            fi
          fi
          if [ -z "$START_ISO" ] && [ -s "${ARTDIR}/${BASE}.start.txt" ]; then
            START_ISO="$(head -n1 "${ARTDIR}/${BASE}.start.txt" | tr -d '\r\n')"
          fi
          if [ -z "$START_ISO" ]; then
            START_ISO="$(date -u +%Y-%m-%dT%H:%M:%SZ)"
          fi
          echo "START_ISO=$START_ISO" >> "$GITHUB_ENV"

      - name: Register assets in WP
        if: ${{ github.event.inputs.mode == '' && env.WP_BASE_URL != '' && env.WP_USER != '' && env.WP_APP_PASSWORD != '' && github.event.inputs.post_id != '' && (steps.upload_mp3.outputs.audio_proxy != '' || steps.upload_mp3.outputs.audio_raw != '') }}
        shell: bash
        env:
          PID:  ${{ github.event.inputs.post_id }}
          AUD:  ${{ steps.upload_mp3.outputs.audio_proxy || steps.upload_mp3.outputs.audio_raw }}
          VTTU: ${{ steps.upload_vtt.outputs.vtt_proxy   || steps.upload_vtt.outputs.vtt_raw }}
          EVTT: ${{ steps.upload_emoji_vtt.outputs.emoji_vtt_proxy || steps.upload_emoji_vtt.outputs.emoji_vtt_raw }}
        run: |
          set -euo pipefail
          TTL="${TTL_FINAL:-${BASE}}"
          ATH_FILE="${WORKDIR}/empty_attendees.html"; : > "$ATH_FILE"
          [ -n "${ATTN_HTML:-}" ] && [ -s "${ATTN_HTML:-}" ] && ATH_FILE="${ATTN_HTML}"
          TR_FILE="${WORKDIR}/empty_transcript.html"; : > "$TR_FILE"
          [ -n "${TRANSCRIPT_PATH:-}" ] && [ -s "${TRANSCRIPT_PATH}" ] && TR_FILE="${TRANSCRIPT_PATH}"
          REP_FILE="${WORKDIR}/empty_replies.html"; : > "$REP_FILE"
          [ -n "${REPLIES_PATH:-}" ] && [ -s "${REPLIES_PATH:-}" ] && REP_FILE="${REPLIES_PATH}"
          LNK_FILE="${WORKDIR}/empty_links.html"; : > "$LNK_FILE"
          [ -n "${LINKS_PATH:-}" ] && [ -s "${LINKS_PATH:-}" ] && LNK_FILE="${LINKS_PATH}"

          REQ="${WORKDIR}/wp_register_body.json"
          jq -n \
            --arg gcs   "${AUD}" \
            --arg mime  "audio/mpeg" \
            --arg pid   "${PID}" \
            --arg ttl   "${TTL}" \
            --arg vtt   "${VTTU}" \
            --arg evtt  "${EVTT}" \
            --arg when  "${START_ISO:-}" \
            --rawfile ath "${ATH_FILE}" \
            --rawfile tr  "${TR_FILE}" \
            --rawfile rep "${REP_FILE}" \
            --rawfile lnk "${LNK_FILE}" \
            '{
               gcs_url: $gcs,
               mime:    $mime,
               post_id: ($pid|tonumber),
               title:   $ttl
             }
             + (if ($when|length)>0 then {post_date_gmt:$when, space_started_at:$when, publish_date:$when} else {} end)
             + (if ($vtt|length)>0 then {vtt_url:$vtt} else {} end)
             + (if ($evtt|length)>0 then {emoji_vtt_url:$evtt} else {} end)
             + (if ($ath|gsub("\\s";"")|length)>0 then {attendees_html:$ath} else {} end)
             + (if ($tr|gsub("\\s";"")|length)>0 then {transcript:$tr, has_transcript:true} else {} end)
             + (if ($rep|gsub("\\s";"")|length)>0 then {ss3k_replies_html:$rep} else {} end)
             + (if ($lnk|gsub("\\s";"")|length)>0 then {shared_links_html:$lnk} else {} end)
            ' > "$REQ"

          curl -sS -u "${WP_USER}:${WP_APP_PASSWORD}" \
            -H "Content-Type: application/json" \
            -X POST "${WP_BASE_URL%/}/wp-json/ss3k/v1/register" \
            --data-binary @"$REQ" | jq -r .

      - name: Patch WP attendees only
        if: ${{ github.event.inputs.mode == 'attendees_only' && env.WP_BASE_URL != '' && env.WP_USER != '' && env.WP_APP_PASSWORD != '' && github.event.inputs.post_id != '' }}
        shell: bash
        run: |
          set -euo pipefail
          AT_HTML=""
          if [ -n "${ATTN_HTML:-}" ] && [ -s "${ATTN_HTML:-}" ]; then AT_HTML="$(cat "${ATTN_HTML}")"; fi
          BODY="$(jq -n --arg pid "${{ github.event.inputs.post_id }}" --arg ath "${AT_HTML}" \
            '{post_id: ($pid|tonumber), status:"complete", progress:100}
             + (if ($ath|length)>0 then {attendees_html:$ath} else {} end)')"
          curl -sS -u "${WP_USER}:${WP_APP_PASSWORD}" -H "Content-Type: application/json" \
            -X POST "${WP_BASE_URL%/}/wp-json/ss3k/v1/patch-assets" -d "$BODY" | jq -r .

      - name: Patch WP replies only
        if: ${{ github.event.inputs.mode == 'replies_only' && env.WP_BASE_URL != '' && env.WP_USER != '' && env.WP_APP_PASSWORD != '' && github.event.inputs.post_id != '' }}
        shell: bash
        run: |
          set -euo pipefail
          REP="$( [ -n "${REPLIES_PATH:-}" ] && [ -s "${REPLIES_PATH:-}" ] && cat "${REPLIES_PATH}" || echo "" )"
          LNK="$( [ -n "${LINKS_PATH:-}" ] && [ -s "${LINKS_PATH:-}" ] && cat "${LINKS_PATH}" || echo "" )"
          BODY="$(jq -n --arg pid "${{ github.event.inputs.post_id }}" --arg rep "${REP}" --arg lnk "${LNK}" \
            '{post_id: ($pid|tonumber), status:"complete", progress:100}
             + (if ($rep|length)>0 then {ss3k_replies_html:$rep} else {} end)
             + (if ($lnk|length)>0 then {shared_links_html:$lnk} else {} end)')"
          curl -sS -u "${WP_USER}:${WP_APP_PASSWORD}" -H "Content-Type: application/json" \
            -X POST "${WP_BASE_URL%/}/wp-json/ss3k/v1/patch-assets" -d "$BODY" | jq -r .

      - name: Summary
        shell: bash
        env:
          SID: ${{ steps.ids.outputs.space_id }}
        run: |
          {
            echo "### Space Worker Summary"
            echo "- Mode ${{ github.event.inputs.mode }}"
            echo "- Space URL ${{ github.event.inputs.space_url }}"
            echo "- Purple URL ${{ github.event.inputs.purple_tweet_url }}"
            echo "- Space ID ${SID}"
            echo "- Post ID ${{ github.event.inputs.post_id }}"
            echo "- Title ${TTL_FINAL:-}"
            echo "- Publish (UTC) ${START_ISO:-}"
            if [ -n "${{ steps.upload_mp3.outputs.audio_proxy }}" ]; then
              echo "- Audio ${{ steps.upload_mp3.outputs.audio_proxy }}"
            elif [ -n "${{ steps.upload_mp3.outputs.audio_raw }}" ]; then
              echo "- Audio ${{ steps.upload_mp3.outputs.audio_raw }}"
            fi
            if [ -n "${{ steps.upload_vtt.outputs.vtt_proxy }}" ]; then
              echo "- VTT ${{ steps.upload_vtt.outputs.vtt_proxy }}"
            elif [ -n "${{ steps.upload_vtt.outputs.vtt_raw }}" ]; then
              echo "- VTT ${{ steps.upload_vtt.outputs.vtt_raw }}"
            fi
            if [ -n "${{ steps.upload_emoji_vtt.outputs.emoji_vtt_proxy }}" ]; then
              echo "- Emoji VTT ${{ steps.upload_emoji_vtt.outputs.emoji_vtt_proxy }}"
            elif [ -n "${{ steps.upload_emoji_vtt.outputs.emoji_vtt_raw }}" ]; then
              echo "- Emoji VTT ${{ steps.upload_emoji_vtt.outputs.emoji_vtt_raw }}"
            fi
          } >> "$GITHUB_STEP_SUMMARY"
