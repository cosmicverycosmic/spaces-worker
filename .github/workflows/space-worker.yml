name: Space Worker

on:
  workflow_dispatch:
    inputs:
      space_url:
        description: X Twitter Space URL https://x.com/i/spaces/...
        required: true
        type: string
      title:
        description: Post title to use in WordPress fallback if no post id
        required: false
        type: string
        default: ""
      post_id:
        description: Existing WP post id to register or patch (optional)
        required: false
        type: string
        default: ""
      gcs_prefix:
        description: GCS prefix folder, e.g. "spaces/2025/09" (empty = auto: spaces/YYYY/MM)
        required: false
        type: string
        default: ""
      make_public:
        description: Set GCS objects to public
        required: false
        type: choice
        options: ["true", "false"]
        default: "true"
      do_transcript:
        description: Generate diarized transcript & VTT (Deepgram) when crawler captions unavailable
        required: false
        type: choice
        options: ["true", "false"]
        default: "true"
      wp_marker:
        description: Opaque marker from WP (optional)
        required: false
        type: string
        default: ""
      space_id:
        description: Space ID (e.g. 1kvJpyzZOOkxE). Auto-parsed from URL if blank
        required: false
        type: string
        default: ""
      mode:
        description: Optional targeted mode
        required: false
        type: choice
        options: ["", "transcript_only", "attendees_only"]
        default: ""
      existing_mp3_url:
        description: For transcript_only: URL of the already encoded MP3
        required: false
        type: string
        default: ""

permissions:
  contents: read
  packages: read

concurrency:
  group: ${{ format('space-worker-{0}-{1}', github.ref, inputs.post_id != '' && inputs.post_id || github.run_id) }}
  cancel-in-progress: false

env:
  GCP_SA_KEY:       ${{ secrets.GCP_SA_KEY       || vars.GCP_SA_KEY }}
  GCS_BUCKET:       ${{ secrets.GCS_BUCKET       || vars.GCS_BUCKET }}
  WP_BASE_URL:      ${{ secrets.WP_BASE_URL      || secrets.WP_URL || vars.WP_BASE_URL || vars.WP_URL }}
  WP_USER:          ${{ secrets.WP_USER          || vars.WP_USER }}
  WP_APP_PASSWORD:  ${{ secrets.WP_APP_PASSWORD  || vars.WP_APP_PASSWORD }}
  DEEPGRAM_API_KEY: ${{ secrets.DEEPGRAM_API_KEY || vars.DEEPGRAM_API_KEY }}

  # X / Twitter creds
  TWITTER_AUTHORIZATION: ${{ secrets.TWITTER_AUTHORIZATION || secrets.X_BEARER || vars.TWITTER_AUTHORIZATION || vars.X_BEARER }}
  TWITTER_AUTH_TOKEN:    ${{ secrets.TWITTER_AUTH_TOKEN    || secrets.X_AUTH_TOKEN || vars.TWITTER_AUTH_TOKEN || vars.X_AUTH_TOKEN }}
  TWITTER_CSRF_TOKEN:    ${{ secrets.TWITTER_CSRF_TOKEN    || secrets.X_CSRF       || vars.TWITTER_CSRF_TOKEN || vars.X_CSRF }}

  WORKDIR: ${{ github.workspace }}/work
  ARTDIR:  ${{ github.workspace }}/out

jobs:
  run:
    name: Process Space
    runs-on: ubuntu-latest
    timeout-minutes: 180

    steps:
      - name: Start ping WP queued
        if: ${{ env.WP_BASE_URL != '' && env.WP_USER != '' && env.WP_APP_PASSWORD != '' && inputs.post_id != '' }}
        shell: bash
        run: |
          set -euo pipefail
          curl -sS -u "${WP_USER}:${WP_APP_PASSWORD}" \
            -H "Content-Type: application/json" \
            -X POST "${WP_BASE_URL%/}/wp-json/ss3k/v1/worker-status" \
            -d "$(jq -n --arg pid "${{ inputs.post_id }}" --arg status "queued" \
                       --arg msg "Workflow received and queued" \
                       --arg run "${{ github.run_id }}" --argjson progress 1 \
                       '{post_id: ($pid|tonumber), status:$status, message:$msg, run_id:$run, progress:$progress}')"

      - name: Install deps (ffmpeg, jq, yt-dlp, gcloud)
        shell: bash
        run: |
          set -euxo pipefail
          sudo apt-get update
          sudo apt-get install -y --no-install-recommends ffmpeg jq python3 python3-pip ca-certificates gnupg
          python3 -m pip install --upgrade pip
          python3 -m pip install --no-cache-dir yt-dlp
          echo "deb [signed-by=/usr/share/keyrings/cloud.google.gpg] http://packages.cloud.google.com/apt cloud-sdk main" | sudo tee /etc/apt/sources.list.d/google-cloud-sdk.list
          curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo gpg --dearmor -o /usr/share/keyrings/cloud.google.gpg
          sudo apt-get update && sudo apt-get install -y google-cloud-sdk

      - name: Validate secrets, normalize prefix, compute bucket prefix
        id: cfg
        shell: bash
        run: |
          set -euxo pipefail
          test -n "${GCP_SA_KEY}" || { echo "GCP_SA_KEY missing"; exit 1; }
          test -n "${GCS_BUCKET}" || { echo "GCS_BUCKET missing"; exit 1; }
          mkdir -p "$WORKDIR" "$ARTDIR" "$ARTDIR/logs"
          PFX="$(echo "${{ inputs.gcs_prefix }}" | sed -E 's#^/*##; s#/*$##')"
          if [ -z "$PFX" ]; then
            PFX="spaces/$(date +%Y)/$(date +%m)"
          fi
          echo "prefix=${PFX}" >> "$GITHUB_OUTPUT"
          echo "PREFIX=${PFX}" >> "$GITHUB_ENV"
          echo "BUCKET_PREFIX=${PFX#spaces/}" >> "$GITHUB_ENV"

      - name: Derive space id and base filename
        id: ids
        shell: bash
        env:
          INP_SPACE_ID: ${{ inputs.space_id }}
          URL:          ${{ inputs.space_url }}
        run: |
          set -euxo pipefail
          SID="${INP_SPACE_ID}"
          if [ -z "$SID" ]; then
            SID="$(echo "$URL" | sed -nE 's#^.*/i/spaces/([^/?#]+).*#\1#p')"
          fi
          test -n "$SID" || { echo "Could not parse Space ID"; exit 1; }
          BASE="space-$(date +%m-%d-%Y)-${SID}"
          echo "space_id=${SID}" >> "$GITHUB_OUTPUT"
          echo "BASE=${BASE}"     >> "$GITHUB_OUTPUT"
          echo "SPACE_ID=${SID}"  >> "$GITHUB_ENV"
          echo "BASE=${BASE}"     >> "$GITHUB_ENV"

      - name: GCP auth (service account)
        shell: bash
        run: |
          set -euxo pipefail
          printf '%s\n' "${GCP_SA_KEY}" > "${HOME}/gcp-key.json"
          gcloud auth activate-service-account --key-file="${HOME}/gcp-key.json" >/dev/null

      # ---------- RELAXED PREFLIGHT (lets crawler run even when /participants=404) ----------
      - name: X preflight auth sanity check
        id: x_preflight
        shell: bash
        run: |
          set -euxo pipefail
          AUTH="${TWITTER_AUTHORIZATION:-}"
          AT="${TWITTER_AUTH_TOKEN:-}"
          CT="${TWITTER_CSRF_TOKEN:-}"

          # Require "Bearer " prefix for AUTH
          if [ -n "$AUTH" ] && ! printf '%s' "$AUTH" | grep -q '^Bearer '; then
            AUTH=""
          fi

          # Mask provided secrets
          [ -n "${TWITTER_AUTHORIZATION:-}" ] && echo "::add-mask::${TWITTER_AUTHORIZATION}"
          [ -n "$AT" ] && echo "::add-mask::${AT}"
          [ -n "$CT" ] && echo "::add-mask::${CT}"

          OK=0
          REASON="no_creds"

          HAS_COOKIE=0
          HAS_BEARER=0
          [ -n "$AT" ] && [ -n "$CT" ] && HAS_COOKIE=1 || true
          [ -n "$AUTH" ] && HAS_BEARER=1 || true

          # If we have any creds at all, allow the crawler
          if [ "$HAS_COOKIE" -eq 1 ] || [ "$HAS_BEARER" -eq 1 ]; then
            OK=1
            REASON="creds_present"
          fi

          mkdir -p "${ARTDIR}"
          BASEH=(-H "User-Agent: Mozilla/5.0" -H "Accept: application/json, text/plain, */*" -H "Referer: https://x.com/i/spaces/${SPACE_ID:-home}")

          # Diagnostics (not gating)
          if [ "$HAS_COOKIE" -eq 1 ] && [ "$HAS_BEARER" -eq 1 ]; then
            CVAL="auth_token=${AT}; ct0=${CT}"
            HTTP=$(curl -sS -o "${ARTDIR}/x_participants_cookie.json" -w "%{http_code}" \
              "https://x.com/i/api/spaces/${SPACE_ID}/participants" \
              "${BASEH[@]}" \
              -H "Authorization: ${AUTH}" \
              -H "x-csrf-token: ${CT}" \
              -H "Cookie: ${CVAL}" \
              -H "x-twitter-active-user: yes" \
              -H "x-twitter-client-language: en" \
              -H "x-twitter-auth-type: OAuth2Session" || echo 000)
            echo "diag_participants_cookie_http=${HTTP}" >> "$GITHUB_OUTPUT"
          fi

          if [ "$HAS_BEARER" -eq 1 ]; then
            GHTTP=$(curl -sS -o "${ARTDIR}/x_guest.json" -w "%{http_code}" \
              -X POST "https://api.twitter.com/1.1/guest/activate.json" \
              -H "Authorization: ${AUTH}" \
              -H "Content-Type: application/json" \
              -d '{}' || echo 000)
            echo "diag_guest_activate_http=${GHTTP}" >> "$GITHUB_OUTPUT"
            if [ "$OK" -ne 1 ] && [ "$GHTTP" = "200" ]; then
              OK=1
              REASON="guest_ok"
            fi
            if [ "$GHTTP" = "200" ]; then
              GUEST=$(jq -r '.guest_token // empty' "${ARTDIR}/x_guest.json" 2>/dev/null || true)
              if [ -n "$GUEST" ]; then
                PHTTP=$(curl -sS -o "${ARTDIR}/x_participants_guest.json" -w "%{http_code}" \
                  "https://x.com/i/api/spaces/${SPACE_ID}/participants" \
                  "${BASEH[@]}" \
                  -H "Authorization: ${AUTH}" \
                  -H "x-guest-token: ${GUEST}" \
                  -H "x-twitter-active-user: yes" \
                  -H "x-twitter-client-language: en" || echo 000)
                echo "diag_participants_guest_http=${PHTTP}" >> "$GITHUB_OUTPUT"
              fi
            fi
          fi

          if [ "$OK" -ne 1 ] ; then
            for PEEK in "https://x.com/i/spaces/${SPACE_ID}/peek" "https://twitter.com/i/spaces/${SPACE_ID}/peek"; do
              PHTTP=$(curl -sS -o "${ARTDIR}/x_peek.json" -w "%{http_code}" "$PEEK" -H "User-Agent: Mozilla/5.0" -H "Accept: application/json" || echo 000)
              echo "diag_peek_http=${PHTTP}" >> "$GITHUB_OUTPUT"
              if [ "$PHTTP" = "200" ]; then
                OK=1
                REASON="public_ok"
                break
              fi
            done
          fi

          echo "ok=${OK}"         >> "$GITHUB_OUTPUT"
          echo "reason=${REASON}" >> "$GITHUB_OUTPUT"
          [ -n "$AUTH" ] && echo "TWITTER_AUTHORIZATION=$AUTH" >> "$GITHUB_ENV"

      # ---------- CRAWLER (run whenever not transcript_only) ----------
      - name: Ping crawler attempting
        if: ${{ steps.x_preflight.outputs.ok == '1' && inputs.mode != 'transcript_only' && env.WP_BASE_URL != '' && inputs.post_id != '' && env.WP_USER != '' && env.WP_APP_PASSWORD != '' }}
        shell: bash
        run: |
          set -euo pipefail
          curl -sS -u "${WP_USER}:${WP_APP_PASSWORD}" -H "Content-Type: application/json" \
            -X POST "${WP_BASE_URL%/}/wp-json/ss3k/v1/worker-status" \
            -d "$(jq -n --arg pid "${{ inputs.post_id }}" --arg status "processing" \
                       --arg msg "twspace crawler fetching audio/captions/meta" \
                       --arg run "${{ github.run_id }}" --argjson progress 8 \
                       '{post_id: ($pid|tonumber), status:$status, message:$msg, run_id:$run, progress:$progress}')"

      - name: twspace crawler (audio/meta best-effort)
        id: crawl
        if: ${{ steps.x_preflight.outputs.ok == '1' && inputs.mode != 'transcript_only' }}
        shell: bash
        env:
          SID: ${{ steps.ids.outputs.space_id }}
        run: |
          set -euxo pipefail
          mkdir -p "${ARTDIR}" "${ARTDIR}/logs"
          docker pull ghcr.io/hitomarukonpaku/twspace-crawler:latest || true

          LOG_STD="${ARTDIR}/logs/crawler_${SID}.out.log"
          LOG_ERR="${ARTDIR}/logs/crawler_${SID}.err.log"

          set +e
          timeout 10m docker run --rm \
            -e TWITTER_AUTHORIZATION \
            -e TWITTER_AUTH_TOKEN \
            -e TWITTER_CSRF_TOKEN \
            -v "${ARTDIR}:/app/download" \
            -v "${ARTDIR}/logs:/app/logs" \
            ghcr.io/hitomarukonpaku/twspace-crawler:latest \
            --id "${SID}" --force \
            > >(tee -a "$LOG_STD") 2> >(tee -a "$LOG_ERR" >&2)
          RC=$?
          set -e
          echo "crawler_exit=$RC"

          AUDIO_FILE="$(find "${ARTDIR}" -type f \( -iname '*.m4a' -o -iname '*.mp3' -o -iname '*.mp4' -o -iname '*.aac' -o -iname '*.webm' -o -iname '*.ogg' -o -iname '*.wav' -o -iname '*.ts' \) -printf '%T@ %p\n' | sort -nr | head -n1 | cut -d' ' -f2- || true)"
          if [ -n "$AUDIO_FILE" ]; then
            echo "INPUT_FILE=${AUDIO_FILE}" >> "$GITHUB_ENV"
            echo "audio_file=${AUDIO_FILE}"  >> "$GITHUB_OUTPUT"
          fi

          # Expose log paths for attendees extraction
          echo "crawler_log_std=${LOG_STD}" >> "$GITHUB_OUTPUT"
          echo "crawler_log_err=${LOG_ERR}" >> "$GITHUB_OUTPUT"

      # ---------- ATTENDEES: parse directly from crawler logs ----------
      - name: Extract attendees from crawler logs
        id: attendees_from_logs
        if: ${{ inputs.mode != 'transcript_only' }}
        shell: bash
        env:
          LOG_STD: ${{ steps.crawl.outputs.crawler_log_std }}
          LOG_ERR: ${{ steps.crawl.outputs.crawler_log_err }}
          OUT_JSON: ${{ env.ARTDIR }}/attendees.json
          OUT_HTML: ${{ env.ARTDIR }}/attendees.html
        run: |
          set -euxo pipefail
          : "${LOG_STD:=}"
          : "${LOG_ERR:=}"
          python3 - <<'PY'
import json, re, sys, os, html
log_paths = [os.environ.get('LOG_STD',''), os.environ.get('LOG_ERR','')]
log_paths = [p for p in log_paths if p and os.path.exists(p)]
buf = ""
for p in log_paths:
    try:
        with open(p,'r',encoding='utf-8',errors='ignore') as f:
            buf += f.read()+"\n"
    except Exception:
        pass

def iter_json_objects(s):
    # find {...} after "audioSpace" or "participants"
    starts = [m.start() for m in re.finditer(r'(\{"audioSpace":|\{"participants":)', s)]
    for st in starts:
        # back up to the opening brace
        i = s.find('{', st)
        if i < 0: continue
        depth = 0; in_str=False; esc=False
        for j,ch in enumerate(s[i:], start=i):
            if in_str:
                if esc: esc=False
                elif ch == '\\\\': esc=True
                elif ch == '"': in_str=False
            else:
                if ch == '"': in_str=True
                elif ch == '{': depth += 1
                elif ch == '}':
                    depth -= 1
                    if depth == 0:
                        yield s[i:j+1]
                        break

objs=[]
for js in iter_json_objects(buf):
    try:
        o=json.loads(js)
        objs.append(o)
    except Exception:
        # Try to salvage common mask artifacts *** by stripping them
        try:
            o=json.loads(js.replace('***',''))
            objs.append(o)
        except Exception:
            pass

# Consolidate participants regardless of wrapper shape
hosts=[]; cohosts=[]; speakers=[]; listeners=[]
def push(lst, disp, handle):
    if not handle: return
    url=f"https://twitter.com/{handle}"
    lst.append({"display":disp or handle, "handle":handle, "url":url})

for o in objs:
    if "audioSpace" in o:
        a=o["audioSpace"]
    else:
        a=o
    p=a.get("participants") or {}
    # Older shapes: admins/cohosts/speakers/listeners; sometimes objects have twitter_screen_name or screen_name
    for src, target in [("admins",hosts), ("cohosts",cohosts), ("speakers",speakers), ("listeners",listeners)]:
        for ent in p.get(src, []):
            handle = ent.get("twitter_screen_name") or ent.get("screen_name") or ent.get("twitterScreenName")
            disp   = ent.get("display_name") or ent.get("name") or ent.get("displayName")
            push(target, disp, handle)

# Deduplicate by handle within each bucket
def dedup(lst):
    seen=set(); out=[]
    for x in lst:
        h=x["handle"].lower()
        if h in seen: continue
        seen.add(h); out.append(x)
    return out

hosts=dedup(hosts); cohosts=dedup(cohosts); speakers=dedup(speakers); listeners=dedup(listeners)

# Build output
out = {
  "host": hosts,
  "cohosts": cohosts,
  "speakers": speakers,
  "listeners": listeners
}
out_path=os.environ["OUT_JSON"]
with open(out_path,"w",encoding="utf-8") as f:
    json.dump(out,f,ensure_ascii=False,indent=2)

# HTML render (only if we have at least one <a> item)
def section(title, items):
    if not items: return ""
    lines=[f"<li><strong>{html.escape(title)}</strong><ul>"]
    for it in items:
        lines.append(f'  <li><a href="{html.escape(it["url"])}" target="_blank">{html.escape(it["display"])} (@{html.escape(it["handle"])})</a></li>')
    lines.append("</ul></li>")
    return "\n".join(lines)

html_out = []
for label, items in [("Host", hosts), ("Co-hosts", cohosts), ("Speakers", speakers), ("Listeners", listeners)]:
    sec = section(label, items)
    if sec: html_out.append(sec)

html_str = "<ul>\n" + "\n".join(html_out) + "\n</ul>\n" if html_out else ""
if html_out:
    with open(os.environ["OUT_HTML"],"w",encoding="utf-8") as f:
        f.write(html_str)
    print("ATTENDEE_HTML_WRITTEN=1")
else:
    print("ATTENDEE_HTML_WRITTEN=0")
PY

          if [ -s "${OUT_HTML}" ] && grep -qi '<li[^>]*><a ' "${OUT_HTML}"; then
            echo "ATTN_HTML=${OUT_HTML}" >> "$GITHUB_ENV"
            echo "attendees_html=${OUT_HTML}" >> "$GITHUB_OUTPUT"
          else
            echo "No attendees extracted from logs"
            echo "ATTN_HTML=" >> "$GITHUB_ENV"
            echo "attendees_html=" >> "$GITHUB_OUTPUT"
          fi

      - name: Upload attendees HTML to GCS (only if non-empty)
        id: upload_attendees
        shell: bash
        run: |
          set -euxo pipefail
          test -n "${ATTN_HTML:-}" && test -s "${ATTN_HTML:-}" || { echo "No attendees HTML to upload"; exit 0; }
          DEST_ATT="gs://${GCS_BUCKET}/${BUCKET_PREFIX}/${BASE}-attendees.html"
          RAW_ATT="https://storage.googleapis.com/${GCS_BUCKET}/${BUCKET_PREFIX}/${BASE}-attendees.html"
          PROXY_ATT="https://media.chbmp.org/${PREFIX}/${BASE}-attendees.html"
          gsutil cp "${ATTN_HTML}" "$DEST_ATT"
          if [ "${{ inputs.make_public }}" = "true" ]; then
            gsutil acl ch -u AllUsers:R "$DEST_ATT" || gsutil iam ch allUsers:objectViewer "gs://${GCS_BUCKET}" || true
          fi
          echo "raw_attn=${RAW_ATT}"     >> "$GITHUB_OUTPUT"
          echo "proxy_attn=${PROXY_ATT}" >> "$GITHUB_OUTPUT"

      # ---------- (Optional) AUDIO → VTT / TRANSCRIPT (unchanged; runs when mode == '' ) ----------
      # Add your existing audio normalization / Deepgram steps here as before.
      # Keep them conditioned on: inputs.mode == ''.

      # ---------- PATCH WORDPRESS WITH RESULTS ----------
      - name: Patch WordPress assets/status
        if: ${{ env.WP_BASE_URL != '' && env.WP_USER != '' && env.WP_APP_PASSWORD != '' && inputs.post_id != '' }}
        shell: bash
        env:
          ATTN_HTML_PATH: ${{ steps.attendees_from_logs.outputs.attendees_html }}
          ATTN_URL_PROXY: ${{ steps.upload_attendees.outputs.proxy_attn }}
        run: |
          set -euxo pipefail
          AT_HTML=""
          if [ -n "${ATTN_HTML:-}" ] && [ -s "${ATTN_HTML:-}" ]; then
            AT_HTML="$(cat "${ATTN_HTML}")"
          fi
          BODY="$(jq -n \
            --arg pid "${{ inputs.post_id }}" \
            --arg attendees_html "${AT_HTML}" \
            --arg attendees_url "${ATTN_URL_PROXY:-}" \
            '
            { post_id: ($pid|tonumber), status:"complete", progress:100 }
            + (if ($attendees_html|length)>0 then {attendees_html:$attendees_html} else {} end)
            + (if ($attendees_url|length)>0 then {artifacts:{attendees_html_url:$attendees_url}} else {} end)
            ')"
          curl -sS -u "${WP_USER}:${WP_APP_PASSWORD}" -H "Content-Type: application/json" \
            -X POST "${WP_BASE_URL%/}/wp-json/ss3k/v1/patch-assets" -d "${BODY}"

      - name: Summary
        shell: bash
        run: |
          {
            echo "### Space Worker Summary"
            echo "- Space URL: ${{ inputs.space_url }}"
            echo "- Space ID:  ${{ steps.ids.outputs.space_id }}"
            echo "- Post ID:   ${{ inputs.post_id }}"
            if [ -n "${{ steps.upload_attendees.outputs.proxy_attn }}" ]; then
              echo "- Attendees HTML: ${{ steps.upload_attendees.outputs.proxy_attn }}"
            else
              echo "- Attendees HTML: (none)"
            fi
            echo "- Crawler preflight OK: ${{ steps.x_preflight.outputs.ok == '1' && 'yes' || 'no' }} reason ${{ steps.x_preflight.outputs.reason }}"
            echo "- Mode: ${{ inputs.mode }}"
          } >> "$GITHUB_STEP_SUMMARY"
