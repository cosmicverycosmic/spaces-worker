name: Space Worker

on:
  workflow_dispatch:
    inputs:
      space_url:
        description: X / Twitter Space URL if running transcript_only with MP3)
        required: false
        type: string
        default: ""
      post_id:
        description: Existing WordPress Post ID 
        required: false
        type: string
        default: ""
      title:
        description: Fallback post title 
        required: false
        type: string
        default: ""
      gcs_prefix:
        description: GCS prefix 
        required: false
        type: string
        default: ""
      make_public:
        description: Make uploaded artifacts public
        required: false
        type: choice
        options: ["true", "false"]
        default: "true"
      do_transcript:
        description: Generate transcript if crawler captions unavailable 
        required: false
        type: choice
        options: ["true", "false"]
        default: "true"
      mode:
        description: Limit processing 
        required: false
        type: choice
        options: ["", "transcript_only", "attendees_only"]
        default: ""
      existing_mp3_url:
        description: For transcript_only, provide URL to existing MP3
        required: false
        type: string
        default: ""

permissions:
  contents: read
  packages: read

env:
  # Core secrets/vars
  GCP_SA_KEY:       ${{ secrets.GCP_SA_KEY       || vars.GCP_SA_KEY }}
  GCS_BUCKET:       ${{ secrets.GCS_BUCKET       || vars.GCS_BUCKET }}
  WP_BASE_URL:      ${{ secrets.WP_BASE_URL      || secrets.WP_URL || vars.WP_BASE_URL || vars.WP_URL }}
  WP_USER:          ${{ secrets.WP_USER          || vars.WP_USER }}
  WP_APP_PASSWORD:  ${{ secrets.WP_APP_PASSWORD  || vars.WP_APP_PASSWORD }}
  DEEPGRAM_API_KEY: ${{ secrets.DEEPGRAM_API_KEY || vars.DEEPGRAM_API_KEY }}

  # twspace-crawler auth (cookie and/or bearer)
  TWITTER_AUTHORIZATION: ${{ secrets.TWITTER_AUTHORIZATION || secrets.X_BEARER     || vars.TWITTER_AUTHORIZATION || vars.X_BEARER }}
  TWITTER_AUTH_TOKEN:    ${{ secrets.TWITTER_AUTH_TOKEN    || secrets.X_AUTH_TOKEN || vars.TWITTER_AUTH_TOKEN    || vars.X_AUTH_TOKEN }}
  TWITTER_CSRF_TOKEN:    ${{ secrets.TWITTER_CSRF_TOKEN    || secrets.X_CSRF       || vars.TWITTER_CSRF_TOKEN    || vars.X_CSRF }}

  # Optional: Twitter API v1.1 for one-shot replies scrape
  TW_API_CONSUMER_KEY:        ${{ secrets.TW_API_CONSUMER_KEY        || vars.TW_API_CONSUMER_KEY }}
  TW_API_CONSUMER_SECRET:     ${{ secrets.TW_API_CONSUMER_SECRET     || vars.TW_API_CONSUMER_SECRET }}
  TW_API_ACCESS_TOKEN:        ${{ secrets.TW_API_ACCESS_TOKEN        || vars.TW_API_ACCESS_TOKEN }}
  TW_API_ACCESS_TOKEN_SECRET: ${{ secrets.TW_API_ACCESS_TOKEN_SECRET || vars.TW_API_ACCESS_TOKEN_SECRET }}

  WORKDIR: ${{ github.workspace }}/work
  ARTDIR:  ${{ github.workspace }}/out

jobs:
  process:
    name: Process Space
    runs-on: ubuntu-latest
    timeout-minutes: 180
    concurrency:
      group: ${{ format('space-worker-{0}-{1}', github.ref, github.event.inputs.post_id != '' && github.event.inputs.post_id || github.run_id) }}
      cancel-in-progress: false

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Notify WP — queued
        if: ${{ env.WP_BASE_URL != '' && env.WP_USER != '' && env.WP_APP_PASSWORD != '' && github.event.inputs.post_id != '' }}
        shell: bash
        run: |
          set -euo pipefail
          curl -sS -u "${WP_USER}:${WP_APP_PASSWORD}" \
            -H "Content-Type: application/json" \
            -X POST "${WP_BASE_URL%/}/wp-json/ss3k/v1/worker-status" \
            -d "$(jq -n --arg pid "${{ github.event.inputs.post_id }}" \
                       --arg status "queued" \
                       --arg msg "Workflow received and queued" \
                       --arg run "${{ github.run_id }}" \
                       --argjson progress 1 \
                       '{post_id: ($pid|tonumber), status:$status, message:$msg, run_id:$run, progress:$progress}')"

      - name: Install deps
        shell: bash
        run: |
          set -euxo pipefail
          sudo apt-get update
          sudo apt-get install -y --no-install-recommends ffmpeg jq python3 python3-pip ca-certificates gnupg
          python3 -m pip install --upgrade pip
          python3 -m pip install --no-cache-dir yt-dlp python-twitter tldextract
          echo "deb [signed-by=/usr/share/keyrings/cloud.google.gpg] http://packages.cloud.google.com/apt cloud-sdk main" | sudo tee /etc/apt/sources.list.d/google-cloud-sdk.list
          curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo gpg --dearmor -o /usr/share/keyrings/cloud.google.gpg
          sudo apt-get update && sudo apt-get install -y google-cloud-sdk
          echo "${{ github.token }}" | docker login ghcr.io -u "${{ github.actor }}" --password-stdin || true

      - name: Validate config and prefixes
        id: cfg
        shell: bash
        run: |
          set -euxo pipefail
          test -n "${GCP_SA_KEY}" || { echo "GCP_SA_KEY missing"; exit 1; }
          test -n "${GCS_BUCKET}" || { echo "GCS_BUCKET missing"; exit 1; }
          mkdir -p "$WORKDIR" "$ARTDIR" "$ARTDIR/logs"
          PFX="$(echo "${{ github.event.inputs.gcs_prefix }}" | sed -E 's#^/*##; s#/*$##')"
          if [ -z "$PFX" ]; then PFX="spaces/$(date +%Y)/$(date +%m)"; fi
          echo "PREFIX=$PFX"                  >> "$GITHUB_ENV"
          echo "BUCKET_PREFIX=${PFX#spaces/}" >> "$GITHUB_ENV"

      - name: Derive Space ID and base
        id: ids
        shell: bash
        env:
          URL: ${{ github.event.inputs.space_url }}
        run: |
          set -euxo pipefail
          SID=""
          if [ -n "$URL" ]; then
            SID="$(echo "$URL" | sed -nE 's#^.*/i/spaces/([^/?#]+).*#\1#p')"
          fi
          [ -z "$SID" ] && SID="unknown"
          BASE="space-$(date +%m-%d-%Y)-${SID}"
          echo "SPACE_ID=${SID}" >> "$GITHUB_ENV"
          echo "BASE=${BASE}"    >> "$GITHUB_ENV"
          echo "space_id=${SID}" >> "$GITHUB_OUTPUT"
          echo "base=${BASE}"    >> "$GITHUB_OUTPUT"

      - name: GCP auth
        shell: bash
        run: |
          set -euxo pipefail
          printf '%s' "${GCP_SA_KEY}" > "${HOME}/gcp-key.json"
          gcloud auth activate-service-account --key-file="${HOME}/gcp-key.json" >/dev/null

      - name: X preflight auth sanity check
        id: x_preflight
        shell: bash
        run: |
          set -euo pipefail
          AUTH="${TWITTER_AUTHORIZATION:-}"
          AT="${TWITTER_AUTH_TOKEN:-}"
          CT="${TWITTER_CSRF_TOKEN:-}"

          if [ -n "$AUTH" ] && ! printf '%s' "$AUTH" | grep -q '^Bearer '; then AUTH=""; fi
          [ -n "${TWITTER_AUTHORIZATION:-}" ] && echo "::add-mask::${TWITTER_AUTHORIZATION}"
          [ -n "$AT" ] && echo "::add-mask::${AT}"
          [ -n "$CT" ] && echo "::add-mask::${CT}"

          OK=0; REASON="no_creds"
          [ -n "$AT" ] && [ -n "$CT" ] && OK=1 && REASON="cookie_ok" || true
          [ -n "$AUTH" ] && OK=1 && REASON="${REASON}_bearer_present" || true

          echo "ok=${OK}"         >> "$GITHUB_OUTPUT"
          echo "reason=${REASON}" >> "$GITHUB_OUTPUT"
          [ -n "$AUTH" ] && echo "TWITTER_AUTHORIZATION=$AUTH" >> "$GITHUB_ENV"

      - name: Run crawler (by id)
        id: crawl
        if: ${{ steps.x_preflight.outputs.ok == '1' }}
        shell: bash
        env:
          SID: ${{ steps.ids.outputs.space_id }}
        run: |
          set -euxo pipefail
          mkdir -p "${ARTDIR}" "${ARTDIR}/logs"
          docker pull ghcr.io/hitomarukonpaku/twspace-crawler:latest || true

          LOG_STD="${ARTDIR}/logs/crawler_${SID}.out.log"
          LOG_ERR="${ARTDIR}/logs/crawler_${SID}.err.log"

          set +e
          timeout 20m docker run --rm \
            -e TWITTER_AUTHORIZATION \
            -e TWITTER_AUTH_TOKEN \
            -e TWITTER_CSRF_TOKEN \
            -v "${ARTDIR}:/app/download" \
            -v "${ARTDIR}/logs:/app/logs" \
            ghcr.io/hitomarukonpaku/twspace-crawler:latest \
            --id "${SID}" --force > >(tee -a "$LOG_STD") 2> >(tee -a "$LOG_ERR" >&2)
          RC=$?
          set -e
          echo "crawler_exit=${RC}"

          # Most-recent audio file
          AUDIO_FILE="$(find "${ARTDIR}" -type f \( -iname '*.m4a' -o -iname '*.mp3' -o -iname '*.mp4' -o -iname '*.aac' -o -iname '*.webm' -o -iname '*.ogg' -o -iname '*.wav' -o -iname '*.ts' \) -printf '%T@ %p\n' | sort -nr | head -n1 | cut -d' ' -f2- || true)"
          if [ -n "${AUDIO_FILE:-}" ] && [ -f "${AUDIO_FILE}" ]; then
            echo "INPUT_FILE=${AUDIO_FILE}" >> "$GITHUB_ENV"
            echo "audio_file=${AUDIO_FILE}" >> "$GITHUB_OUTPUT"
          fi

          # Extract minimal JSON from crawler logs
          RAW="$( (grep -hE 'getAudioSpaceBy(Id|RestId)\s*\|' "$LOG_STD" "$LOG_ERR" | tail -n1) || true )"
          if [ -n "$RAW" ]; then
            JSON_PART="$(printf '%s' "$RAW" | sed -e 's/^[^{]*//')"
            if printf '%s' "$JSON_PART" | jq -e . >/dev/null 2>&1; then
              printf '%s\n' "$JSON_PART" | jq -c . > "${ARTDIR}/_as_line.json"
              echo "as_line=${ARTDIR}/_as_line.json" >> "$GITHUB_OUTPUT"
            fi
          fi

          # Captions JSONL from crawler
          CC_JSONL="$(find "${ARTDIR}" -type f \( -iname '*cc.jsonl' -o -iname '*caption*.jsonl' -o -iname '*captions*.jsonl' \) -print | head -n1 || true)"
          if [ -n "${CC_JSONL:-}" ]; then
            echo "CRAWLER_CC=${CC_JSONL}" >> "$GITHUB_ENV"
          fi

      - name: Extract Space title & start (title = post title; start = post date)
        if: ${{ steps.crawl.outcome == 'success' }}
        shell: bash
        run: |
          set -euo pipefail
          J="${ARTDIR}/_as_line.json"
          TTL=""
          START_RAW=""
          if [ -s "$J" ] && jq -e . "$J" >/dev/null 2>&1; then
            TTL="$(jq -r '(.audioSpace // .) | .metadata.title // empty' "$J" || echo '')"
            START_RAW="$(jq -r '(.audioSpace // .) | (.metadata.started_at // .metadata.startedAt // .metadata.scheduled_start // .metadata.created_at // empty)' "$J" || echo '')"
          fi
          [ -z "$TTL" ] && TTL="${{ github.event.inputs.title }}"
          [ -z "$TTL" ] && TTL="${BASE}"
          echo "SPACE_TITLE=${TTL}" >> "$GITHUB_ENV"
          echo "TTL_FINAL=${TTL}"   >> "$GITHUB_ENV"

          DATE_GMT=""
          if [ -n "$START_RAW" ] && [ "$START_RAW" != "null" ]; then
            if [[ "$START_RAW" =~ ^[0-9]+$ ]]; then
              SEC=$((START_RAW/1000))
              DATE_GMT="$(date -u -d "@$SEC" '+%Y-%m-%dT%H:%M:%SZ')"
            else
              DATE_GMT="$(date -u -d "$START_RAW" '+%Y-%m-%dT%H:%M:%SZ' 2>/dev/null || true)"
            fi
          fi
          [ -z "$DATE_GMT" ] && DATE_GMT="$(date -u '+%Y-%m-%dT%H:%M:%SZ')"
          echo "SPACE_STARTED_AT=${DATE_GMT}" >> "$GITHUB_ENV"

      - name: Build VTT & syncable grouped transcript (from crawler JSONL)
        if: ${{ github.event.inputs.mode != 'attendees_only' }}
        shell: bash
        run: |
          set -euxo pipefail
          CC_JSONL="${CRAWLER_CC:-}"
          if [ -z "${CC_JSONL}" ]; then
            CC_JSONL="$(find "${ARTDIR}" -type f \( -iname '*cc.jsonl' -o -iname '*caption*.jsonl' -o -iname '*captions*.jsonl' \) -printf '%T@ %p\n' | sort -nr | head -n1 | cut -d' ' -f2- || true)"
          fi
          if [ -n "${CC_JSONL:-}" ] && [ -s "${CC_JSONL:-}" ]; then
            CC_JSONL="${CC_JSONL}" ARTDIR="${ARTDIR}" BASE="${BASE}" python3 - <<'PYCODE'
import json, os, re, html
from datetime import datetime, timezone

artdir = os.environ.get("ARTDIR")
base   = os.environ.get("BASE")
src    = os.environ.get("CC_JSONL") or ""
if not src:
    raise SystemExit(0)

def parse_time_iso(s):
    if not s: return None
    s = s.strip()
    if s.endswith('Z'): s = s[:-1] + '+00:00'
    if re.search(r'[+-]\d{4}$', s):
        s = s[:-5] + s[-5:-2] + ':' + s[-2:]
    try:
        dt = datetime.fromisoformat(s)
        if dt.tzinfo is None: dt = dt.replace(tzinfo=timezone.utc)
        return dt.timestamp()
    except Exception:
        return None

def fmt_ts(t):
    if t < 0: t = 0.0
    h = int(t // 3600); m = int((t % 3600) // 60); s = t % 60
    return f"{h:02d}:{m:02d}:{s:06.3f}"

def clean_name(s):
    s = s or ""
    s = re.sub(r'[<>&]', '', s)
    s = ''.join(ch for ch in s if (ord(ch) < 0x1F000 and not (0xD800 <= ord(ch) <= 0xDFFF)))
    s = s.strip()
    return s or "Speaker"

def esc(s): return (s or "").replace("&","&amp;").replace("<","&lt;").replace(">","&gt;")

# Load utterances (type 45)
utt = []
with open(src, 'r', encoding='utf-8', errors='ignore') as f:
    for line in f:
        line = line.strip()
        if not line: continue
        try: outer = json.loads(line)
        except Exception: continue
        payload_raw = outer.get("payload") or ""
        try: payload = json.loads(payload_raw)
        except Exception: continue
        body_raw = payload.get("body") or ""
        try: inner = json.loads(body_raw)
        except Exception: continue
        if inner.get("type") != 45: continue
        text = (inner.get("body") or "").strip()
        if not text: continue
        if "final" in inner and not inner.get("final"): continue
        name     = inner.get("displayName") or payload.get("sender", {}).get("display_name") \
                   or inner.get("username") or inner.get("user_id") or "Speaker"
        username = inner.get("username") or payload.get("sender", {}).get("screen_name") or ""
        avatar   = payload.get("sender", {}).get("profile_image_url_https") \
                   or payload.get("sender", {}).get("profile_image_url") or ""
        ts = parse_time_iso(inner.get("programDateTime"))
        if ts is None:
            try: ts = int(inner.get("timestamp")) / 1000.0
            except Exception: ts = None
        if ts is None: continue
        utt.append({"ts": ts, "name": clean_name(name), "username": username, "avatar": avatar, "text": text})

utt.sort(key=lambda x: x["ts"])
if not utt: raise SystemExit(0)

# Relative timings
t0_abs = utt[0]["ts"]
for i,u in enumerate(utt):
    u["start_rel"] = u["ts"] - t0_abs
    if i+1 < len(utt):
        nxt = utt[i+1]["ts"] - t0_abs
        u["end_rel"] = max(u["start_rel"] + 0.6, nxt - 0.1)
    else:
        words = max(1, len(u["text"].split()))
        u["end_rel"] = u["start_rel"] + min(6.0, max(1.2, 0.35*words + 0.8))

# Group adjacent same-speaker fragments
groups = []
GAP_MAX = 4.0
cur = None
for u in utt:
    if (cur is not None and
        u["name"] == cur["name"] and
        u["username"] == cur["username"] and
        (u["start_rel"] - cur["end_rel"]) <= GAP_MAX):
        sep = "" if cur["text"].endswith(('.', '!', '?')) else " "
        cur["text"] = (cur["text"] + sep + u["text"]).strip()
        cur["end_rel"] = max(cur["end_rel"], u["end_rel"])
    else:
        cur = {
            "name": u["name"],
            "username": u["username"],
            "avatar": u["avatar"],
            "start_rel": u["start_rel"],
            "end_rel": u["end_rel"],
            "text": u["text"],
        }
        groups.append(cur)

# WEBVTT
with open(os.path.join(artdir, f"{base}.vtt"), "w", encoding="utf-8") as vf:
    vf.write("WEBVTT\n\n")
    for idx,g in enumerate(groups,1):
        vf.write(f"{idx}\n{fmt_ts(g['start_rel'])} --> {fmt_ts(g['end_rel'])}\n")
        vf.write(f"<b>{esc(g['name'])}</b>: {esc(g['text'])}\n\n")

# Syncable transcript HTML
css = '''
<style>
.ss3k-transcript{font:15px/1.5 system-ui,-apple-system,Segoe UI,Roboto,Arial,sans-serif}
.ss3k-seg{display:flex;gap:10px;padding:8px 10px;border-radius:10px;margin:6px 0}
.ss3k-seg.active{background:#eef6ff;outline:1px solid #bfdbfe}
.ss3k-avatar{width:26px;height:26px;border-radius:50%;flex:0 0 26px;margin-top:3px}
.ss3k-meta{font-size:12px;color:#64748b;margin-bottom:2px}
.ss3k-name a{color:#0f172a;text-decoration:none}
.ss3k-text{white-space:pre-wrap;word-break:break-word;cursor:pointer}
</style>
'''
js = '''
<script>
(function(){
  function time(s){return parseFloat(s||'0')||0}
  function within(t,seg){return t>=time(seg.dataset.start) && t<time(seg.dataset.end)}
  function bind(){
    var audio=document.getElementById('ss3k-audio')||document.querySelector('audio[data-ss3k-player]');
    var cont=document.querySelector('.ss3k-transcript'); if(!audio||!cont) return;
    var segs=[].slice.call(cont.querySelectorAll('.ss3k-seg'));
    function tick(){
      var t=audio.currentTime||0, found=null;
      for(var i=0;i<segs.length;i++){ if(within(t,segs[i])){found=segs[i];break;} }
      segs.forEach(s=>s.classList.toggle('active', s===found));
    }
    audio.addEventListener('timeupdate', tick);
    segs.forEach(function(s){
      s.addEventListener('click', function(){ if(audio){ audio.currentTime=time(s.dataset.start)+0.05; audio.play().catch(()=>{}); }});
    });
    tick();
  }
  if(document.readyState!=='loading') bind(); else document.addEventListener('DOMContentLoaded', bind);
})();
</script>
'''
tr_path = os.path.join(artdir, f"{base}_transcript.html")
with open(tr_path, "w", encoding="utf-8") as tf:
    tf.write(css)
    tf.write('<div class="ss3k-transcript">\n')
    for i,g in enumerate(groups,1):
        name = g["name"]
        uname = (g.get("username") or "").strip()
        prof = f"https://x.com/{html.escape(uname, True)}" if uname else ""
        avatar = g.get("avatar") or (f"https://unavatar.io/x/{html.escape(uname, True)}" if uname else "")
        avtag = f'<a href="{prof}" target="_blank" rel="noopener"><img class="ss3k-avatar" src="{html.escape(avatar, True)}" alt=""></a>' if avatar and prof else (f'<img class="ss3k-avatar" src="{html.escape(avatar, True)}" alt="">' if avatar else '<div style="width:26px;height:26px"></div>')
        name_html = f'<span class="ss3k-name"><a href="{prof}" target="_blank" rel="noopener"><strong>{html.escape(name, True)}</strong></a></span>' if prof else f'<span class="ss3k-name"><strong>{html.escape(name, True)}</strong></span>'
        tf.write(f'<div class="ss3k-seg" id="seg-{i:04d}" data-start="{g["start_rel"]:.3f}" data-end="{g["end_rel"]:.3f}" data-speaker="{html.escape(name, True)}">')
        tf.write(avtag)
        tf.write('<div class="ss3k-body">')
        tf.write(f'<div class="ss3k-meta">{name_html} · <time>{fmt_ts(g["start_rel"])}</time>–<time>{fmt_ts(g["end_rel"])}</time></div>')
        tf.write(f'<div class="ss3k-text">{html.escape(g["text"], True)}</div>')
        tf.write('</div></div>\n')
    tf.write('</div>\n')
    tf.write(js)

start_iso = datetime.fromtimestamp(utt[0]["ts"], timezone.utc).isoformat(timespec='seconds').replace('+00:00','Z')
with open(os.path.join(artdir, f"{base}.start.txt"), "w", encoding="utf-8") as sf:
    sf.write(start_iso + "\n")
PYCODE
            # Export paths
            [ -s "${ARTDIR}/${BASE}.vtt" ] && echo "VTT_PATH=${ARTDIR}/${BASE}.vtt" >> "$GITHUB_ENV" || true
            [ -s "${ARTDIR}/${BASE}_transcript.html" ] && echo "TRANSCRIPT_PATH=${ARTDIR}/${BASE}_transcript.html" >> "$GITHUB_ENV" || true
            if [ -z "${SPACE_STARTED_AT:-}" ] && [ -s "${ARTDIR}/${BASE}.start.txt" ]; then
              echo "SPACE_STARTED_AT=$(tr -d '\r\n' < "${ARTDIR}/${BASE}.start.txt")" >> "$GITHUB_ENV"
            fi
          fi

      - name: Notify WP — processing audio
        if: ${{ github.event.inputs.mode != 'attendees_only' && env.WP_BASE_URL != '' && env.WP_USER != '' && env.WP_APP_PASSWORD != '' && github.event.inputs.post_id != '' }}
        shell: bash
        run: |
          set -euo pipefail
          curl -sS -u "${WP_USER}:${WP_APP_PASSWORD}" \
            -H "Content-Type: application/json" \
            -X POST "${WP_BASE_URL%/}/wp-json/ss3k/v1/worker-status" \
            -d "$(jq -n --arg pid "${{ github.event.inputs.post_id }}" \
                         --arg status "processing" \
                         --arg msg "Processing audio" \
                         --arg run "${{ github.run_id }}" --argjson progress 10 \
                         '{post_id: ($pid|tonumber), status:$status, message:$msg, run_id:$run, progress:$progress}')"

      - name: Fallback download via yt-dlp
        if: ${{ github.event.inputs.mode != 'attendees_only' && (steps.crawl.outputs.audio_file == '' || steps.crawl.outcome != 'success') && github.event.inputs.existing_mp3_url == '' && github.event.inputs.space_url != '' }}
        shell: bash
        working-directory: ${{ env.WORKDIR }}
        env:
          URL: ${{ github.event.inputs.space_url }}
        run: |
          set -euxo pipefail
          yt-dlp -o "%(title)s.%(ext)s" -f "bestaudio/best" "$URL"
          IN="$(ls -S | head -n1 || true)"
          test -f "$IN" || { echo "No file downloaded"; exit 1; }
          echo "INPUT_FILE=$PWD/$IN" >> "$GITHUB_ENV"

      - name: Use provided MP3 for transcript only
        if: ${{ github.event.inputs.mode == 'transcript_only' && github.event.inputs.existing_mp3_url != '' }}
        shell: bash
        run: |
          set -euxo pipefail
          curl -L "${{ github.event.inputs.existing_mp3_url }}" -o "${ARTDIR}/${BASE}.mp3"
          echo "INPUT_FILE=${ARTDIR}/${BASE}.mp3" >> "$GITHUB_ENV"

      - name: Trim head and tail silence
        if: ${{ github.event.inputs.mode != 'attendees_only' && env.INPUT_FILE != '' }}
        shell: bash
        run: |
          set -euxo pipefail
          TRIM_WAV="${WORKDIR}/trim_${{ github.run_id }}.wav"
          ffmpeg -hide_banner -y -i "$INPUT_FILE" \
            -af "silenceremove=start_periods=1:start_silence=1:start_threshold=-45dB:detection=peak,areverse,silenceremove=start_periods=1:start_silence=1:start_threshold=-45dB:detection=peak,areverse" \
            -ar 48000 -ac 2 -c:a pcm_s16le "$TRIM_WAV"
          echo "AUDIO_IN=${TRIM_WAV}" >> "$GITHUB_ENV"

      - name: Enhance + loudness normalize to MP3 (radio tone)
        if: ${{ github.event.inputs.mode != 'attendees_only' && env.AUDIO_IN != '' }}
        shell: bash
        run: |
          set -euxo pipefail
          # Presence EQ + gentle gate + compression + adaptive norm; de-esser if available
          PRE_BASE='highpass=f=80,lowpass=f=12000,afftdn=nr=12:nf=-28,equalizer=f=250:t=q:w=1.2:g=-2.5,equalizer=f=3000:t=q:w=1.0:g=2.5,equalizer=f=8000:t=q:w=0.8:g=1.5,agate=threshold=0.015:ratio=2:attack=5:release=100,acompressor=threshold=-20dB:ratio=3:attack=8:release=220:makeup=5,dynaudnorm=p=1:m=7:s=12'
          PRE_DESS='highpass=f=80,lowpass=f=12000,afftdn=nr=12:nf=-28,deesser=i=0.6,equalizer=f=250:t=q:w=1.2:g=-2.5,equalizer=f=3000:t=q:w=1.0:g=2.5,equalizer=f=8000:t=q:w=0.8:g=1.5,agate=threshold=0.015:ratio=2:attack=5:release=100,acompressor=threshold=-20dB:ratio=3:attack=8:release=220:makeup=5,dynaudnorm=p=1:m=7:s=12'
          PRE="$PRE_BASE"

          PASS1_JSON="${WORKDIR}/loudnorm1.json"
          if ffmpeg -hide_banner -y -i "$AUDIO_IN" -af "${PRE_DESS},loudnorm=I=-16:TP=-1.5:LRA=11:print_format=json" -f null - 2>"${WORKDIR}/pass1.log"; then
            PRE="$PRE_DESS"
          else
            echo "De-esser unavailable or failed — using base chain."
            ffmpeg -hide_banner -y -i "$AUDIO_IN" -af "${PRE},loudnorm=I=-16:TP=-1.5:LRA=11:print_format=json" -f null - 2>"${WORKDIR}/pass1.log" || true
          fi

          awk '/^{/{f=1} f{print} /}/{f=0}' "${WORKDIR}/pass1.log" > "$PASS1_JSON" || true

          if jq -e . "$PASS1_JSON" >/dev/null 2>&1; then
            I=$(jq -r '.input_i // "-16"'      "$PASS1_JSON")
            TP=$(jq -r '.input_tp // "-1.5"'    "$PASS1_JSON")
            LRA=$(jq -r '.input_lra // "11"'    "$PASS1_JSON")
            TH=$(jq -r '.input_thresh // "-26"' "$PASS1_JSON")
            ffmpeg -hide_banner -y -i "$AUDIO_IN" \
              -af "${PRE},loudnorm=I=-16:TP=-1.5:LRA=11:measured_I=$I:measured_TP=$TP:measured_LRA=$LRA:measured_thresh=$TH:linear=true" \
              -ar 48000 -ac 1 -c:a libmp3lame -b:a 160k "${ARTDIR}/${BASE}.mp3"
          else
            ffmpeg -hide_banner -y -i "$AUDIO_IN" \
              -af "${PRE},loudnorm=I=-16:TP=-1.5:LRA=11" \
              -ar 48000 -ac 1 -c:a libmp3lame -b:a 160k "${ARTDIR}/${BASE}.mp3"
          fi
          echo "MP3_PATH=${ARTDIR}/${BASE}.mp3" >> "$GITHUB_ENV"

      - name: Upload MP3 to GCS
        id: upload_mp3
        if: ${{ github.event.inputs.mode != 'attendees_only' && env.MP3_PATH != '' }}
        shell: bash
        run: |
          set -euxo pipefail
          DEST="gs://${GCS_BUCKET}/${BUCKET_PREFIX}/${BASE}.mp3"
          RAW="https://storage.googleapis.com/${GCS_BUCKET}/${BUCKET_PREFIX}/${BASE}.mp3"
          PROXY="https://media.chbmp.org/${PREFIX}/${BASE}.mp3"
          gsutil -m cp "${MP3_PATH}" "$DEST"
          if [ "${{ github.event.inputs.make_public }}" = "true" ]; then
            (gsutil acl ch -u AllUsers:R "$DEST" || gsutil iam ch allUsers:objectViewer "gs://${GCS_BUCKET}") || true
          fi
          echo "audio_raw=${RAW}"     >> "$GITHUB_OUTPUT"
          echo "audio_proxy=${PROXY}" >> "$GITHUB_OUTPUT"

      - name: Prefer crawler captions if present
        id: crawl_cc
        if: ${{ github.event.inputs.mode != 'attendees_only' }}
        shell: bash
        run: |
          set -euo pipefail
          [ -s "${ARTDIR}/${BASE}.vtt" ] && echo "VTT_PATH=${ARTDIR}/${BASE}.vtt" >> "$GITHUB_ENV" || true

      - name: VTT via Deepgram (fallback)
        id: deepgram
        if: ${{ github.event.inputs.mode != 'attendees_only' && env.VTT_PATH == '' && env.DEEPGRAM_API_KEY != '' && github.event.inputs.do_transcript == 'true' && env.MP3_PATH != '' }}
        shell: bash
        run: |
          set -euxo pipefail
          curl -sS -X POST \
            -H "Authorization: Token ${DEEPGRAM_API_KEY}" \
            -H "Content-Type: audio/mpeg" \
            --data-binary @"${MP3_PATH}" \
            "https://api.deepgram.com/v1/listen?model=nova-2&smart_format=true&punctuate=true&format=vtt" \
            -o "${ARTDIR}/${BASE}.vtt" || true
          [ -s "${ARTDIR}/${BASE}.vtt" ] && echo "VTT_PATH=${ARTDIR}/${BASE}.vtt" >> "$GITHUB_ENV" || true

      - name: Upload VTT to GCS
        id: upload_vtt
        if: ${{ github.event.inputs.mode != 'attendees_only' && env.VTT_PATH != '' }}
        shell: bash
        run: |
          set -euxo pipefail
          DEST="gs://${GCS_BUCKET}/${BUCKET_PREFIX}/${BASE}.vtt"
          RAW="https://storage.googleapis.com/${GCS_BUCKET}/${BUCKET_PREFIX}/${BASE}.vtt"
          PROXY="https://media.chbmp.org/${PREFIX}/${BASE}.vtt"
          gsutil -m cp "${VTT_PATH}" "$DEST"
          if [ "${{ github.event.inputs.make_public }}" = "true" ]; then
            (gsutil acl ch -u AllUsers:R "$DEST" || gsutil iam ch allUsers:objectViewer "gs://${GCS_BUCKET}") || true
          fi
          echo "vtt_raw=${RAW}"     >> "$GITHUB_OUTPUT"
          echo "vtt_proxy=${PROXY}" >> "$GITHUB_OUTPUT"

      - name: Build attendees JSON & HTML (from crawler)
        id: attendees
        if: ${{ steps.crawl.outcome == 'success' && steps.crawl.outputs.as_line != '' }}
        shell: bash
        env:
          CAND: ${{ steps.crawl.outputs.as_line }}
        run: |
          set -euxo pipefail
          OUT_JSON="${ARTDIR}/attendees.json"
          OUT_HTML="${ARTDIR}/attendees.html"

          jq -r '
            def mkp:
              { handle: (.twitter_screen_name // .user_results?.result?.legacy?.screen_name),
                name:   (.display_name       // .user_results?.result?.legacy?.name)
              }
              | select(.handle!=null and .handle!="")
              | . + { url: ("https://x.com/" + .handle) };

            (.audioSpace // .) as $a
            | ($a.metadata?.creator_results?.result?.legacy?) as $h
            | ($h.screen_name // empty) as $H
            | {
                host:    ( if $H != "" then [ {handle:$H, name:($h.name // ""), url:("https://x.com/" + $H)} ] else [] end ),
                cohosts: ( ($a.participants?.admins   // []) | map(mkp) | map(select(.handle != $H)) | unique_by(.handle) ),
                speakers:( ($a.participants?.speakers // []) | map(mkp) | unique_by(.handle) )
              }
          ' "${CAND}" > "$OUT_JSON" || true

          if [ -s "$OUT_JSON" ] && jq -e . "$OUT_JSON" >/dev/null 2>&1; then
            jq -r '
              def li: "  <li><a href=\"" + (.url//"#") + "\">" + ((.name // "") + " (@" + (.handle // "") + ")") + "</a></li>";
              def section(title; items):
                if (items|length) > 0
                then "<h3>" + title + "</h3>\n<ul>\n" + (items|map(li)|join("\n")) + "\n</ul>\n"
                else ""
                end;
              . as $d
              | section("Host"; $d.host)
              + section( (if ($d.cohosts|length)==1 then "Co-host" else "Co-hosts" end); $d.cohosts)
              + section("Speakers"; $d.speakers)
            ' "$OUT_JSON" > "$OUT_HTML"
            if grep -qi '<li><a ' "$OUT_HTML"; then
              echo "ATTN_HTML=${OUT_HTML}" >> "$GITHUB_ENV"
              echo "ATTENDEES_OK=1"       >> "$GITHUB_ENV"
            fi
          fi

      - name: Scrape Space tweet replies (one-shot, optional)
        if: ${{ env.TW_API_CONSUMER_KEY != '' && env.TW_API_CONSUMER_SECRET != '' && env.TW_API_ACCESS_TOKEN != '' && env.TW_API_ACCESS_TOKEN_SECRET != '' }}
        shell: bash
        run: |
          set -euxo pipefail
          ARTDIR="${ARTDIR}" BASE="${BASE}" SPACE_ID="${SPACE_ID}" python3 - <<'PY'
import os, json, html
from collections import defaultdict
import tldextract, twitter

out_dir = os.environ["ARTDIR"]
base    = os.environ["BASE"]
space_id = os.environ.get("SPACE_ID","").strip()

as_json = os.path.join(out_dir, "_as_line.json")
creator = None
if os.path.exists(as_json):
    try:
        data = json.load(open(as_json, "r", encoding="utf-8", errors="ignore"))
        a = (data.get("audioSpace") or {})
        creator = a.get("username") or a.get("creator_results",{}).get("result",{}).get("legacy",{}).get("screen_name")
    except Exception:
        pass

ck  = os.environ.get("TW_API_CONSUMER_KEY") or ""
cs  = os.environ.get("TW_API_CONSUMER_SECRET") or ""
at  = os.environ.get("TW_API_ACCESS_TOKEN") or ""
ats = os.environ.get("TW_API_ACCESS_TOKEN_SECRET") or ""

if not (ck and cs and at and ats and space_id):
    raise SystemExit(0)

api = twitter.Api(consumer_key=ck, consumer_secret=cs,
                  access_token_key=at, access_token_secret=ats,
                  sleep_on_rate_limit=True, tweet_mode='extended')

def do_search(q, pages=5):
    res=[]; max_id=None
    for _ in range(pages):
        batch = api.GetSearch(term=q, count=100, include_entities=True, max_id=max_id, result_type='recent')
        if not batch: break
        res.extend(batch); max_id = min(t.id for t in batch) - 1
    return res

terms = [f"i/spaces/{space_id}", f"https://twitter.com/i/spaces/{space_id}"]
candidates = do_search(terms[0])
if creator: candidates += do_search(f'from:{creator} "{terms[0]}"')

def has_space_link(t):
    txt = (getattr(t, "full_text", None) or t.text or "")
    if space_id in txt: return True
    for u in (t.urls or []):
        if space_id in ((u.expanded_url or u.url) or ""): return True
    return False

cands = [t for t in candidates if has_space_link(t)]
if not cands: raise SystemExit(0)

root = None
if creator:
    for t in sorted(cands, key=lambda x: x.created_at_in_seconds or 0):
        if t.user and (t.user.screen_name or "").lower() == creator.lower():
            root = t; break
if root is None:
    root = sorted(cands, key=lambda x: x.created_at_in_seconds or 0)[0]

q = f"to:{root.user.screen_name} since_id:{root.id}"
all_replies=[]; max_id=None
for _ in range(25):
    batch = api.GetSearch(term=q, count=100, include_entities=True, max_id=max_id, result_type='recent')
    if not batch: break
    all_replies.extend(batch); max_id = min(t.id for t in batch) - 1

node = {}
def make_node(t): return {"tweet":t, "children":[]}
node[root.id]=make_node(root)
for t in all_replies: node[t.id]=make_node(t)
for t in all_replies:
    pid=t.in_reply_to_status_id
    if pid in node: node[pid]["children"].append(node[t.id])
for n in node.values(): n["children"].sort(key=lambda x: x["tweet"].created_at_in_seconds or 0)

def esc(s): return html.escape(s or "", True)
def avatar(user):
    return (user.profile_image_url_https or user.profile_image_url or f"https://unavatar.io/x/{esc(user.screen_name)}") if user else ""

def link_chips(t):
    chips=[]; seen=set()
    for u in (t.urls or []):
        href=u.expanded_url or u.url
        if not href or href in seen: continue
        seen.add(href)
        host=tldextract.extract(href).registered_domain or href
        chips.append(f'<a class="ss3k-link-card" href="{esc(href)}" target="_blank" rel="noopener">{esc(host)}</a>')
    return ('\n        <div class="ss3k-link-cards">' + "\n          " + "\n          ".join(chips) + "\n        </div>") if chips else ""

def media_block(t):
    media = getattr(t, "media", None) or []
    parts=[]
    for m in media:
        if getattr(m, "type", None) == "photo" and getattr(m, "media_url_https", None):
            parts.append(f'<img class="reply-media" src="{esc(m.media_url_https)}" alt="">')
    return ("\n        " + "\n        ".join(parts)) if parts else ""

def render(n, level=1):
    t=n["tweet"]; sn=t.user.screen_name if t.user else "user"
    name=t.user.name if t.user else sn
    prof=f"https://x.com/{esc(sn)}"; tw=f"https://x.com/{esc(sn)}/status/{t.id}"
    dt=t.created_at_in_seconds or 0
    from datetime import datetime, timezone
    iso=datetime.fromtimestamp(dt, tz=timezone.utc).isoformat(timespec="seconds")
    av=avatar(t.user)
    txt=(getattr(t,"full_text",None) or t.text or "")
    for u in (t.urls or []):
        if u.expanded_url and u.url: txt=txt.replace(u.url, u.expanded_url)
    content=esc(txt)
    links=link_chips(t); media=media_block(t)
    child=""
    if n["children"]:
        cid=f"children-{t.id}"; btn=f"Show {len(n['children'])} repl" + ("y" if len(n["children"])==1 else "ies")
        child = (
          f'\n      <button class="ss3k-toggle" data-label="{esc(btn)}" data-hide="Hide replies" onclick="ss3kToggleReplies(\'{cid}\', this)">{esc(btn)}</button>\n'
          f'      <div class="ss3k-children" id="{cid}">\n'
          + "\n".join(render(c, level+1) for c in n["children"]) + "\n      </div>"
        )
    return f'''
<div class="ss3k-reply-card" id="{t.id}" data-level="{level}">
  <div class="ss3k-reply-head">
    <a href="{prof}" target="_blank" rel="noopener">
      <img class="avatar" src="{esc(av)}" alt="">
    </a>
    <div>
      <div>
        <a href="{prof}" target="_blank" rel="noopener"><strong>{esc(name)}</strong></a>
        <span style="color:#64748b">@{esc(sn)}</span>
      </div>
      <div class="ss3k-reply-meta">
        <a href="{tw}" target="_blank" rel="noopener"><time datetime="{iso}">{iso.replace('T',' ')} UTC</time></a>
      </div>
    </div>
  </div>
  <div class="ss3k-reply-content">{content}</div>{media}{links}{child}
</div>'''.rstrip()

html_top = '''<style>
.ss3k-replies{font:14px/1.45 system-ui,-apple-system,Segoe UI,Roboto,Arial,sans-serif}
.ss3k-reply-card{border:1px solid #e2e8f0;border-radius:12px;padding:12px;margin:10px 0;background:#fff;box-shadow:0 1px 1px rgba(0,0,0,.03)}
.ss3k-reply-head{display:flex;align-items:center;gap:8px}
.ss3k-reply-head img.avatar{width:28px;height:28px;border-radius:50%}
.ss3k-reply-meta{color:#64748b;font-size:12px;margin-top:4px}
.ss3k-reply-content{margin-top:8px;white-space:pre-wrap;word-break:break-word}
.ss3k-link-cards{margin-top:8px;display:flex;flex-wrap:wrap;gap:6px}
.ss3k-link-card{border:1px solid #cbd5e1;padding:4px 8px;border-radius:8px;background:#f8fafc;font-size:12px}
.ss3k-children{margin-left:16px;display:none}
.ss3k-toggle{margin-top:6px;font-size:12px;color:#2563eb;background:none;border:none;padding:0;cursor:pointer}
.reply-media{max-width:100%;border-radius:10px;margin-top:8px}
</style>
<script>
function ss3kToggleReplies(id,btn){
  const el=document.getElementById(id); if(!el) return;
  const open=(el.style.display==='block'); el.style.display=open?'none':'block';
  if(btn){ btn.textContent=open?(btn.dataset.label||'Show replies'):(btn.dataset.hide||'Hide replies'); }
}
</script>
<div class="ss3k-replies">'''
html_bottom = "\n</div>\n"

# Collect domain links (optional)
domain_links = defaultdict(list)
def collect(t):
    for u in (t.urls or []):
        href=u.expanded_url or u.url
        if not href: continue
        host=tldextract.extract(href).registered_domain or href
        if href not in domain_links[host]: domain_links[host].append(href)
for t in [root]+all_replies: collect(t)

replies_html = html_top + "\n" + render(node[root.id]) + "\n" + html_bottom
open(os.path.join(out_dir, f"{base}_replies.html"), "w", encoding="utf-8").write(replies_html)

parts=[]
for dom in sorted(domain_links):
    links="\n".join(f'  <li><a href="{html.escape(u, True)}" target="_blank" rel="noopener">{html.escape(u, True)}</a></li>' for u in domain_links[dom])
    parts.append(f"<h4>{html.escape(dom, True)}</h4>\n<ul>\n{links}\n</ul>")
links_html="\n\n".join(parts)
open(os.path.join(out_dir, f"{base}_links.html"), "w", encoding="utf-8").write(links_html)
PY
          [ -s "${ARTDIR}/${BASE}_replies.html" ] && echo "REPLIES_PATH=${ARTDIR}/${BASE}_replies.html" >> "$GITHUB_ENV" || true
          [ -s "${ARTDIR}/${BASE}_links.html" ] && echo "LINKS_PATH=${ARTDIR}/${BASE}_links.html" >> "$GITHUB_ENV" || true

      - name: Register assets in WP (finalize)
        if: ${{ env.WP_BASE_URL != '' && env.WP_USER != '' && env.WP_APP_PASSWORD != '' && github.event.inputs.post_id != '' && (steps.upload_mp3.outputs.audio_proxy != '' || steps.upload_mp3.outputs.audio_raw != '') }}
        shell: bash
        env:
          PID:  ${{ github.event.inputs.post_id }}
          AUD:  ${{ steps.upload_mp3.outputs.audio_proxy || steps.upload_mp3.outputs.audio_raw }}
          VTTU: ${{ steps.upload_vtt.outputs.vtt_proxy   || steps.upload_vtt.outputs.vtt_raw }}
        run: |
          set -euo pipefail
          TTL="${TTL_FINAL:-${{ github.event.inputs.title }}}"
          [ -z "$TTL" ] && TTL="${BASE}"

          ATH_FILE="${WORKDIR}/empty_attendees.html"; : > "$ATH_FILE"
          [ -n "${ATTN_HTML:-}" ] && [ -s "${ATTN_HTML:-}" ] && ATH_FILE="${ATTN_HTML}"

          TR_FILE="${WORKDIR}/empty_transcript.html"; : > "$TR_FILE"
          [ -n "${TRANSCRIPT_PATH:-}" ] && [ -s "${TRANSCRIPT_PATH}" ] && TR_FILE="${TRANSCRIPT_PATH}"

          REP_FILE="${WORKDIR}/empty_replies.html"; : > "$REP_FILE"
          [ -n "${REPLIES_PATH:-}" ] && [ -s "${REPLIES_PATH}" ] && REP_FILE="${REPLIES_PATH}"

          LNK_FILE="${WORKDIR}/empty_links.html"; : > "$LNK_FILE"
          [ -n "${LINKS_PATH:-}" ] && [ -s "${LINKS_PATH}" ] && LNK_FILE="${LINKS_PATH}"

          REQ="${WORKDIR}/wp_register_body.json"
          jq -n \
            --arg gcs   "${AUD}" \
            --arg mime  "audio/mpeg" \
            --arg pid   "${PID}" \
            --arg ttl   "${TTL}" \
            --arg vtt   "${VTTU}" \
            --rawfile ath "${ATH_FILE}" \
            --rawfile tr  "${TR_FILE}" \
            --rawfile rep "${REP_FILE}" \
            --rawfile lnk "${LNK_FILE}" \
            --arg started "${SPACE_STARTED_AT:-}" \
            '{
               gcs_url: $gcs,
               mime:    $mime,
               post_id: ($pid|tonumber),
               title:   $ttl
             }
             + (if ($vtt|length)>0 then {vtt_url:$vtt} else {} end)
             + (if ($ath|gsub("\\s";"")|length)>0 then {attendees_html:$ath} else {} end)
             + (if ($tr|gsub("\\s";"")|length)>0 then {transcript:$tr, has_transcript:true} else {} end)
             + (if ($rep|gsub("\\s";"")|length)>0 then {ss3k_replies_html:$rep} else {} end)
             + (if ($lnk|gsub("\\s";"")|length)>0 then {links_html:$lnk} else {} end)
             + (if ($started|length)>0 then {space_started_at:$started} else {} end)
            ' > "$REQ"

          curl -sS -u "${WP_USER}:${WP_APP_PASSWORD}" \
            -H "Content-Type: application/json" \
            -X POST "${WP_BASE_URL%/}/wp-json/ss3k/v1/register" \
            --data-binary @"$REQ" | jq -r .

      - name: Set WP post date to Space start (authoritative)
        if: ${{ env.WP_BASE_URL != '' && env.WP_USER != '' && env.WP_APP_PASSWORD != '' && env.SPACE_STARTED_AT != '' && github.event.inputs.post_id != '' }}
        shell: bash
        run: |
          set -euo pipefail
          DATE_GMT="$(date -u -d "${SPACE_STARTED_AT}" '+%Y-%m-%dT%H:%M:%S')"
          curl -sS -u "${WP_USER}:${WP_APP_PASSWORD}" \
            -H "Content-Type: application/json" \
            -X POST "${WP_BASE_URL%/}/wp-json/wp/v2/posts/${{ github.event.inputs.post_id }}" \
            -d "$(jq -n --arg d "${DATE_GMT}" '{date_gmt:$d}')" | jq -r '.id // "ok"'

      - name: Patch WP — attendees only
        if: ${{ github.event.inputs.mode == 'attendees_only' && env.WP_BASE_URL != '' && env.WP_USER != '' && env.WP_APP_PASSWORD != '' && github.event.inputs.post_id != '' }}
        shell: bash
        run: |
          set -euo pipefail
          AT_HTML=""
          if [ -n "${ATTN_HTML:-}" ] && [ -s "${ATTN_HTML:-}" ]; then
            AT_HTML="$(cat "${ATTN_HTML}")"
          fi

          BODY="$(jq -n \
            --arg pid "${{ github.event.inputs.post_id }}" \
            --arg ath "${AT_HTML}" \
            '{post_id: ($pid|tonumber), status:"complete", progress:100}
             + (if ($ath|length)>0 then {attendees_html:$ath} else {} end)
          ')"

          curl -sS -u "${WP_USER}:${WP_APP_PASSWORD}" \
            -H "Content-Type: application/json" \
            -X POST "${WP_BASE_URL%/}/wp-json/ss3k/v1/patch-assets" \
            -d "$BODY" | jq -r .

      - name: Summary
        shell: bash
        env:
          SID: ${{ steps.ids.outputs.space_id }}
        run: |
          {
            echo "### Space Worker Summary"
            echo "- Space URL ${{ github.event.inputs.space_url }}"
            echo "- Space ID  ${SID}"
            echo "- Post ID   ${{ github.event.inputs.post_id }}"
            if [ -n "${SPACE_TITLE:-}" ]; then
              echo "- Space title: ${SPACE_TITLE}"
            fi
            if [ -n "${SPACE_STARTED_AT:-}" ]; then
              echo "- Space start (UTC): ${SPACE_STARTED_AT}"
            fi
            if [ -n "${{ steps.upload_mp3.outputs.audio_proxy }}" ]; then
              echo "- Audio     ${{ steps.upload_mp3.outputs.audio_proxy }}"
            elif [ -n "${{ steps.upload_mp3.outputs.audio_raw }}" ]; then
              echo "- Audio     ${{ steps.upload_mp3.outputs.audio_raw }}"
            fi
            if [ -n "${{ steps.upload_vtt.outputs.vtt_proxy }}" ]; then
              echo "- VTT       ${{ steps.upload_vtt.outputs.vtt_proxy }}"
            elif [ -n "${{ steps.upload_vtt.outputs.vtt_raw }}" ]; then
              echo "- VTT       ${{ steps.upload_vtt.outputs.vtt_raw }}"
            fi
            if [ -n "${TRANSCRIPT_PATH:-}" ] && [ -s "${TRANSCRIPT_PATH}" ]; then
              echo "- Transcript embedded (sync-ready)"
            else
              echo "- Transcript not generated"
            fi
            if [ -n "${REPLIES_PATH:-}" ]; then
              echo "- Replies HTML generated"
            fi
            if [ -n "${LINKS_PATH:-}" ]; then
              echo "- Shared links HTML generated"
            fi
            if [ "${ATTENDEES_OK:-0}" = "1" ]; then
              echo "- Attendees saved to WP (HTML)"
            else
              echo "- Attendees not extracted"
            fi
            echo "- Preflight ok=${{ steps.x_preflight.outputs.ok }} reason=${{ steps.x_preflight.outputs.reason }}"
            echo "- Mode      ${{ github.event.inputs.mode }}"
          } >> "$GITHUB_STEP_SUMMARY"
